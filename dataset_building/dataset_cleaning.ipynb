{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a199f33",
   "metadata": {},
   "source": [
    "# **Packages import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8f476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e108f",
   "metadata": {},
   "source": [
    "# **Processing MASI dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6ec7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dernier</th>\n",
       "      <th>Ouv.</th>\n",
       "      <th>Plus Haut</th>\n",
       "      <th>Plus Bas</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Variation %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19/12/2025</td>\n",
       "      <td>18.938,30</td>\n",
       "      <td>18.815,95</td>\n",
       "      <td>19.005,82</td>\n",
       "      <td>18.815,95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/12/2025</td>\n",
       "      <td>18.815,95</td>\n",
       "      <td>18.760,08</td>\n",
       "      <td>18.869,60</td>\n",
       "      <td>18.759,49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/12/2025</td>\n",
       "      <td>18.760,08</td>\n",
       "      <td>18.583,78</td>\n",
       "      <td>18.767,61</td>\n",
       "      <td>18.583,78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/12/2025</td>\n",
       "      <td>18.583,78</td>\n",
       "      <td>18.553,93</td>\n",
       "      <td>18.671,92</td>\n",
       "      <td>18.543,49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/12/2025</td>\n",
       "      <td>18.553,93</td>\n",
       "      <td>18.566,51</td>\n",
       "      <td>18.694,45</td>\n",
       "      <td>18.515,19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,07%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>08/01/2021</td>\n",
       "      <td>11.249,14</td>\n",
       "      <td>11.271,23</td>\n",
       "      <td>11.298,06</td>\n",
       "      <td>11.244,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>07/01/2021</td>\n",
       "      <td>11.271,23</td>\n",
       "      <td>11.215,71</td>\n",
       "      <td>11.303,69</td>\n",
       "      <td>11.215,71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>06/01/2021</td>\n",
       "      <td>11.215,71</td>\n",
       "      <td>11.253,70</td>\n",
       "      <td>11.277,86</td>\n",
       "      <td>11.210,15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>05/01/2021</td>\n",
       "      <td>11.253,70</td>\n",
       "      <td>11.308,67</td>\n",
       "      <td>11.327,53</td>\n",
       "      <td>11.253,28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>04/01/2021</td>\n",
       "      <td>11.340,86</td>\n",
       "      <td>11.287,38</td>\n",
       "      <td>11.340,97</td>\n",
       "      <td>11.274,78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,47%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Dernier       Ouv.  Plus Haut   Plus Bas  Vol. Variation %\n",
       "0     19/12/2025  18.938,30  18.815,95  19.005,82  18.815,95   NaN       0,65%\n",
       "1     18/12/2025  18.815,95  18.760,08  18.869,60  18.759,49   NaN       0,30%\n",
       "2     17/12/2025  18.760,08  18.583,78  18.767,61  18.583,78   NaN       0,95%\n",
       "3     16/12/2025  18.583,78  18.553,93  18.671,92  18.543,49   NaN       0,16%\n",
       "4     15/12/2025  18.553,93  18.566,51  18.694,45  18.515,19   NaN      -0,07%\n",
       "...          ...        ...        ...        ...        ...   ...         ...\n",
       "1232  08/01/2021  11.249,14  11.271,23  11.298,06  11.244,10   NaN      -0,20%\n",
       "1233  07/01/2021  11.271,23  11.215,71  11.303,69  11.215,71   NaN       0,50%\n",
       "1234  06/01/2021  11.215,71  11.253,70  11.277,86  11.210,15   NaN      -0,34%\n",
       "1235  05/01/2021  11.253,70  11.308,67  11.327,53  11.253,28   NaN      -0,77%\n",
       "1236  04/01/2021  11.340,86  11.287,38  11.340,97  11.274,78   NaN       0,47%\n",
       "\n",
       "[1237 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Moroccan All Shares - Données Historiques.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a745b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\1065603435.py:2: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "for col in df.columns:\n",
    "    if col == \"Date\" or col == \"Vol.\" or col == \"Variation %\":\n",
    "        continue\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .str.replace(\".\", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False) \n",
    "        .astype(float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50bac3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              0\n",
       "Dernier           0\n",
       "Ouv.              0\n",
       " Plus Haut        0\n",
       "Plus Bas          0\n",
       "Vol.           1237\n",
       "Variation %       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506af08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Dernier        0\n",
       "Ouv.           0\n",
       " Plus Haut     0\n",
       "Plus Bas       0\n",
       "Variation %    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = [\"Vol.\"], inplace = True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079be9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dernier</th>\n",
       "      <th>Ouv.</th>\n",
       "      <th>Plus Haut</th>\n",
       "      <th>Plus Bas</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>is_friday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>18938.30</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>19005.82</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>0,65%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-18</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>18760.08</td>\n",
       "      <td>18869.60</td>\n",
       "      <td>18759.49</td>\n",
       "      <td>0,30%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-17</td>\n",
       "      <td>18760.08</td>\n",
       "      <td>18583.78</td>\n",
       "      <td>18767.61</td>\n",
       "      <td>18583.78</td>\n",
       "      <td>0,95%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-16</td>\n",
       "      <td>18583.78</td>\n",
       "      <td>18553.93</td>\n",
       "      <td>18671.92</td>\n",
       "      <td>18543.49</td>\n",
       "      <td>0,16%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-15</td>\n",
       "      <td>18553.93</td>\n",
       "      <td>18566.51</td>\n",
       "      <td>18694.45</td>\n",
       "      <td>18515.19</td>\n",
       "      <td>-0,07%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>11249.14</td>\n",
       "      <td>11271.23</td>\n",
       "      <td>11298.06</td>\n",
       "      <td>11244.10</td>\n",
       "      <td>-0,20%</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>11271.23</td>\n",
       "      <td>11215.71</td>\n",
       "      <td>11303.69</td>\n",
       "      <td>11215.71</td>\n",
       "      <td>0,50%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>11215.71</td>\n",
       "      <td>11253.70</td>\n",
       "      <td>11277.86</td>\n",
       "      <td>11210.15</td>\n",
       "      <td>-0,34%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>11253.70</td>\n",
       "      <td>11308.67</td>\n",
       "      <td>11327.53</td>\n",
       "      <td>11253.28</td>\n",
       "      <td>-0,77%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>11340.86</td>\n",
       "      <td>11287.38</td>\n",
       "      <td>11340.97</td>\n",
       "      <td>11274.78</td>\n",
       "      <td>0,47%</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Dernier      Ouv.   Plus Haut  Plus Bas Variation %  \\\n",
       "0    2025-12-19  18938.30  18815.95    19005.82  18815.95       0,65%   \n",
       "1    2025-12-18  18815.95  18760.08    18869.60  18759.49       0,30%   \n",
       "2    2025-12-17  18760.08  18583.78    18767.61  18583.78       0,95%   \n",
       "3    2025-12-16  18583.78  18553.93    18671.92  18543.49       0,16%   \n",
       "4    2025-12-15  18553.93  18566.51    18694.45  18515.19      -0,07%   \n",
       "...         ...       ...       ...         ...       ...         ...   \n",
       "1232 2021-01-08  11249.14  11271.23    11298.06  11244.10      -0,20%   \n",
       "1233 2021-01-07  11271.23  11215.71    11303.69  11215.71       0,50%   \n",
       "1234 2021-01-06  11215.71  11253.70    11277.86  11210.15      -0,34%   \n",
       "1235 2021-01-05  11253.70  11308.67    11327.53  11253.28      -0,77%   \n",
       "1236 2021-01-04  11340.86  11287.38    11340.97  11274.78       0,47%   \n",
       "\n",
       "      is_friday  \n",
       "0          True  \n",
       "1         False  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  \n",
       "...         ...  \n",
       "1232       True  \n",
       "1233      False  \n",
       "1234      False  \n",
       "1235      False  \n",
       "1236      False  \n",
       "\n",
       "[1237 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flag Fridays\n",
    "df[\"is_friday\"] = df[\"Date\"].dt.weekday == 4\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a8544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"weekly_mean\"] = (\n",
    "    df\n",
    "    .groupby(df[\"Date\"].dt.to_period(\"W-FRI\"))[\"Dernier\"]\n",
    "    .transform(\"mean\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d3a961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dernier</th>\n",
       "      <th>Ouv.</th>\n",
       "      <th>Plus Haut</th>\n",
       "      <th>Plus Bas</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>is_friday</th>\n",
       "      <th>weekly_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>18938.30</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>19005.82</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>0,65%</td>\n",
       "      <td>True</td>\n",
       "      <td>18730.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-18</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>18760.08</td>\n",
       "      <td>18869.60</td>\n",
       "      <td>18759.49</td>\n",
       "      <td>0,30%</td>\n",
       "      <td>False</td>\n",
       "      <td>18730.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-17</td>\n",
       "      <td>18760.08</td>\n",
       "      <td>18583.78</td>\n",
       "      <td>18767.61</td>\n",
       "      <td>18583.78</td>\n",
       "      <td>0,95%</td>\n",
       "      <td>False</td>\n",
       "      <td>18730.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-16</td>\n",
       "      <td>18583.78</td>\n",
       "      <td>18553.93</td>\n",
       "      <td>18671.92</td>\n",
       "      <td>18543.49</td>\n",
       "      <td>0,16%</td>\n",
       "      <td>False</td>\n",
       "      <td>18730.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-15</td>\n",
       "      <td>18553.93</td>\n",
       "      <td>18566.51</td>\n",
       "      <td>18694.45</td>\n",
       "      <td>18515.19</td>\n",
       "      <td>-0,07%</td>\n",
       "      <td>False</td>\n",
       "      <td>18730.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>18566.51</td>\n",
       "      <td>18498.78</td>\n",
       "      <td>18622.63</td>\n",
       "      <td>18498.78</td>\n",
       "      <td>0,37%</td>\n",
       "      <td>True</td>\n",
       "      <td>18503.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>18498.78</td>\n",
       "      <td>18520.07</td>\n",
       "      <td>18545.73</td>\n",
       "      <td>18418.11</td>\n",
       "      <td>-0,11%</td>\n",
       "      <td>False</td>\n",
       "      <td>18503.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-12-10</td>\n",
       "      <td>18520.07</td>\n",
       "      <td>18458.27</td>\n",
       "      <td>18529.44</td>\n",
       "      <td>18396.95</td>\n",
       "      <td>0,33%</td>\n",
       "      <td>False</td>\n",
       "      <td>18503.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12-09</td>\n",
       "      <td>18458.70</td>\n",
       "      <td>18473.46</td>\n",
       "      <td>18527.50</td>\n",
       "      <td>18410.70</td>\n",
       "      <td>-0,08%</td>\n",
       "      <td>False</td>\n",
       "      <td>18503.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>18473.46</td>\n",
       "      <td>18469.38</td>\n",
       "      <td>18563.04</td>\n",
       "      <td>18418.04</td>\n",
       "      <td>0,02%</td>\n",
       "      <td>False</td>\n",
       "      <td>18503.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>18469.38</td>\n",
       "      <td>18386.27</td>\n",
       "      <td>18480.01</td>\n",
       "      <td>18339.21</td>\n",
       "      <td>0,45%</td>\n",
       "      <td>True</td>\n",
       "      <td>18402.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>18386.27</td>\n",
       "      <td>18371.96</td>\n",
       "      <td>18495.42</td>\n",
       "      <td>18371.68</td>\n",
       "      <td>0,08%</td>\n",
       "      <td>False</td>\n",
       "      <td>18402.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-12-03</td>\n",
       "      <td>18371.96</td>\n",
       "      <td>18350.34</td>\n",
       "      <td>18415.29</td>\n",
       "      <td>18323.25</td>\n",
       "      <td>0,12%</td>\n",
       "      <td>False</td>\n",
       "      <td>18402.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-12-02</td>\n",
       "      <td>18350.34</td>\n",
       "      <td>18428.73</td>\n",
       "      <td>18437.57</td>\n",
       "      <td>18318.91</td>\n",
       "      <td>-0,46%</td>\n",
       "      <td>False</td>\n",
       "      <td>18402.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>18434.92</td>\n",
       "      <td>18603.59</td>\n",
       "      <td>18603.59</td>\n",
       "      <td>18434.92</td>\n",
       "      <td>-0,91%</td>\n",
       "      <td>False</td>\n",
       "      <td>18402.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>18603.59</td>\n",
       "      <td>18640.63</td>\n",
       "      <td>18662.77</td>\n",
       "      <td>18492.47</td>\n",
       "      <td>-0,20%</td>\n",
       "      <td>True</td>\n",
       "      <td>18500.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>18640.63</td>\n",
       "      <td>18535.59</td>\n",
       "      <td>18648.85</td>\n",
       "      <td>18515.50</td>\n",
       "      <td>0,57%</td>\n",
       "      <td>False</td>\n",
       "      <td>18500.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>18535.59</td>\n",
       "      <td>18382.71</td>\n",
       "      <td>18538.80</td>\n",
       "      <td>18382.71</td>\n",
       "      <td>0,83%</td>\n",
       "      <td>False</td>\n",
       "      <td>18500.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>18382.71</td>\n",
       "      <td>18337.56</td>\n",
       "      <td>18458.28</td>\n",
       "      <td>18337.56</td>\n",
       "      <td>0,25%</td>\n",
       "      <td>False</td>\n",
       "      <td>18500.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>18337.56</td>\n",
       "      <td>18205.28</td>\n",
       "      <td>18340.14</td>\n",
       "      <td>18187.32</td>\n",
       "      <td>0,73%</td>\n",
       "      <td>False</td>\n",
       "      <td>18500.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Dernier      Ouv.   Plus Haut  Plus Bas Variation %  \\\n",
       "0  2025-12-19  18938.30  18815.95    19005.82  18815.95       0,65%   \n",
       "1  2025-12-18  18815.95  18760.08    18869.60  18759.49       0,30%   \n",
       "2  2025-12-17  18760.08  18583.78    18767.61  18583.78       0,95%   \n",
       "3  2025-12-16  18583.78  18553.93    18671.92  18543.49       0,16%   \n",
       "4  2025-12-15  18553.93  18566.51    18694.45  18515.19      -0,07%   \n",
       "5  2025-12-12  18566.51  18498.78    18622.63  18498.78       0,37%   \n",
       "6  2025-12-11  18498.78  18520.07    18545.73  18418.11      -0,11%   \n",
       "7  2025-12-10  18520.07  18458.27    18529.44  18396.95       0,33%   \n",
       "8  2025-12-09  18458.70  18473.46    18527.50  18410.70      -0,08%   \n",
       "9  2025-12-08  18473.46  18469.38    18563.04  18418.04       0,02%   \n",
       "10 2025-12-05  18469.38  18386.27    18480.01  18339.21       0,45%   \n",
       "11 2025-12-04  18386.27  18371.96    18495.42  18371.68       0,08%   \n",
       "12 2025-12-03  18371.96  18350.34    18415.29  18323.25       0,12%   \n",
       "13 2025-12-02  18350.34  18428.73    18437.57  18318.91      -0,46%   \n",
       "14 2025-12-01  18434.92  18603.59    18603.59  18434.92      -0,91%   \n",
       "15 2025-11-28  18603.59  18640.63    18662.77  18492.47      -0,20%   \n",
       "16 2025-11-27  18640.63  18535.59    18648.85  18515.50       0,57%   \n",
       "17 2025-11-26  18535.59  18382.71    18538.80  18382.71       0,83%   \n",
       "18 2025-11-25  18382.71  18337.56    18458.28  18337.56       0,25%   \n",
       "19 2025-11-24  18337.56  18205.28    18340.14  18187.32       0,73%   \n",
       "\n",
       "    is_friday  weekly_mean  \n",
       "0        True    18730.408  \n",
       "1       False    18730.408  \n",
       "2       False    18730.408  \n",
       "3       False    18730.408  \n",
       "4       False    18730.408  \n",
       "5        True    18503.504  \n",
       "6       False    18503.504  \n",
       "7       False    18503.504  \n",
       "8       False    18503.504  \n",
       "9       False    18503.504  \n",
       "10       True    18402.574  \n",
       "11      False    18402.574  \n",
       "12      False    18402.574  \n",
       "13      False    18402.574  \n",
       "14      False    18402.574  \n",
       "15       True    18500.016  \n",
       "16      False    18500.016  \n",
       "17      False    18500.016  \n",
       "18      False    18500.016  \n",
       "19      False    18500.016  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13e4e0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Dernier        0\n",
       "Ouv.           0\n",
       " Plus Haut     0\n",
       "Plus Bas       0\n",
       "Variation %    0\n",
       "is_friday      0\n",
       "weekly_mean    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c784c416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dernier</th>\n",
       "      <th>Ouv.</th>\n",
       "      <th>Plus Haut</th>\n",
       "      <th>Plus Bas</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>is_friday</th>\n",
       "      <th>weekly_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>11249.14</td>\n",
       "      <td>11271.23</td>\n",
       "      <td>11298.06</td>\n",
       "      <td>11244.10</td>\n",
       "      <td>-0,20%</td>\n",
       "      <td>True</td>\n",
       "      <td>11266.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>11416.19</td>\n",
       "      <td>11326.79</td>\n",
       "      <td>11442.59</td>\n",
       "      <td>11315.60</td>\n",
       "      <td>0,79%</td>\n",
       "      <td>True</td>\n",
       "      <td>11325.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>11563.73</td>\n",
       "      <td>11514.99</td>\n",
       "      <td>11567.93</td>\n",
       "      <td>11499.44</td>\n",
       "      <td>0,42%</td>\n",
       "      <td>True</td>\n",
       "      <td>11508.4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>11630.01</td>\n",
       "      <td>11657.63</td>\n",
       "      <td>11711.26</td>\n",
       "      <td>11630.01</td>\n",
       "      <td>-0,24%</td>\n",
       "      <td>True</td>\n",
       "      <td>11667.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>11713.50</td>\n",
       "      <td>11742.17</td>\n",
       "      <td>11778.18</td>\n",
       "      <td>11713.50</td>\n",
       "      <td>-0,24%</td>\n",
       "      <td>True</td>\n",
       "      <td>11710.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>18205.28</td>\n",
       "      <td>18112.94</td>\n",
       "      <td>18217.85</td>\n",
       "      <td>18112.90</td>\n",
       "      <td>0,51%</td>\n",
       "      <td>True</td>\n",
       "      <td>18255.5225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>18603.59</td>\n",
       "      <td>18640.63</td>\n",
       "      <td>18662.77</td>\n",
       "      <td>18492.47</td>\n",
       "      <td>-0,20%</td>\n",
       "      <td>True</td>\n",
       "      <td>18500.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>18469.38</td>\n",
       "      <td>18386.27</td>\n",
       "      <td>18480.01</td>\n",
       "      <td>18339.21</td>\n",
       "      <td>0,45%</td>\n",
       "      <td>True</td>\n",
       "      <td>18402.5740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>18566.51</td>\n",
       "      <td>18498.78</td>\n",
       "      <td>18622.63</td>\n",
       "      <td>18498.78</td>\n",
       "      <td>0,37%</td>\n",
       "      <td>True</td>\n",
       "      <td>18503.5040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>18938.30</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>19005.82</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>0,65%</td>\n",
       "      <td>True</td>\n",
       "      <td>18730.4080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   Dernier      Ouv.   Plus Haut  Plus Bas Variation %  \\\n",
       "0   2021-01-08  11249.14  11271.23    11298.06  11244.10      -0,20%   \n",
       "1   2021-01-15  11416.19  11326.79    11442.59  11315.60       0,79%   \n",
       "2   2021-01-22  11563.73  11514.99    11567.93  11499.44       0,42%   \n",
       "3   2021-01-29  11630.01  11657.63    11711.26  11630.01      -0,24%   \n",
       "4   2021-02-05  11713.50  11742.17    11778.18  11713.50      -0,24%   \n",
       "..         ...       ...       ...         ...       ...         ...   \n",
       "245 2025-11-21  18205.28  18112.94    18217.85  18112.90       0,51%   \n",
       "246 2025-11-28  18603.59  18640.63    18662.77  18492.47      -0,20%   \n",
       "247 2025-12-05  18469.38  18386.27    18480.01  18339.21       0,45%   \n",
       "248 2025-12-12  18566.51  18498.78    18622.63  18498.78       0,37%   \n",
       "249 2025-12-19  18938.30  18815.95    19005.82  18815.95       0,65%   \n",
       "\n",
       "     is_friday  weekly_mean  \n",
       "0         True   11266.1280  \n",
       "1         True   11325.5150  \n",
       "2         True   11508.4480  \n",
       "3         True   11667.5300  \n",
       "4         True   11710.7080  \n",
       "..         ...          ...  \n",
       "245       True   18255.5225  \n",
       "246       True   18500.0160  \n",
       "247       True   18402.5740  \n",
       "248       True   18503.5040  \n",
       "249       True   18730.4080  \n",
       "\n",
       "[250 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df[\"is_friday\"]]\n",
    "df_filtered = df_filtered.sort_values(by = \"Date\", ascending= True)\n",
    "df_filtered.reset_index(drop = True, inplace = True)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29e18f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Date         250 non-null    datetime64[ns]\n",
      " 1   Dernier      250 non-null    float64       \n",
      " 2   Ouv.         250 non-null    float64       \n",
      " 3    Plus Haut   250 non-null    float64       \n",
      " 4   Plus Bas     250 non-null    float64       \n",
      " 5   Variation %  250 non-null    object        \n",
      " 6   is_friday    250 non-null    bool          \n",
      " 7   weekly_mean  250 non-null    float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33b625b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dernier</th>\n",
       "      <th>Ouv.</th>\n",
       "      <th>Plus Haut</th>\n",
       "      <th>Plus Bas</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>is_friday</th>\n",
       "      <th>weekly_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>11249.14</td>\n",
       "      <td>11271.23</td>\n",
       "      <td>11298.06</td>\n",
       "      <td>11244.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11266.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>11416.19</td>\n",
       "      <td>11326.79</td>\n",
       "      <td>11442.59</td>\n",
       "      <td>11315.60</td>\n",
       "      <td>0.527129</td>\n",
       "      <td>True</td>\n",
       "      <td>11325.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>11563.73</td>\n",
       "      <td>11514.99</td>\n",
       "      <td>11567.93</td>\n",
       "      <td>11499.44</td>\n",
       "      <td>1.615229</td>\n",
       "      <td>True</td>\n",
       "      <td>11508.4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>11630.01</td>\n",
       "      <td>11657.63</td>\n",
       "      <td>11711.26</td>\n",
       "      <td>11630.01</td>\n",
       "      <td>1.382306</td>\n",
       "      <td>True</td>\n",
       "      <td>11667.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>11713.50</td>\n",
       "      <td>11742.17</td>\n",
       "      <td>11778.18</td>\n",
       "      <td>11713.50</td>\n",
       "      <td>0.370070</td>\n",
       "      <td>True</td>\n",
       "      <td>11710.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>18205.28</td>\n",
       "      <td>18112.94</td>\n",
       "      <td>18217.85</td>\n",
       "      <td>18112.90</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>True</td>\n",
       "      <td>18255.5225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>18603.59</td>\n",
       "      <td>18640.63</td>\n",
       "      <td>18662.77</td>\n",
       "      <td>18492.47</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>True</td>\n",
       "      <td>18500.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>18469.38</td>\n",
       "      <td>18386.27</td>\n",
       "      <td>18480.01</td>\n",
       "      <td>18339.21</td>\n",
       "      <td>-0.526713</td>\n",
       "      <td>True</td>\n",
       "      <td>18402.5740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>18566.51</td>\n",
       "      <td>18498.78</td>\n",
       "      <td>18622.63</td>\n",
       "      <td>18498.78</td>\n",
       "      <td>0.548456</td>\n",
       "      <td>True</td>\n",
       "      <td>18503.5040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2025-12-19</td>\n",
       "      <td>18938.30</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>19005.82</td>\n",
       "      <td>18815.95</td>\n",
       "      <td>1.226276</td>\n",
       "      <td>True</td>\n",
       "      <td>18730.4080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   Dernier      Ouv.   Plus Haut  Plus Bas  Variation %  \\\n",
       "0   2021-01-08  11249.14  11271.23    11298.06  11244.10          NaN   \n",
       "1   2021-01-15  11416.19  11326.79    11442.59  11315.60     0.527129   \n",
       "2   2021-01-22  11563.73  11514.99    11567.93  11499.44     1.615229   \n",
       "3   2021-01-29  11630.01  11657.63    11711.26  11630.01     1.382306   \n",
       "4   2021-02-05  11713.50  11742.17    11778.18  11713.50     0.370070   \n",
       "..         ...       ...       ...         ...       ...          ...   \n",
       "245 2025-11-21  18205.28  18112.94    18217.85  18112.90    -2.645324   \n",
       "246 2025-11-28  18603.59  18640.63    18662.77  18492.47     1.339285   \n",
       "247 2025-12-05  18469.38  18386.27    18480.01  18339.21    -0.526713   \n",
       "248 2025-12-12  18566.51  18498.78    18622.63  18498.78     0.548456   \n",
       "249 2025-12-19  18938.30  18815.95    19005.82  18815.95     1.226276   \n",
       "\n",
       "     is_friday  weekly_mean  \n",
       "0         True   11266.1280  \n",
       "1         True   11325.5150  \n",
       "2         True   11508.4480  \n",
       "3         True   11667.5300  \n",
       "4         True   11710.7080  \n",
       "..         ...          ...  \n",
       "245       True   18255.5225  \n",
       "246       True   18500.0160  \n",
       "247       True   18402.5740  \n",
       "248       True   18503.5040  \n",
       "249       True   18730.4080  \n",
       "\n",
       "[250 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure data is sorted by date\n",
    "df_filtered = df_filtered.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Compute weekly variation (week-over-week) in percentage (%)\n",
    "df_filtered[\"Variation %\"] = df_filtered[\"weekly_mean\"].pct_change()*100\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fc189b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_filtered.drop(columns = [\"Dernier\", \"Ouv.\", \" Plus Haut\", \"Plus Bas\", \"is_friday\"])\n",
    "df_final.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "213e01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"MASI_cleaned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85a639",
   "metadata": {},
   "source": [
    "# **Processing ATTIJARI DIVERSIFIE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c15c925b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Fonds</th>\n",
       "      <th>Horizon minimum conseillé</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25%</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.99%</td>\n",
       "      <td>0.55%</td>\n",
       "      <td>11.23%</td>\n",
       "      <td>9.21%</td>\n",
       "      <td>35.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96%</td>\n",
       "      <td>0.71%</td>\n",
       "      <td>6.43%</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>11.42%</td>\n",
       "      <td>9.34%</td>\n",
       "      <td>37.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>0.56%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>0.31%</td>\n",
       "      <td>11.49%</td>\n",
       "      <td>9.69%</td>\n",
       "      <td>37.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72%</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>7.23%</td>\n",
       "      <td>0.88%</td>\n",
       "      <td>11.53%</td>\n",
       "      <td>9.54%</td>\n",
       "      <td>37.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15%</td>\n",
       "      <td>0.23%</td>\n",
       "      <td>7.33%</td>\n",
       "      <td>2.47%</td>\n",
       "      <td>11.25%</td>\n",
       "      <td>10.05%</td>\n",
       "      <td>38.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90%</td>\n",
       "      <td>1.87%</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>13.26%</td>\n",
       "      <td>29.74%</td>\n",
       "      <td>35.37%</td>\n",
       "      <td>39.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11%</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>1.21%</td>\n",
       "      <td>11.56%</td>\n",
       "      <td>27.49%</td>\n",
       "      <td>32.53%</td>\n",
       "      <td>36.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>2.42%</td>\n",
       "      <td>13.34%</td>\n",
       "      <td>29.42%</td>\n",
       "      <td>33.47%</td>\n",
       "      <td>38.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92%</td>\n",
       "      <td>0.45%</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>13.14%</td>\n",
       "      <td>28.26%</td>\n",
       "      <td>31.91%</td>\n",
       "      <td>36.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>ATTIJARI DIVERSIFIE</td>\n",
       "      <td>4</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30%</td>\n",
       "      <td>0.33%</td>\n",
       "      <td>1.02%</td>\n",
       "      <td>13.64%</td>\n",
       "      <td>27.19%</td>\n",
       "      <td>33.33%</td>\n",
       "      <td>35.06%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                Fonds  Horizon minimum conseillé  \\\n",
       "0    2021-01-08  ATTIJARI DIVERSIFIE                          4   \n",
       "1    2021-01-15  ATTIJARI DIVERSIFIE                          4   \n",
       "2    2021-01-22  ATTIJARI DIVERSIFIE                          4   \n",
       "3    2021-01-29  ATTIJARI DIVERSIFIE                          4   \n",
       "4    2021-02-12  ATTIJARI DIVERSIFIE                          4   \n",
       "..          ...                  ...                        ...   \n",
       "244  2025-11-14  ATTIJARI DIVERSIFIE                          4   \n",
       "245  2025-11-21  ATTIJARI DIVERSIFIE                          4   \n",
       "246  2025-11-28  ATTIJARI DIVERSIFIE                          4   \n",
       "247  2025-12-05  ATTIJARI DIVERSIFIE                          4   \n",
       "248  2025-12-12  ATTIJARI DIVERSIFIE                          4   \n",
       "\n",
       "     Valeur Liquidative Performances glissantes Depuis Début d'année  \\\n",
       "0                539.68                                        0.25%   \n",
       "1                543.51                                        0.96%   \n",
       "2                546.53                                        1.52%   \n",
       "3                547.58                                        1.72%   \n",
       "4                549.92                                        2.15%   \n",
       "..                  ...                                          ...   \n",
       "244              726.77                                       13.90%   \n",
       "245              715.36                                       12.11%   \n",
       "246              723.81                                       13.43%   \n",
       "247              720.56                                       12.92%   \n",
       "248              722.94                                       13.30%   \n",
       "\n",
       "    Performances glissantes 1 semaine Performances glissantes 6 mois  \\\n",
       "0                               0.18%                          5.99%   \n",
       "1                               0.71%                          6.43%   \n",
       "2                               0.56%                          6.98%   \n",
       "3                               0.19%                          7.23%   \n",
       "4                               0.23%                          7.33%   \n",
       "..                                ...                            ...   \n",
       "244                             1.87%                          3.89%   \n",
       "245                             1.57%                          1.21%   \n",
       "246                             1.18%                          2.42%   \n",
       "247                             0.45%                          0.59%   \n",
       "248                             0.33%                          1.02%   \n",
       "\n",
       "    Performances glissantes 1 an Performances glissantes 2 ans  \\\n",
       "0                          0.55%                        11.23%   \n",
       "1                          0.26%                        11.42%   \n",
       "2                          0.31%                        11.49%   \n",
       "3                          0.88%                        11.53%   \n",
       "4                          2.47%                        11.25%   \n",
       "..                           ...                           ...   \n",
       "244                       13.26%                        29.74%   \n",
       "245                       11.56%                        27.49%   \n",
       "246                       13.34%                        29.42%   \n",
       "247                       13.14%                        28.26%   \n",
       "248                       13.64%                        27.19%   \n",
       "\n",
       "    Performances glissantes 3 ans Performances glissantes 5 ans  \n",
       "0                           9.21%                        35.94%  \n",
       "1                           9.34%                        37.15%  \n",
       "2                           9.69%                        37.75%  \n",
       "3                           9.54%                        37.77%  \n",
       "4                          10.05%                        38.14%  \n",
       "..                            ...                           ...  \n",
       "244                        35.37%                        39.45%  \n",
       "245                        32.53%                        36.14%  \n",
       "246                        33.47%                        38.04%  \n",
       "247                        31.91%                        36.83%  \n",
       "248                        33.33%                        35.06%  \n",
       "\n",
       "[249 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attijari = pd.read_csv(\"DIVERSIFIE_ALL.csv\", parse_dates=True)\n",
    "attijari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983b357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25%</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.99%</td>\n",
       "      <td>0.55%</td>\n",
       "      <td>11.23%</td>\n",
       "      <td>9.21%</td>\n",
       "      <td>35.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96%</td>\n",
       "      <td>0.71%</td>\n",
       "      <td>6.43%</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>11.42%</td>\n",
       "      <td>9.34%</td>\n",
       "      <td>37.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>0.56%</td>\n",
       "      <td>6.98%</td>\n",
       "      <td>0.31%</td>\n",
       "      <td>11.49%</td>\n",
       "      <td>9.69%</td>\n",
       "      <td>37.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72%</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>7.23%</td>\n",
       "      <td>0.88%</td>\n",
       "      <td>11.53%</td>\n",
       "      <td>9.54%</td>\n",
       "      <td>37.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15%</td>\n",
       "      <td>0.23%</td>\n",
       "      <td>7.33%</td>\n",
       "      <td>2.47%</td>\n",
       "      <td>11.25%</td>\n",
       "      <td>10.05%</td>\n",
       "      <td>38.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90%</td>\n",
       "      <td>1.87%</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>13.26%</td>\n",
       "      <td>29.74%</td>\n",
       "      <td>35.37%</td>\n",
       "      <td>39.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11%</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>1.21%</td>\n",
       "      <td>11.56%</td>\n",
       "      <td>27.49%</td>\n",
       "      <td>32.53%</td>\n",
       "      <td>36.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>2.42%</td>\n",
       "      <td>13.34%</td>\n",
       "      <td>29.42%</td>\n",
       "      <td>33.47%</td>\n",
       "      <td>38.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92%</td>\n",
       "      <td>0.45%</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>13.14%</td>\n",
       "      <td>28.26%</td>\n",
       "      <td>31.91%</td>\n",
       "      <td>36.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30%</td>\n",
       "      <td>0.33%</td>\n",
       "      <td>1.02%</td>\n",
       "      <td>13.64%</td>\n",
       "      <td>27.19%</td>\n",
       "      <td>33.33%</td>\n",
       "      <td>35.06%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Valeur Liquidative  \\\n",
       "0    2021-01-08              539.68   \n",
       "1    2021-01-15              543.51   \n",
       "2    2021-01-22              546.53   \n",
       "3    2021-01-29              547.58   \n",
       "4    2021-02-12              549.92   \n",
       "..          ...                 ...   \n",
       "244  2025-11-14              726.77   \n",
       "245  2025-11-21              715.36   \n",
       "246  2025-11-28              723.81   \n",
       "247  2025-12-05              720.56   \n",
       "248  2025-12-12              722.94   \n",
       "\n",
       "    Performances glissantes Depuis Début d'année  \\\n",
       "0                                          0.25%   \n",
       "1                                          0.96%   \n",
       "2                                          1.52%   \n",
       "3                                          1.72%   \n",
       "4                                          2.15%   \n",
       "..                                           ...   \n",
       "244                                       13.90%   \n",
       "245                                       12.11%   \n",
       "246                                       13.43%   \n",
       "247                                       12.92%   \n",
       "248                                       13.30%   \n",
       "\n",
       "    Performances glissantes 1 semaine Performances glissantes 6 mois  \\\n",
       "0                               0.18%                          5.99%   \n",
       "1                               0.71%                          6.43%   \n",
       "2                               0.56%                          6.98%   \n",
       "3                               0.19%                          7.23%   \n",
       "4                               0.23%                          7.33%   \n",
       "..                                ...                            ...   \n",
       "244                             1.87%                          3.89%   \n",
       "245                             1.57%                          1.21%   \n",
       "246                             1.18%                          2.42%   \n",
       "247                             0.45%                          0.59%   \n",
       "248                             0.33%                          1.02%   \n",
       "\n",
       "    Performances glissantes 1 an Performances glissantes 2 ans  \\\n",
       "0                          0.55%                        11.23%   \n",
       "1                          0.26%                        11.42%   \n",
       "2                          0.31%                        11.49%   \n",
       "3                          0.88%                        11.53%   \n",
       "4                          2.47%                        11.25%   \n",
       "..                           ...                           ...   \n",
       "244                       13.26%                        29.74%   \n",
       "245                       11.56%                        27.49%   \n",
       "246                       13.34%                        29.42%   \n",
       "247                       13.14%                        28.26%   \n",
       "248                       13.64%                        27.19%   \n",
       "\n",
       "    Performances glissantes 3 ans Performances glissantes 5 ans  \n",
       "0                           9.21%                        35.94%  \n",
       "1                           9.34%                        37.15%  \n",
       "2                           9.69%                        37.75%  \n",
       "3                           9.54%                        37.77%  \n",
       "4                          10.05%                        38.14%  \n",
       "..                            ...                           ...  \n",
       "244                        35.37%                        39.45%  \n",
       "245                        32.53%                        36.14%  \n",
       "246                        33.47%                        38.04%  \n",
       "247                        31.91%                        36.83%  \n",
       "248                        33.33%                        35.06%  \n",
       "\n",
       "[249 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attijari.drop(columns=[\"Fonds\",\t\"Horizon minimum conseillé\"], inplace = True)\n",
    "attijari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "589e8597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249 entries, 0 to 248\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Date                                          249 non-null    object \n",
      " 1   Valeur Liquidative                            249 non-null    float64\n",
      " 2   Performances glissantes Depuis Début d'année  249 non-null    object \n",
      " 3   Performances glissantes 1 semaine             249 non-null    object \n",
      " 4   Performances glissantes 6 mois                249 non-null    object \n",
      " 5   Performances glissantes 1 an                  249 non-null    object \n",
      " 6   Performances glissantes 2 ans                 249 non-null    object \n",
      " 7   Performances glissantes 3 ans                 249 non-null    object \n",
      " 8   Performances glissantes 5 ans                 249 non-null    object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 17.6+ KB\n"
     ]
    }
   ],
   "source": [
    "attijari.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99117e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_clean = [\"Performances glissantes Depuis Début d'année\",\t\"Performances glissantes 1 semaine\", \"Performances glissantes 6 mois\", \"Performances glissantes 1 an\", \"Performances glissantes 2 ans\",\t\"Performances glissantes 3 ans\", \"Performances glissantes 5 ans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d702010a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Valeur Liquidative  \\\n",
       "0    2021-01-08              539.68   \n",
       "1    2021-01-15              543.51   \n",
       "2    2021-01-22              546.53   \n",
       "3    2021-01-29              547.58   \n",
       "4    2021-02-12              549.92   \n",
       "..          ...                 ...   \n",
       "244  2025-11-14              726.77   \n",
       "245  2025-11-21              715.36   \n",
       "246  2025-11-28              723.81   \n",
       "247  2025-12-05              720.56   \n",
       "248  2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "244                                         13.90   \n",
       "245                                         12.11   \n",
       "246                                         13.43   \n",
       "247                                         12.92   \n",
       "248                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "244                               1.87                            3.89   \n",
       "245                               1.57                            1.21   \n",
       "246                               1.18                            2.42   \n",
       "247                               0.45                            0.59   \n",
       "248                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "244                         13.26                          29.74   \n",
       "245                         11.56                          27.49   \n",
       "246                         13.34                          29.42   \n",
       "247                         13.14                          28.26   \n",
       "248                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \n",
       "0                             9.21                          35.94  \n",
       "1                             9.34                          37.15  \n",
       "2                             9.69                          37.75  \n",
       "3                             9.54                          37.77  \n",
       "4                            10.05                          38.14  \n",
       "..                             ...                            ...  \n",
       "244                          35.37                          39.45  \n",
       "245                          32.53                          36.14  \n",
       "246                          33.47                          38.04  \n",
       "247                          31.91                          36.83  \n",
       "248                          33.33                          35.06  \n",
       "\n",
       "[249 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in columns_to_clean:\n",
    "    attijari[col] = (\n",
    "    attijari[col]\n",
    "    .str.replace(\"%\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "attijari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57954e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-01-08              539.68   \n",
       "1   2021-01-15              543.51   \n",
       "2   2021-01-22              546.53   \n",
       "3   2021-01-29              547.58   \n",
       "4   2021-02-12              549.92   \n",
       "..         ...                 ...   \n",
       "244 2025-11-14              726.77   \n",
       "245 2025-11-21              715.36   \n",
       "246 2025-11-28              723.81   \n",
       "247 2025-12-05              720.56   \n",
       "248 2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "244                                         13.90   \n",
       "245                                         12.11   \n",
       "246                                         13.43   \n",
       "247                                         12.92   \n",
       "248                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "244                               1.87                            3.89   \n",
       "245                               1.57                            1.21   \n",
       "246                               1.18                            2.42   \n",
       "247                               0.45                            0.59   \n",
       "248                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "244                         13.26                          29.74   \n",
       "245                         11.56                          27.49   \n",
       "246                         13.34                          29.42   \n",
       "247                         13.14                          28.26   \n",
       "248                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \n",
       "0                             9.21                          35.94  \n",
       "1                             9.34                          37.15  \n",
       "2                             9.69                          37.75  \n",
       "3                             9.54                          37.77  \n",
       "4                            10.05                          38.14  \n",
       "..                             ...                            ...  \n",
       "244                          35.37                          39.45  \n",
       "245                          32.53                          36.14  \n",
       "246                          33.47                          38.04  \n",
       "247                          31.91                          36.83  \n",
       "248                          33.33                          35.06  \n",
       "\n",
       "[249 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attijari[\"Date\"] = pd.to_datetime(attijari[\"Date\"])\n",
    "attijari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5a6dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attijari.to_csv(\"attijari_diversifie.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830a889",
   "metadata": {},
   "source": [
    "# **Merging MASI and Attijari data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04ecacb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>weekly_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11266.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "      <td>0.527129</td>\n",
       "      <td>11325.5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "      <td>1.615229</td>\n",
       "      <td>11508.4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "      <td>1.382306</td>\n",
       "      <td>11667.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "      <td>-0.827123</td>\n",
       "      <td>11613.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>18751.5620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>18255.5225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>18500.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "      <td>-0.526713</td>\n",
       "      <td>18402.5740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "      <td>0.548456</td>\n",
       "      <td>18503.5040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-01-08              539.68   \n",
       "1   2021-01-15              543.51   \n",
       "2   2021-01-22              546.53   \n",
       "3   2021-01-29              547.58   \n",
       "4   2021-02-12              549.92   \n",
       "..         ...                 ...   \n",
       "229 2025-11-14              726.77   \n",
       "230 2025-11-21              715.36   \n",
       "231 2025-11-28              723.81   \n",
       "232 2025-12-05              720.56   \n",
       "233 2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "229                                         13.90   \n",
       "230                                         12.11   \n",
       "231                                         13.43   \n",
       "232                                         12.92   \n",
       "233                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "229                               1.87                            3.89   \n",
       "230                               1.57                            1.21   \n",
       "231                               1.18                            2.42   \n",
       "232                               0.45                            0.59   \n",
       "233                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "229                         13.26                          29.74   \n",
       "230                         11.56                          27.49   \n",
       "231                         13.34                          29.42   \n",
       "232                         13.14                          28.26   \n",
       "233                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "0                             9.21                          35.94   \n",
       "1                             9.34                          37.15   \n",
       "2                             9.69                          37.75   \n",
       "3                             9.54                          37.77   \n",
       "4                            10.05                          38.14   \n",
       "..                             ...                            ...   \n",
       "229                          35.37                          39.45   \n",
       "230                          32.53                          36.14   \n",
       "231                          33.47                          38.04   \n",
       "232                          31.91                          36.83   \n",
       "233                          33.33                          35.06   \n",
       "\n",
       "     Variation %  weekly_mean  \n",
       "0       0.000000   11266.1280  \n",
       "1       0.527129   11325.5150  \n",
       "2       1.615229   11508.4480  \n",
       "3       1.382306   11667.5300  \n",
       "4      -0.827123   11613.8460  \n",
       "..           ...          ...  \n",
       "229    -3.772092   18751.5620  \n",
       "230    -2.645324   18255.5225  \n",
       "231     1.339285   18500.0160  \n",
       "232    -0.526713   18402.5740  \n",
       "233     0.548456   18503.5040  \n",
       "\n",
       "[234 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.merge(attijari, df_final, on = \"Date\", how = \"inner\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5888345",
   "metadata": {},
   "source": [
    "# **Feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c73c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ton DataFrame\n",
    "for lag in range(1, 5):\n",
    "    df_merged[f'rendement_lag_{lag}'] = df_merged['Performances glissantes 1 semaine'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "374c5b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>weekly_mean</th>\n",
       "      <th>rendement_lag_1</th>\n",
       "      <th>rendement_lag_2</th>\n",
       "      <th>rendement_lag_3</th>\n",
       "      <th>rendement_lag_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11266.1280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "      <td>0.527129</td>\n",
       "      <td>11325.5150</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "      <td>1.615229</td>\n",
       "      <td>11508.4480</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "      <td>1.382306</td>\n",
       "      <td>11667.5300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "      <td>-0.827123</td>\n",
       "      <td>11613.8460</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>18751.5620</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>18255.5225</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>18500.0160</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "      <td>-0.526713</td>\n",
       "      <td>18402.5740</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "      <td>0.548456</td>\n",
       "      <td>18503.5040</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-01-08              539.68   \n",
       "1   2021-01-15              543.51   \n",
       "2   2021-01-22              546.53   \n",
       "3   2021-01-29              547.58   \n",
       "4   2021-02-12              549.92   \n",
       "..         ...                 ...   \n",
       "229 2025-11-14              726.77   \n",
       "230 2025-11-21              715.36   \n",
       "231 2025-11-28              723.81   \n",
       "232 2025-12-05              720.56   \n",
       "233 2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "229                                         13.90   \n",
       "230                                         12.11   \n",
       "231                                         13.43   \n",
       "232                                         12.92   \n",
       "233                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "229                               1.87                            3.89   \n",
       "230                               1.57                            1.21   \n",
       "231                               1.18                            2.42   \n",
       "232                               0.45                            0.59   \n",
       "233                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "229                         13.26                          29.74   \n",
       "230                         11.56                          27.49   \n",
       "231                         13.34                          29.42   \n",
       "232                         13.14                          28.26   \n",
       "233                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "0                             9.21                          35.94   \n",
       "1                             9.34                          37.15   \n",
       "2                             9.69                          37.75   \n",
       "3                             9.54                          37.77   \n",
       "4                            10.05                          38.14   \n",
       "..                             ...                            ...   \n",
       "229                          35.37                          39.45   \n",
       "230                          32.53                          36.14   \n",
       "231                          33.47                          38.04   \n",
       "232                          31.91                          36.83   \n",
       "233                          33.33                          35.06   \n",
       "\n",
       "     Variation %  weekly_mean  rendement_lag_1  rendement_lag_2  \\\n",
       "0       0.000000   11266.1280              NaN              NaN   \n",
       "1       0.527129   11325.5150             0.18              NaN   \n",
       "2       1.615229   11508.4480             0.71             0.18   \n",
       "3       1.382306   11667.5300             0.56             0.71   \n",
       "4      -0.827123   11613.8460             0.19             0.56   \n",
       "..           ...          ...              ...              ...   \n",
       "229    -3.772092   18751.5620             0.94             0.89   \n",
       "230    -2.645324   18255.5225             1.87             0.94   \n",
       "231     1.339285   18500.0160             1.57             1.87   \n",
       "232    -0.526713   18402.5740             1.18             1.57   \n",
       "233     0.548456   18503.5040             0.45             1.18   \n",
       "\n",
       "     rendement_lag_3  rendement_lag_4  \n",
       "0                NaN              NaN  \n",
       "1                NaN              NaN  \n",
       "2                NaN              NaN  \n",
       "3               0.18              NaN  \n",
       "4               0.71             0.18  \n",
       "..               ...              ...  \n",
       "229             2.30             0.26  \n",
       "230             0.89             2.30  \n",
       "231             0.94             0.89  \n",
       "232             1.87             0.94  \n",
       "233             1.57             1.87  \n",
       "\n",
       "[234 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5964ea1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>weekly_mean</th>\n",
       "      <th>rendement_lag_1</th>\n",
       "      <th>rendement_lag_2</th>\n",
       "      <th>rendement_lag_3</th>\n",
       "      <th>rendement_lag_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11266.1280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "      <td>0.527129</td>\n",
       "      <td>11325.5150</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "      <td>1.615229</td>\n",
       "      <td>11508.4480</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "      <td>1.382306</td>\n",
       "      <td>11667.5300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "      <td>-0.827123</td>\n",
       "      <td>11613.8460</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>18751.5620</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>18255.5225</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>18500.0160</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "      <td>-0.526713</td>\n",
       "      <td>18402.5740</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "      <td>0.548456</td>\n",
       "      <td>18503.5040</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-01-08              539.68   \n",
       "1   2021-01-15              543.51   \n",
       "2   2021-01-22              546.53   \n",
       "3   2021-01-29              547.58   \n",
       "4   2021-02-12              549.92   \n",
       "..         ...                 ...   \n",
       "229 2025-11-14              726.77   \n",
       "230 2025-11-21              715.36   \n",
       "231 2025-11-28              723.81   \n",
       "232 2025-12-05              720.56   \n",
       "233 2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "229                                         13.90   \n",
       "230                                         12.11   \n",
       "231                                         13.43   \n",
       "232                                         12.92   \n",
       "233                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "229                               1.87                            3.89   \n",
       "230                               1.57                            1.21   \n",
       "231                               1.18                            2.42   \n",
       "232                               0.45                            0.59   \n",
       "233                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "229                         13.26                          29.74   \n",
       "230                         11.56                          27.49   \n",
       "231                         13.34                          29.42   \n",
       "232                         13.14                          28.26   \n",
       "233                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "0                             9.21                          35.94   \n",
       "1                             9.34                          37.15   \n",
       "2                             9.69                          37.75   \n",
       "3                             9.54                          37.77   \n",
       "4                            10.05                          38.14   \n",
       "..                             ...                            ...   \n",
       "229                          35.37                          39.45   \n",
       "230                          32.53                          36.14   \n",
       "231                          33.47                          38.04   \n",
       "232                          31.91                          36.83   \n",
       "233                          33.33                          35.06   \n",
       "\n",
       "     Variation %  weekly_mean  rendement_lag_1  rendement_lag_2  \\\n",
       "0       0.000000   11266.1280              NaN              NaN   \n",
       "1       0.527129   11325.5150             0.18              NaN   \n",
       "2       1.615229   11508.4480             0.71             0.18   \n",
       "3       1.382306   11667.5300             0.56             0.71   \n",
       "4      -0.827123   11613.8460             0.19             0.56   \n",
       "..           ...          ...              ...              ...   \n",
       "229    -3.772092   18751.5620             0.94             0.89   \n",
       "230    -2.645324   18255.5225             1.87             0.94   \n",
       "231     1.339285   18500.0160             1.57             1.87   \n",
       "232    -0.526713   18402.5740             1.18             1.57   \n",
       "233     0.548456   18503.5040             0.45             1.18   \n",
       "\n",
       "     rendement_lag_3  rendement_lag_4  \n",
       "0                NaN              NaN  \n",
       "1                NaN              NaN  \n",
       "2                NaN              NaN  \n",
       "3               0.18              NaN  \n",
       "4               0.71             0.18  \n",
       "..               ...              ...  \n",
       "229             2.30             0.26  \n",
       "230             0.89             2.30  \n",
       "231             0.94             0.89  \n",
       "232             1.87             0.94  \n",
       "233             1.57             1.87  \n",
       "\n",
       "[234 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged = df_merged.copy()\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efc82561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0018\n",
       "1      0.0071\n",
       "2      0.0056\n",
       "3      0.0019\n",
       "4      0.0023\n",
       "        ...  \n",
       "229    0.0187\n",
       "230    0.0157\n",
       "231    0.0118\n",
       "232    0.0045\n",
       "233    0.0033\n",
       "Name: returns, Length: 234, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged['returns'] = df_lagged['Performances glissantes 1 semaine'] / 100\n",
    "\n",
    "# Remove missing values\n",
    "returns = df_lagged['returns'].dropna()\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cb090e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Projet_Data_Science\\Mesure-et-gestion-du-risque-des-portefeuilles-OPCVM-l-aide-de-la-Data-Science\\venv_gestion_risque\\Lib\\site-packages\\arch\\univariate\\base.py:694: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 4.029e-05. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 100 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  self._check_scale(resids)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "garch = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='GARCH',\n",
    "    p=1,\n",
    "    q=1,\n",
    "    dist='normal'   # or 't' (often better in finance)\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "garch_result = garch.fit(disp=\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae84317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>weekly_mean</th>\n",
       "      <th>rendement_lag_1</th>\n",
       "      <th>rendement_lag_2</th>\n",
       "      <th>rendement_lag_3</th>\n",
       "      <th>rendement_lag_4</th>\n",
       "      <th>returns</th>\n",
       "      <th>garch_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11266.1280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.005041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "      <td>0.527129</td>\n",
       "      <td>11325.5150</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.005625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "      <td>1.615229</td>\n",
       "      <td>11508.4480</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.005751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "      <td>1.382306</td>\n",
       "      <td>11667.5300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "      <td>-0.827123</td>\n",
       "      <td>11613.8460</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.005896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>18751.5620</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.006384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>18255.5225</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.007349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>18500.0160</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.007228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "      <td>-0.526713</td>\n",
       "      <td>18402.5740</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.006714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "      <td>0.548456</td>\n",
       "      <td>18503.5040</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.006186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-01-08              539.68   \n",
       "1   2021-01-15              543.51   \n",
       "2   2021-01-22              546.53   \n",
       "3   2021-01-29              547.58   \n",
       "4   2021-02-12              549.92   \n",
       "..         ...                 ...   \n",
       "229 2025-11-14              726.77   \n",
       "230 2025-11-21              715.36   \n",
       "231 2025-11-28              723.81   \n",
       "232 2025-12-05              720.56   \n",
       "233 2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "229                                         13.90   \n",
       "230                                         12.11   \n",
       "231                                         13.43   \n",
       "232                                         12.92   \n",
       "233                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "229                               1.87                            3.89   \n",
       "230                               1.57                            1.21   \n",
       "231                               1.18                            2.42   \n",
       "232                               0.45                            0.59   \n",
       "233                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "229                         13.26                          29.74   \n",
       "230                         11.56                          27.49   \n",
       "231                         13.34                          29.42   \n",
       "232                         13.14                          28.26   \n",
       "233                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "0                             9.21                          35.94   \n",
       "1                             9.34                          37.15   \n",
       "2                             9.69                          37.75   \n",
       "3                             9.54                          37.77   \n",
       "4                            10.05                          38.14   \n",
       "..                             ...                            ...   \n",
       "229                          35.37                          39.45   \n",
       "230                          32.53                          36.14   \n",
       "231                          33.47                          38.04   \n",
       "232                          31.91                          36.83   \n",
       "233                          33.33                          35.06   \n",
       "\n",
       "     Variation %  weekly_mean  rendement_lag_1  rendement_lag_2  \\\n",
       "0       0.000000   11266.1280              NaN              NaN   \n",
       "1       0.527129   11325.5150             0.18              NaN   \n",
       "2       1.615229   11508.4480             0.71             0.18   \n",
       "3       1.382306   11667.5300             0.56             0.71   \n",
       "4      -0.827123   11613.8460             0.19             0.56   \n",
       "..           ...          ...              ...              ...   \n",
       "229    -3.772092   18751.5620             0.94             0.89   \n",
       "230    -2.645324   18255.5225             1.87             0.94   \n",
       "231     1.339285   18500.0160             1.57             1.87   \n",
       "232    -0.526713   18402.5740             1.18             1.57   \n",
       "233     0.548456   18503.5040             0.45             1.18   \n",
       "\n",
       "     rendement_lag_3  rendement_lag_4  returns  garch_vol  \n",
       "0                NaN              NaN   0.0018   0.005041  \n",
       "1                NaN              NaN   0.0071   0.005625  \n",
       "2                NaN              NaN   0.0056   0.005751  \n",
       "3               0.18              NaN   0.0019   0.005777  \n",
       "4               0.71             0.18   0.0023   0.005896  \n",
       "..               ...              ...      ...        ...  \n",
       "229             2.30             0.26   0.0187   0.006384  \n",
       "230             0.89             2.30   0.0157   0.007349  \n",
       "231             0.94             0.89   0.0118   0.007228  \n",
       "232             1.87             0.94   0.0045   0.006714  \n",
       "233             1.57             1.87   0.0033   0.006186  \n",
       "\n",
       "[234 rows x 17 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional volatility (σ_t)\n",
    "df_lagged.loc[returns.index, 'garch_vol'] = garch_result.conditional_volatility\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eade53f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>weekly_mean</th>\n",
       "      <th>rendement_lag_1</th>\n",
       "      <th>rendement_lag_2</th>\n",
       "      <th>rendement_lag_3</th>\n",
       "      <th>rendement_lag_4</th>\n",
       "      <th>returns</th>\n",
       "      <th>garch_vol</th>\n",
       "      <th>garch_vol_lag_1</th>\n",
       "      <th>garch_vol_lag_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11266.1280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "      <td>0.527129</td>\n",
       "      <td>11325.5150</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "      <td>1.615229</td>\n",
       "      <td>11508.4480</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.005041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "      <td>1.382306</td>\n",
       "      <td>11667.5300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.005625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "      <td>-0.827123</td>\n",
       "      <td>11613.8460</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>18751.5620</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>18255.5225</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>18500.0160</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "      <td>-0.526713</td>\n",
       "      <td>18402.5740</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.007349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "      <td>0.548456</td>\n",
       "      <td>18503.5040</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.007228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-01-08              539.68   \n",
       "1   2021-01-15              543.51   \n",
       "2   2021-01-22              546.53   \n",
       "3   2021-01-29              547.58   \n",
       "4   2021-02-12              549.92   \n",
       "..         ...                 ...   \n",
       "229 2025-11-14              726.77   \n",
       "230 2025-11-21              715.36   \n",
       "231 2025-11-28              723.81   \n",
       "232 2025-12-05              720.56   \n",
       "233 2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "229                                         13.90   \n",
       "230                                         12.11   \n",
       "231                                         13.43   \n",
       "232                                         12.92   \n",
       "233                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "229                               1.87                            3.89   \n",
       "230                               1.57                            1.21   \n",
       "231                               1.18                            2.42   \n",
       "232                               0.45                            0.59   \n",
       "233                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "229                         13.26                          29.74   \n",
       "230                         11.56                          27.49   \n",
       "231                         13.34                          29.42   \n",
       "232                         13.14                          28.26   \n",
       "233                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "0                             9.21                          35.94   \n",
       "1                             9.34                          37.15   \n",
       "2                             9.69                          37.75   \n",
       "3                             9.54                          37.77   \n",
       "4                            10.05                          38.14   \n",
       "..                             ...                            ...   \n",
       "229                          35.37                          39.45   \n",
       "230                          32.53                          36.14   \n",
       "231                          33.47                          38.04   \n",
       "232                          31.91                          36.83   \n",
       "233                          33.33                          35.06   \n",
       "\n",
       "     Variation %  weekly_mean  rendement_lag_1  rendement_lag_2  \\\n",
       "0       0.000000   11266.1280              NaN              NaN   \n",
       "1       0.527129   11325.5150             0.18              NaN   \n",
       "2       1.615229   11508.4480             0.71             0.18   \n",
       "3       1.382306   11667.5300             0.56             0.71   \n",
       "4      -0.827123   11613.8460             0.19             0.56   \n",
       "..           ...          ...              ...              ...   \n",
       "229    -3.772092   18751.5620             0.94             0.89   \n",
       "230    -2.645324   18255.5225             1.87             0.94   \n",
       "231     1.339285   18500.0160             1.57             1.87   \n",
       "232    -0.526713   18402.5740             1.18             1.57   \n",
       "233     0.548456   18503.5040             0.45             1.18   \n",
       "\n",
       "     rendement_lag_3  rendement_lag_4  returns  garch_vol  garch_vol_lag_1  \\\n",
       "0                NaN              NaN   0.0018   0.005041              NaN   \n",
       "1                NaN              NaN   0.0071   0.005625         0.005041   \n",
       "2                NaN              NaN   0.0056   0.005751         0.005625   \n",
       "3               0.18              NaN   0.0019   0.005777         0.005751   \n",
       "4               0.71             0.18   0.0023   0.005896         0.005777   \n",
       "..               ...              ...      ...        ...              ...   \n",
       "229             2.30             0.26   0.0187   0.006384         0.006902   \n",
       "230             0.89             2.30   0.0157   0.007349         0.006384   \n",
       "231             0.94             0.89   0.0118   0.007228         0.007349   \n",
       "232             1.87             0.94   0.0045   0.006714         0.007228   \n",
       "233             1.57             1.87   0.0033   0.006186         0.006714   \n",
       "\n",
       "     garch_vol_lag_2  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2           0.005041  \n",
       "3           0.005625  \n",
       "4           0.005751  \n",
       "..               ...  \n",
       "229         0.008109  \n",
       "230         0.006902  \n",
       "231         0.006384  \n",
       "232         0.007349  \n",
       "233         0.007228  \n",
       "\n",
       "[234 rows x 19 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged['garch_vol_lag_1'] = df_lagged['garch_vol'].shift(1)\n",
    "df_lagged['garch_vol_lag_2'] = df_lagged['garch_vol'].shift(2)\n",
    "df_lagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43d15d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>weekly_mean</th>\n",
       "      <th>rendement_lag_1</th>\n",
       "      <th>rendement_lag_2</th>\n",
       "      <th>rendement_lag_3</th>\n",
       "      <th>rendement_lag_4</th>\n",
       "      <th>returns</th>\n",
       "      <th>garch_vol</th>\n",
       "      <th>garch_vol_lag_1</th>\n",
       "      <th>garch_vol_lag_2</th>\n",
       "      <th>vol_future_2w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>539.68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.23</td>\n",
       "      <td>9.21</td>\n",
       "      <td>35.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11266.1280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>543.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.42</td>\n",
       "      <td>9.34</td>\n",
       "      <td>37.15</td>\n",
       "      <td>0.527129</td>\n",
       "      <td>11325.5150</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>546.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.49</td>\n",
       "      <td>9.69</td>\n",
       "      <td>37.75</td>\n",
       "      <td>1.615229</td>\n",
       "      <td>11508.4480</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.002110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>547.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.53</td>\n",
       "      <td>9.54</td>\n",
       "      <td>37.77</td>\n",
       "      <td>1.382306</td>\n",
       "      <td>11667.5300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "      <td>-0.827123</td>\n",
       "      <td>11613.8460</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.004610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>18751.5620</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.013888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>18255.5225</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>18500.0160</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.003946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2025-12-05</td>\n",
       "      <td>720.56</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>13.14</td>\n",
       "      <td>28.26</td>\n",
       "      <td>31.91</td>\n",
       "      <td>36.83</td>\n",
       "      <td>-0.526713</td>\n",
       "      <td>18402.5740</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>722.94</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.19</td>\n",
       "      <td>33.33</td>\n",
       "      <td>35.06</td>\n",
       "      <td>0.548456</td>\n",
       "      <td>18503.5040</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-01-08              539.68   \n",
       "1   2021-01-15              543.51   \n",
       "2   2021-01-22              546.53   \n",
       "3   2021-01-29              547.58   \n",
       "4   2021-02-12              549.92   \n",
       "..         ...                 ...   \n",
       "229 2025-11-14              726.77   \n",
       "230 2025-11-21              715.36   \n",
       "231 2025-11-28              723.81   \n",
       "232 2025-12-05              720.56   \n",
       "233 2025-12-12              722.94   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            0.25   \n",
       "1                                            0.96   \n",
       "2                                            1.52   \n",
       "3                                            1.72   \n",
       "4                                            2.15   \n",
       "..                                            ...   \n",
       "229                                         13.90   \n",
       "230                                         12.11   \n",
       "231                                         13.43   \n",
       "232                                         12.92   \n",
       "233                                         13.30   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.18                            5.99   \n",
       "1                                 0.71                            6.43   \n",
       "2                                 0.56                            6.98   \n",
       "3                                 0.19                            7.23   \n",
       "4                                 0.23                            7.33   \n",
       "..                                 ...                             ...   \n",
       "229                               1.87                            3.89   \n",
       "230                               1.57                            1.21   \n",
       "231                               1.18                            2.42   \n",
       "232                               0.45                            0.59   \n",
       "233                               0.33                            1.02   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            0.55                          11.23   \n",
       "1                            0.26                          11.42   \n",
       "2                            0.31                          11.49   \n",
       "3                            0.88                          11.53   \n",
       "4                            2.47                          11.25   \n",
       "..                            ...                            ...   \n",
       "229                         13.26                          29.74   \n",
       "230                         11.56                          27.49   \n",
       "231                         13.34                          29.42   \n",
       "232                         13.14                          28.26   \n",
       "233                         13.64                          27.19   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "0                             9.21                          35.94   \n",
       "1                             9.34                          37.15   \n",
       "2                             9.69                          37.75   \n",
       "3                             9.54                          37.77   \n",
       "4                            10.05                          38.14   \n",
       "..                             ...                            ...   \n",
       "229                          35.37                          39.45   \n",
       "230                          32.53                          36.14   \n",
       "231                          33.47                          38.04   \n",
       "232                          31.91                          36.83   \n",
       "233                          33.33                          35.06   \n",
       "\n",
       "     Variation %  weekly_mean  rendement_lag_1  rendement_lag_2  \\\n",
       "0       0.000000   11266.1280              NaN              NaN   \n",
       "1       0.527129   11325.5150             0.18              NaN   \n",
       "2       1.615229   11508.4480             0.71             0.18   \n",
       "3       1.382306   11667.5300             0.56             0.71   \n",
       "4      -0.827123   11613.8460             0.19             0.56   \n",
       "..           ...          ...              ...              ...   \n",
       "229    -3.772092   18751.5620             0.94             0.89   \n",
       "230    -2.645324   18255.5225             1.87             0.94   \n",
       "231     1.339285   18500.0160             1.57             1.87   \n",
       "232    -0.526713   18402.5740             1.18             1.57   \n",
       "233     0.548456   18503.5040             0.45             1.18   \n",
       "\n",
       "     rendement_lag_3  rendement_lag_4  returns  garch_vol  garch_vol_lag_1  \\\n",
       "0                NaN              NaN   0.0018   0.005041              NaN   \n",
       "1                NaN              NaN   0.0071   0.005625         0.005041   \n",
       "2                NaN              NaN   0.0056   0.005751         0.005625   \n",
       "3               0.18              NaN   0.0019   0.005777         0.005751   \n",
       "4               0.71             0.18   0.0023   0.005896         0.005777   \n",
       "..               ...              ...      ...        ...              ...   \n",
       "229             2.30             0.26   0.0187   0.006384         0.006902   \n",
       "230             0.89             2.30   0.0157   0.007349         0.006384   \n",
       "231             0.94             0.89   0.0118   0.007228         0.007349   \n",
       "232             1.87             0.94   0.0045   0.006714         0.007228   \n",
       "233             1.57             1.87   0.0033   0.006186         0.006714   \n",
       "\n",
       "     garch_vol_lag_2  vol_future_2w  \n",
       "0                NaN       0.006394  \n",
       "1                NaN       0.004182  \n",
       "2           0.005041       0.002110  \n",
       "3           0.005625       0.002300  \n",
       "4           0.005751       0.004610  \n",
       "..               ...            ...  \n",
       "229         0.008109       0.013888  \n",
       "230         0.006902       0.008930  \n",
       "231         0.006384       0.003946  \n",
       "232         0.007349            NaN  \n",
       "233         0.007228            NaN  \n",
       "\n",
       "[234 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute future squared returns\n",
    "future_sq_returns = returns.shift(-1)**2 + returns.shift(-2)**2\n",
    "\n",
    "# Compute 2-week future volatility\n",
    "df_lagged['vol_future_2w'] = np.sqrt(future_sq_returns / 2)\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "543dd9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                            0\n",
       "Valeur Liquidative                              0\n",
       "Performances glissantes Depuis Début d'année    0\n",
       "Performances glissantes 1 semaine               0\n",
       "Performances glissantes 6 mois                  0\n",
       "Performances glissantes 1 an                    0\n",
       "Performances glissantes 2 ans                   0\n",
       "Performances glissantes 3 ans                   0\n",
       "Performances glissantes 5 ans                   0\n",
       "Variation %                                     0\n",
       "weekly_mean                                     0\n",
       "rendement_lag_1                                 1\n",
       "rendement_lag_2                                 2\n",
       "rendement_lag_3                                 3\n",
       "rendement_lag_4                                 4\n",
       "returns                                         0\n",
       "garch_vol                                       0\n",
       "garch_vol_lag_1                                 1\n",
       "garch_vol_lag_2                                 2\n",
       "vol_future_2w                                   2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cb65735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                            0\n",
       "Valeur Liquidative                              0\n",
       "Performances glissantes Depuis Début d'année    0\n",
       "Performances glissantes 1 semaine               0\n",
       "Performances glissantes 6 mois                  0\n",
       "Performances glissantes 1 an                    0\n",
       "Performances glissantes 2 ans                   0\n",
       "Performances glissantes 3 ans                   0\n",
       "Performances glissantes 5 ans                   0\n",
       "Variation %                                     0\n",
       "weekly_mean                                     0\n",
       "rendement_lag_1                                 0\n",
       "rendement_lag_2                                 0\n",
       "rendement_lag_3                                 0\n",
       "rendement_lag_4                                 0\n",
       "returns                                         0\n",
       "garch_vol                                       0\n",
       "garch_vol_lag_1                                 0\n",
       "garch_vol_lag_2                                 0\n",
       "vol_future_2w                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged.dropna(inplace = True)\n",
    "df_lagged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6794809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFEAAAL9CAYAAADjF/kIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAApi1JREFUeJzs3Qm8TdX///FlKHMZMyskmcpQFKXIlJkGNJhK+aZUJBoMlWii0KDJVCkNhiJRipAhRaXIFImQmczZ/8d7/b77/u8999K+femetbyej8f53nP3vd+ctc+55+z92Z8hXRAEgQEAAAAAAMBxpT/+jwEAAAAAAEAQBQAAAAAAICIyUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAJ0C6dOlMv379Tvi+POecc0z79u2ND07WPjoRrrzySlO+fPm0fhgAACDOEUQBAOC/Ro0aZU/0dZszZ06y/RIEgSlatKj9eePGjdlvOCFefPFF+9oDAADxL2NaPwAAAOJN5syZzdixY81ll12WZPusWbPMb7/9ZjJlypTs/7N//36TMeOJ/1j9+eefTfr0XPPwPYiSN29ebzKOAADwGUdlAADEaNiwoXnvvffMkSNHkmxXYKVKlSqmQIECKQZeTkYQRQGb0047jecIAAAgDhBEAQAgRps2bcy2bdvMp59+mrDt0KFD5v333zc33HBDpH4fe/bsMffcc4/taaJAyFlnnWXq1q1rvv3224TfWblypbnmmmtsUEZBmCJFipjWrVubXbt2HbMnSlhyNHfuXNOtWzeTL18+ky1bNtOiRQvzxx9/JHlMR48etY+pUKFCJmvWrKZWrVrmp59++ts+K4cPHza5c+c2HTp0SPaz3bt328d63333JeyXPn362ODSmWeeaR/L5Zdfbr744ou/fV3pMeixxNJj1hpjvfnmm/bfyZIli3182lfr169P8jtR9unxaP9oP2l/FS5c2Dz11FPJfufgwYOmb9++5txzz7XPrUq87r//frs9sZEjR5ratWvb516/V7ZsWfPSSy8l+R2t/8cff7RZTmEpmfqzJH6uVVrWtWtX+1znzJnT3H777Xa/79y507Rt29bkypXL3vQYVHKW2DPPPGOqV69u8uTJY/eb9p9ex7H079x5553mrbfeMqVLl7b7Tr/75ZdfRtpvAACcKijnAQAghk5sL730UvP222+bq6++2m6bOnWqPRHXCfnQoUP/dp917tzZnqzqxFQnzwrK6GR42bJlpnLlyvYkuH79+vbE+6677rIn/Rs2bDCTJ0+2J8cKSByP/j86cdbJ/Nq1a81zzz1n/61x48Yl/M4DDzxggwBNmjSx/9Z3331nvx44cOC4/21lvigoM378ePPyyy+b008/PeFnEydOtI9Z+yEMqrz22ms28NSpUycbPHr99dftv7Nw4UJTsWLFE/L6evzxx03v3r3N9ddfb2699VYbMBo2bJipWbOmWbx4sQ0u/K/7dMeOHaZBgwamZcuW9t/R89ezZ09ToUKFhNeBAlNNmza1z+Vtt91mypQpY3744Qfz7LPPmhUrVtj9E1LApFy5cvb3laX00UcfmTvuuMP+N7p06WJ/R8+bHmv27NnNQw89ZLflz58/yeMK1/LII4+Y+fPnm1deecWu96uvvjLFihUzAwYMMB9//LF5+umnbXNcBVZCQ4YMsf/+jTfeaPfPO++8Y6677jq7Txo1apTk31EgR68fBWwU9FGZkfaHnkea7gIA8F8BAACwRo4cqcv4wddffx08//zzQY4cOYJ9+/bZn1133XVBrVq17P2zzz47aNSoUZK9pv9f3759E74/88wzgy5duhxzzy5evNj+f957773j7n39W+3atUv2GOvUqRMcPXo0Yfu9994bZMiQIdi5c6f9ftOmTUHGjBmD5s2bJ/nv9evXz/7/E/83UzJt2jT7ex999FGS7Q0bNgxKlCiR8P2RI0eCgwcPJvmdHTt2BPnz5w86dux43H2kx6D1xdLvJD5EWbt2rV3b448/nuT3fvjhB7vGcHvUfZqSK664wv5/x4wZk7BN6ypQoEBwzTXXJGx74403gvTp0wezZ89O8v8fPny4/f/PnTs3YVv42kmsfv36SfaflCtXzv77scLnWv+fxM/1pZdeGqRLly7o3LlzkuehSJEiyf47sY/h0KFDQfny5YPatWsn2a5/R7dFixYlbFu3bl2QOXPmoEWLFskeGwAApyrKeQAASIEyEdQsVlfslV2hr8cq5UmJMgUWLFhgNm7cmOLPw6yIadOmmX379qX6OVAWROKSF5XQ/PXXX2bdunX2+xkzZtieLsp8iM1qiEJlKGp2mjizRZkaKnFq1apVwrYMGTIkZKoow2L79u32373ooouSlC79L5QRo/+2npOtW7cm3JSdUapUqYTSof91nyob5Kabbkr4XuuqWrWqWbNmTcI29cpR9sn555+f5LFof0niMiaVz4SUxaTfu+KKK+x/L2p5kdxyyy1Jnutq1arZsh1tT/w8aJ8nfqyxj0HPn/5dvVZSem6UfaUSnpCyXJo1a2b3p15bAACAnigAAKRI/Sfq1Kljm8nqJF4nkddee23kvaUymqVLl9p+GToRV5+PxCe4xYsXtz1NVAqjYIXKUF544YXIJ9c6wU1MpT3hibKEwRT17UhMvUTC3z0elZ+ot8ikSZMSen1oP6hfSuIgiowePdpccMEFto+Gem9o302ZMiVVgYLjUZ8TBQ0UMNF/O/FN5VFbtmw5IftU/VNie7FoX4X7NHws6mES+zjOO+88+/PwsYj61ug1pD4xCqrp9x588EH7s9Tsm9jnOgwW6bUVuz3xYxUF/y655BL73Oi512NQmVFK/772byytSwGp2H47AACcquiJAgDAMSjzRH0+Nm3aZHti6EQ4KmVN6Ir/hAkTzPTp022/iieffNIGIsL+GoMGDbLNVRWo0O+oF8XAgQNt3wud0B+PMg9SEttY9H+hvifqiaJ+MM2bNzfvvvuuzcC48MILkzR71Rr08x49etgmqnpsWsfq1auP+99PqXmsxGY9KAtFv6vHkdK6lUESOtn7VI9FPVIGDx6c4u+GgQ2t/aqrrrL7S7+r7cpsUe8S9U/RfyeqYz2ulLYnfqyzZ8+2/VDUN0b9TQoWLGj73ajhrYKDAAAg9QiiAABwDGquqkkoOgFPXNYSlU5aVU6jmzIU1FBWDVLDIIrohFy3hx9+2DYKrVGjhhk+fLjp37////S8nH322fbrqlWrbIZGSA1uY7MVjkUn31qD1n7ZZZeZzz//PKH5aUjNV0uUKGGDQ4mDImp4+3eU5aGGr7HCLJpQyZIlbXBA6wgzPo7nZO3T8LGoQa8CJMcKAomayCqD58MPP0ySSZLS1KLj/Xf+Fx988IHNQFE5jhrFhhRESYmybGKpWa4mFSmDBQAAUM4DAMAxKcNBpQ8qxdGEm6iUSRFbLqEMDY0aDktjNNVGvUMS04l/+vTpk43K/Sd0kq+SnNiRus8//3zk/4Yei0qYFBB444037OONLeUJsyESZ0CoF8y8efMiBSS0n77//vuEbb///rvN3klM03L072g6TWymjb5XYOjf2KdhhpEm/rz66qvJfqYeOn/++ecx94vWmlIAQ+U+KQWT/ld6DArQJM7s0SSnxBOEEtNzlrhXisZHK6OnXr16x8yGAQDgVEMmCgAAx9GuXbtU7x81olXpiAIQKn1RMOazzz4zX3/9tS03EWV1aCSxxs0qu0In/wpU6GRVvUj+VxqTe/fdd9t/TyUdGlWrDAqVxKhfSNTsBwVNNEpYmSUKSKipamKNGze2WSjK2tHI3F9++cVmfWis8969e/+2XEgjhPX/VdmNem8o6KP9kfhkXsEWZZFoZLOCACodypEjh/23FHBRk9377rvvpO9Tufnmm21Zk0ZYK6tEWS4KUixfvtxuV9aHGrwq8KDyHQXflM2kfaHAi4JpChQlpmauWrfWqB42+p2wUe3/Qs+HSon03Ks0TdlQ6hGjfyNx4CqkMcbqI5N4xLEoeAUAAP4PQRQAAE4wlT+ohEc9OcLJMjpx1Unpf/7zH/s7Cq7ohFVZHsps0P9H2xTkUCPQE0E9WPTf1cm7gjiavqLHpNIclXlEUb16ddvPQ1kJsVkoov4j6hmj3ikKICh4oj4pmmIzc+bM4/631YRWQRA1g73//vttuY76l6isJHZ6TK9evWxgRP1EwpN6PS4FKxQk+rf2qbJalMmhxzFmzBj7+PXvqKRJQauw3Kh06dK21EklRQrwaJKQnnuVxXTs2DHJf7NPnz62hEnNiBWA0wSfExFE0X/j9ddfN0888YS555577P7Va0KBqJSCKPp39RrR/v3111/tczlq1CjbNBgAAPyfdJpz/N/7AADAcyobUS8SZT3E9jfBqUuZSV26dElVuRcAAKei9Gn9AAAAwMmhHh2xnnvuOfv1yiuvZLcDAACkEuU8AAB4SlN1VI7RsGFD25dlzpw55u2337YlMOrlAQAAgNQhiAIAgKfUy0ITetRrQ5NrwmazJ2LULwAAwKmInigAAAAAAAAR0BMFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAOJGNZTOeXjjqrwIAAAAAADjjyKENkX6PTBQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAIIgCAAAAAABwYpCJAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAREEQBAAAAAACIgCAKAAAAAABABARRAAAAAAAAIiCIAgAAAAAAEAFBFAAAAAAAgAgIogAAAAAAAERAEAUAAAAAACACgigAAAAAAAAEUQAAAAAAAE4MMlEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAIAKCKAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAEAEBFEAAAAAAAAiIIgCAAAAAAAQAUEUAAAAAACACAiiAAAAAAAAREAQBQAAAAAAgCAKAAAAAADAiUEmCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgCgAAAAAAQAQEUQAAAAAAACIgiAIAAAAAABABQRQAAAAAAIAICKIAAAAAAABEQBAFAAAAAAAgiiDOHDhwIOjbt6/96hNf1+Xz2liXW3x9vnxeG+tyi6/Pl89rY11u8fX58nltrMstvj5fPq/tQJyuK53+x8SR3bt3mzPPPNPs2rXLnHHGGcYXvq7L57WxLrf4+nz5vDbW5RZfny+f18a63OLr8+Xz2liXW3x9vnxe2+44XRflPAAAAAAAABEQRAEAAAAAAIiAIAoAAAAAAICLQZRMmTKZvn372q8+8XVdPq+NdbnF1+fL57WxLrf4+nz5vDbW5RZfny+f18a63OLr8+Xz2jLF6brirrEsAAAAAABAPIq7TBQAAAAAAIB4RBAFAAAAAAAgAoIoAAAAAAAAERBEAQAAAAAAiIAgykm2atUqM23aNLN//377vS99fHfu3Glee+0188ADD5jt27fbbd9++63ZsGFDWj80wDu7d+82EydONMuWLTM+YV3umDJliunRo4fp1q2b+eCDD9L64QAAAKQZgignybZt20ydOnXMeeedZxo2bGh+//13u/2WW24x3bt3Ny77/vvv7bqefPJJ88wzz9iAiowfP94GVVw2e/Zsc9NNN5lLL700ISD0xhtvmDlz5hhXjR492p4Ahe6//36TM2dOU716dbNu3Trjqj///NP07t3bruPcc881JUqUSHJz2fXXX2+ef/55e18B2Isuushuu+CCC5w+gWVdbtLfmd430qVLZy8E3Hvvveauu+5K64cFAAA8c+DAAeOCjCZOrF692owcOdJ+HTJkiDnrrLPM1KlTTbFixUy5cuWMa3SQmTFjRvPrr7+aMmXKJGxv1aqVvZI3aNAg4yo9/vbt25unnnrK5MiRI2G7gkU33HCDcZVOTm+++WZz4403msWLF5uDBw/a7bt27TIDBgwwH3/8sXGRHvtLL71k78+bN8+88MIL5tlnnzWTJ0+2r1MFv1x06623mlmzZtnnrGDBgvYEzxdffvmleeihh+z9CRMm2BNXBSsVEOvfv7+55pprjItYlxsWLVpkA3ehcePGme+++85kyZLFfq/3/yuvvNIMGzbMuByEfeKJJ8yMGTPMli1bzNGjR5P8fM2aNWn22ADg39KyZcvIv+vq8eKx6HOtcuXK5q+//jKu0TmJno/cuXObjh07mvPPPz/hZzt27LDHiZ9//rlxUc6cOU3VqlXNFVdcYY81dLE0PP6IJ3ERRNGJ0NVXX21q1KhhD7Iff/xxG0TRi/v1118377//vnHN9OnTbRlPkSJFkmwvVaqU01f/5euvvzYvv/xysu2FCxc2mzZtMq7Syenw4cNN27ZtzTvvvJOwXa9L/cxV69evt5kaopIQvbHedtttdl16c3KVgqzKsNE6fKPAnT4Y5ZNPPrHPWdasWU2jRo1sSYWrWJcbOnfubC677DIbgNXrTpldCvxfd9115tChQzYoq2xEl/kchD0WHVh/9NFH9jPORQp0pU+fPsXtv/32m73o5iIFydeuXWuKFi1qL77pb0zBc13I0cWpvHnzGl/Url3bXjA9++yzjct0QUPPiz6TRZl6r7zyiilbtqx5++23nVrfmWeeaU5lLrZZGDt2rH0fb9Cggfn555/tBQ21WNBFYNF7iD7fXPXZZ5/ZeMDMmTPtRd8jR47YCzthUKVu3bomHsRFEKVXr172JFUZDokzG/RmG6a0u3iVSwefsdQ/JFOmTMZlevzqZRBrxYoVJl++fMZVeiOqWbNmih8wYcmSi7Jnz27Ly3SAqeCe/s4kc+bMCb16XJQrV66EQINvdDCtrCGtT0GUMKinkyA9b65iXW5YsGCBLdXUFbqnn37ajBgxwpbv6GBGV+wUYNFBnMt8DsIeizJjO3To4FwQRccbCnopAHTGGWeY22+/3fTt29dkyJDB/vyPP/4wxYsXd/Jqso476tevby92KFipz2gFK5cvX25P7nQc+dVXX9kLcC758MMPU9yuEyNlweqzQJo2bWpc5FOGr4Jap2qWjS7suBhA1+fy4MGDTdeuXe337777rs1GURmM2ka47rLLLrO3Bx980AZQwov3qoBQBmm8vNfHRRDlhx9+SPGATNkoW7duNS66/PLLzZgxY8xjjz1mv9cfqa6W6AVQq1Yt4zJ96D366KP2jzZcmw7Oevbs6WyZgRQoUMA2Aj7nnHOSbFc/FJd7bChiqwPQSpUq2UCXrmzJjz/+mGytLtHfVp8+fewVoZQCli6755577BUFBcB0RSvMGNIBaIUKFYyrWJcbdHKq93OdzP3nP/8x2bJlsxc0ChUqZHzhYxA2pYsbie3Zs8e42pNHmcnqT6YLGrropkb2OlE9/fTTnb2aLPo7u/DCC22ASMFKZTYoy0sn5jpm1N+gjre0dpc0b948oYdSrLCfkn4eLydDqeVrhm9IgUkF+KR06dLOXiDV35WOgfPnz5/iz119/a1cudI0adIkSb85PUc6Pzt8+LBp0aKFcd2KFStsJkp4U2Ze48aN4+vvK4gDhQsXDubOnWvvZ8+ePVi9erW9P378+KBEiRKBi3744YfgrLPOCho0aBCcfvrpwbXXXhuUKVMmyJ8/f7Bq1arAZTt37gzq1KkT5MyZM8iQIUNQtGjR4LTTTgtq1qwZ7N27N3DVgAEDgrJlywbz588PcuTIEcyePTt48803g3z58gVDhw4NXLVjx46gS5cuQdOmTYOpU6cmbO/Tp0/Qv3//wFUVK1a0z5PeM8qXLx9UqlQpyc11X3/9tX0P3LNnT8K2yZMnB3PmzAlcxrrcM2bMmKBkyZLB888/H/jijTfesJ/Lf/75Z+CLdOnSBenTpz/mLfy5a4oVKxZ88cUXCd//8ccfQdWqVYN69eoFBw4cCDZt2uTkukTHF4sXL7b3dfyk50jHHiEdG2v9rtGxb6NGjYLNmzcn2Z4xY8bgxx9/DFyn5+3bb79NOBbRe6To+D5btmyBq/Qa7NChgz2212tRNz1nHTt2dPK9skKFCsFrr712zJ/rb8/F946CBQsG8+bNS7Z95syZ9pj4oYcecnJdoUKFCgW5cuUKWrRoEQwZMiRYsmRJcPTo0SDepNP/pHUg57777rPpw++9956NwOsKw+bNm23KqW5K23SR0sR09U5XUPbu3WtTo7t06WLrr32gDA1N6gnXpmlELtOfglI0Bw4caPbt25dQuqTXZ5hRhPjxyCOPHPfnrr5vAGlNV/v1XqiR2rpKrpJbXQXSZDmVGbz66qtOZ0SJMvPUyF7v+8rIO+2005L8XMchrlHpqRpSV6tW7ZhXL1UK49rVV2UaKnNSJTuJs2pUBqNmg+oFoKwA19YVrk1/U2E/F5W0L1myxJQsWTIh40GlPK5Mq0hM5S26vfjii/YKsujvTMfE6h3iMmWK6nnT+4h6oCgbO0+ePLaMSSUIS5cuNS7S+4P6UejcJSx11LG+ykaU0RGWMLlC5Yv6G1O5VUr0Gafs7F9++cW4lumlz+aUjoOVtaG/N5Xru/ieKBUrVrR/Xzq3VOaJbirvibes87gIoqgBjoILo0aNsk+4Gmvpqya9aFtY94r4ow92BRpcrCk83utRZT0KDumDXiUVrlFwq3z58rYJn+4fj8bmIr7o/U/vfceaHOJqx3XW5YZmzZrZQEqbNm3sa1B9eMJyAn2vdHylEmvMvat8DMKqVFhN+tXkMiU6edVJX+z7SbzT1AnV/4elqCF9RterV89e9FBZuIsnDAr+6L1eJwiik9SbbropoT+ggnkq8fn999+NixQQUsBB61NARYE+H4Ioen98+OGHbZBLJY9q8Bm+b6jELJyu5xo1y9Uwj9iSiS+++MKWjKjMxyUK/ut9Id5Ovv9XahqrXkkPPPBAij/X86WWEi73u9m5c6ctYddadfvpp59scEWfcxpAEw/iIogS0puRPgj1wagPetcaacV+MOqDUB8eLq8jJToA0wtYk2yUMaS6NfUMUd2yruj50NTIdQqeaFKS+grpfmxtcvi9yzXJPrvzzjvtgbUOnlOaHKKDURexLjfoBE5j3sOr+/qa+Eqdgufq06BsFcQPZQjp6mPYbDCWPq/1ue1agEjrURBB2cqxlJGiK+RqPOjiZ5kmYWnqhPqWpURNFGfPnm2bILtKr0k1W1XwX6PDdWHH9SCKrxRs+Oabb0yZMmWSbFcmmEbOamiGz/T3pr9Jjdj1icvr2rZtm82umTRpks360jlovLzXx0UQRQdjKpmIjRTqjVcdiNU80jU6yVGzXL0ZValSxQZUWrVqZZuXumbcuHHm0ksvTUg31fOlZp762qlTJ5u2qCCKfu+5556zDdFcpA8HvdEc6+q/PvxdoTHaer508v13I7VdGsWXmN5E9XemBsdKpVUGUewkLFfpapCuIsReeXUd63JDWJ6pE7tPP/3UnrzqIAZIC5pKtnHjRlOuXLkUf65AijI2NP7SNwpeKhPMhzJwlbroCrmunusCj+t0pXzhwoXJjhd13KXR6S666qqrbFmSjj/CSYA6F2vXrp09plKpj880/UvZUy4Pk/BhXePHj09oKKsMFDWBVzabMqT0Pq9SpngQF0EUlevoKkPsm6qiT9oWLxGnf0JZGm+99ZaNnunDUGlICqi4NGJQ0b+7777bftULV7W6r7zyin2z1RVLpWbqD1P1awq26IDHRUpdV8qYPvxSuvqvfYD4oeCqauHVp0FptUqfXbt2re2Ur58d62qsCzQFRR8e6hHlE9blBh1sKYCienGlz+rvLPbKpOt8DsJGpb42H3/8ccK4WV/4ui6f1+baujT1RZnmypzXCWri40Xdd/X9QxdF1WtIZTDhiaqO8RVQmTZt2jEDmb5IfE7jE9fWddZZZ5maNWsmBE3itQdbXARRVG6gNNPYEVpK/VP2hms1eMcyf/58WzupVEbXAkN67Mo6UbmVGrkpYKIMhsR/mIoWKt1PHyouUpqbUmbDZlo+UQNFZQnppEiUSqugUNi8zkV67EOHDrUlL4mb8WmbXq8pjU13xaBBg2zmk5q7+dRviHUhXvgchPX1wPpUX5fPa3NtXbrAoUxRlTT61m9DPYZ08VfH+aIAugJGOvb3nWuvw1N9XWktY1r+47ly5bInCLrpDSnxyYKCDDoZVw2X65TupxM6lbvs3r3bXHfddcY1l1xyic3SCE/AVaMbWwaiZlTqZeMqvR6VMuYbXT3Q7HhdUQ4DRHPnzrVXFHQ1RfXkLlLPlzA6rea/moYl6kqu/jwuUzd8pT1PnTrVPk+xk0OU6ugi1oV4oZME9RBRELZfv342E1FBWDXaVhD2VAiiAPhnNmzYYN8jfAugqN+V1qSLpgDiOIiiK+NKhOnYsaPtlK+u3SF1t1aTUpWH+FDGU7t2bTvJoGXLlk5Oe5EwwKCrdKqP1IeI6kB1Qvfzzz/bGsrJkycbV2mMsdamfi8+fTBqPKmauqnfS+z2nj17OhtEKVKkiC0DVO8XnfxMnz7d9nJQg0FNjHKZsqJatGhhfMO6EC98DsICOLlU8rJo0SLvruyrjELHHmo7oJJ9VQoA/5bDhw/brFCdV+qcU4kUihGEVLWisvB4qeZI0yCKTsSlePHipnr16smutrpMI/kuvvhiO7q5devWJn/+/MYXGn+pDAY1ls2WLZsNPOjk1eWshrDUQGUveq4UwIt9PapxnYtUwqO6/1h6Y1Ig01X6oFcT4GrVqtmRq/rQf/31121/AwWNXObyWLrjYV2IFz4HYQGcXMpg69Gjhy1jVzA29nhR2b8u0kVEZc7rOF8XttVSQcdWmiAFnGyPP/64vSCvYTNq3NytWzezYMEC8/LLLyf8Thx0IYmPIEoocUd1pZLFNnhT0ybXKDPDt9HGiV1++eV2aoNPmjdvbnykXkPqFxL7etQ2lzvkJ86s0Qe9ysu++uoru84mTZqk6WMDEN98DsICOLnCchddTIyl1gTxcqX8n7wv6qaJVyrRVza9yvmVcaP3SBenpab23MbH3i+urOutt96yvcqUESrt27c3V199tenQoYMZMWKE3RZPfQLjorGsmhjdf//99mq5JvLEcvXNyHcKdqU0CjgchYz4oA95TaFQ+Y4yvsKeKCovU5SX1PX4pAOYY00OcTUrSlgX4tG8efPs7VQKwvrabNDXdfm8Nl/X5QNl26ixrItDMULqR5kSnZAr81AtJFzk27qyZs1qX2+qBgipdYRaYqi646mnnrITvOLldRgXxW5KidMknpdeesk+6YpCqUeK6p6U1uMK1W9t3bo1SZPSY91ctnLlyoSopq7+qxxLN73o9RXxRUESXT0YNmyYzfrSTVNf1ExRUykQfzRhSJF3lZYtXrzYTr3KkyePndijqLyrWJdbdKCi7IwbbrjB1KlTxx7IJL75RP3XFFQ+VQIoohRpn0qNfV+Xz2tzaV3q25AxY0Y7DthXqgrQRRxlaKvMUSObda7mcj82nZfF3rQ9PJfp27dvsovC8c63dRUoUMC2VUiscOHCdtCCSm2VmRJP4iITRZkLCpZoHrRKd3SV9dxzzzVvvPGGTSXT7HhXagnV/0SBoFGjRh035SjsB+MiTXjRB4gyGwoWLJhsneFseRcooKUmwHnz5k2YFnUs+hBxnVI0w6s+iO+eSvrg08SQxFfoFAzT61BBMBexLrfceeed9rNM9f8pvdcrw81lOsYYPny4bf6uLBQdcKpPlC4GqCeAy8HKlOj5y5w5sz2+qlmzpsmQIYNxia/r8nltvq5Ln8cTJkxw6ng36jRH9UTRqHcd51977bU2C0XPkct0jqmGpToJ10WpcHKqztt0MfGPP/4wzzzzjA0UPfjgg8YVvq3r1ltvtT1PdPEmljJSFCfQxcR4yUTRg01z2bJlC9atW2fvFy5cOFiwYIG9v2bNGvszxJesWbMGy5YtC3wwatSo4MCBAwn3j3cD/i1ZsmQJ1q5da+/ny5cvWLJkib2/YsWKIHfu3M4+EazLLXny5AmmTJkS+OjFF18M8ubNG/Tv39++LlevXm23jxw5MrjyyisDl51zzjn22CldunT2/UI33de2/Pnz2/slS5YMfv3118Alvq7L57X5uq7XXnstaNiwYbBt27bAJ3ovvO6664KJEycGhw4dCnxRu3btYNy4ccm2a5t+JmPGjAlKly4duMS3da1duzb45JNPjvnzDRs2xNX5WFwEUSpUqBDMnDnT3r/qqquC7t272/tDhgyxQRUXpU+fPti8eXOy7Vu3brU/c9lFF10UzJ49O60fBiLSa+6OO+4IypQpY0+KcuXKleSG+FO8ePHg22+/tferVKkSDB8+3N6fNm2a088Z63JLwYIFg59//jnwkd4PJ0yYYO9nz549IYjyww8/2PdJl40dO9YGglatWpWwbeXKlfag+p133gnWr18f1KhRI7jmmmsCl/i6Lp/X5uu6KlasaN83MmXKFJx33nlBpUqVktxctXv37ki/N3DgwGDHjh2BKzJnzmwvQsXSNgWOwgv34X1X+LquqBTI3LhxY5BW4mI6j2r/la6uXg0qEVFNstLVVXc4ePBg46JjVUkdPHjQuUY/sdSQVI2ABwwYkOJoNxenKcXyZUqU3HzzzWbVqlXmlltusTXH8dTZGilTv4kPP/zQVKpUyb4/alqIGrIuWrTItGzZ0tndxrrc0r17dzNkyBD7eezb+4ZKePT3FUvluH/++adxmdK4P/jgAzu6OaSyCaV1X3PNNTYdWg36dN8lvq7L57X5ui5fpzlGLfXW8f/1119ve2+4QM1IVSKSeKqjaJt+JhpsorJ+l/i6rqi+/PJLs3//fpNW4iKIknicoJrXLV++3HzzzTf2jfaCCy4wLtZ/6oBTDXKzZ8+e8DPVcOkJV18Al+k5kquuuipZ4Mjl0W46cO7Zs6d3U6Jmz55t5syZ413t7rEoIKtGaK4+X/LKK68kNALr0qWLbSqr8c1NmzY1t99+u3EV63KL3jfU0G3q1KmmXLlyyQLm48ePN65S3xONeVcflMQ++eQTU6ZMGeOy33//3Rw5ciTZdm3btGmTva/G/WGPLFf4ui6f1+brutSz7FQWB+00U0VBu+uuu85+lmnKi+iilM43dYFK1Li0VatWxiW+rssVaR5E0YmCGtfpYGzt2rX2JFwHN2pmpCwH14SN9vQGo4Z1iZtlKQNFE2y03WU6qPaRsmu0Nk2JUvbGCy+8YBsZqWt8bJTXJQrapWWkNi249gEfK3369PYWUsNq3VzHutyiq4wtWrQwPtIkHgUolXWo9ws141Mj+4EDB9oLIC6rVauWDbZqHWG2jaZ8/ec//0mYqvTDDz84N03P13X5vDZf1wW36ALUzz//bI/n9VU06VANdMNxunpNusbXdbkiTafz6J9W6Y6m7+gquU72tG3ZsmX2TVUvDr0QXKQPDgWGfE2h8pEvU6JiKQqtMjlNdilfvrzz5Vd/V86ya9cuM3PmTKczUQCcfG+99ZYd9R6OVNQV8UceecSWPrpMV/h1IWDGjBkJ7/e68q/sUX2eqaxTFwxUMl2vXj3jCl/X5fPafF2XLggcr8TR9+OPxFMDgVP1dZimQZSRI0eau+++20yaNMkGHRL7/PPPbc2harHbtm2bVg8Rx7Bz50575W7Lli3J5o+7+nyp9Oqnn36ywZQiRYrYIJhGhql2XllRe/fuNS5auXKlueGGG2xQyIfyKx2I1a1b1x58pUQjgCdPnuzcuoB4pTGJ4VWu0qVLm3z58hmf7Nu3z76/n3XWWcYnSulesWJFwvOmmw98XZfPa/NtXTpvSUxBIGXYaLSsD4HYeD95/V/e63/99ddkPQ9dax1xqqwr3l+HaRpEUdRZ6Xy6Sn6sxkWzZs2yc8td9Ntvv9nmkCm9sF1tmCsfffSRnRuvg05lMSSOxuu+TmJdpDebYcOG2QbH6vtSsWJFW2+oPjdqfKbn00UKBGXMmNEGLFNqLKv1uvY8aS3HOkhRn4MqVaoQRAFOQJ+ou+66y2bohcFylagqUK73yqxZs7KPAeC/xo4da8aNG5csyOKbtD55/ScXAtSkX71DUuLqRTdf1+XK6zBNe6J8//339uT0WFTXFTZqdY1SF1WOpCdWEXiVUajni2JWanrpMk1s6Nixow1y+XQQ7eOUKFm6dKm9QuL6lZ+QAiTKqjlWEEXTNZRNBOB/7xuiCxkKnNeoUSOh2WzXrl3t54D6R7lKzcNV4qhSgpQyKl29GOD7RRxf1+Xz2nxdV0ouueQSc9tttxnfXX755SZLlizGFffcc4/NoF+wYIEt2Z8wYYLZvHmz6d+/vxk0aJBxla/riurBBx80uXPnNmklTTNR1Gh13bp1pmDBgin+fOPGjbbZlMYCu3j1X0EgpfWFkTKlCiuDo0GDBk43+smWLZvtWeNKBPqf0mvT1SlRidWsWdOeLIRTlVyn9wNF130K4J2q9PGjk9fEDbgRP/LmzWs7/OvgLDEFHjTeUlfBXNWwYcPjjn5v166dcdXfXcRRubSLfF2Xz2vzdV0pUQP/Bx54wGYFhOWPLtJnst4bUwou63jSRTrPVHaQzs2UQa8JNuedd54N7ulivi4OuMjXdYl6JmkQi1oqzJs3z07Se+6552xcoFmzZiYuBGkoffr0wZYtW475802bNtnfcVH27NmDVatW2fs5c+YMli5dau8vWbIkOPvsswOXtWjRIhg3blxaPwxE9O677wZly5YNRo4cGSxatCj47rvvktwQX6ZMmRLccsstQY8ePYJly5Yl+dn27duDWrVqBa45fPhw8NBDDwU1a9YM+vTpY7c99dRTQdasWYPTTz89aNu2bXDw4MHANQsWLAiOHDmS8P1HH31k11ioUKGgSpUqwejRowOXZcmSJfjpp5+SbdfnmZ47l+kzWp/HPrr44osT/s60ztWrVwd79uwJmjZtGrz44ouBq3xdl89r83VdOq7PlStXwk3fZ8iQIciRI0cwadKkwFXz5s0Lihcvbs+90qVLl+Tm6vmY6Hn55Zdf7P1ixYoFc+bMsffXrFljP+dc5eu6XnzxxSBv3rxB//797Tr0viE6j7nyyiuDeJGm5TyKRLdv396m36fExQyUxNkaYdqiIoXq/l+uXDn7/datW43LGjVqZHr06GGbsKrhauy0F111cJUm2RwrvdvVtNNwPrxKsEK66upqY1nf66nVb0LZarqSpb4TGg2pDDbRe4rKK1yjjLxwHcps0N/XlClTzCuvvGJff0rJ1BUGjRl3yaWXXmp+//13m2Wokhc1Q7/pppvs35xK6JTloExEV8cEa319+/a1PVEyZ86ccLVVz6d+5jKfR79rwqEmyon6YWmdapz+6KOP2it4rmbC+roun9fm67qeffbZJNlrmtajhtvVqlVzeipn586dzUUXXWQ/n3XucrwJRC5RObuOqTT2V9NgNRJY95XpcKxqCBf4uq5hw4aZV1991R5TPfHEEwnb9dq87777TLxI0yBKlHRZVye9qC5SaVRlypSxacOqH1cJjCa+6Gcu69Spk/2qD8FYLp+Uq8fLww8/bN+UYtO7Xf4gUSoc3PD000/bYJ16Tsi7775rg18HDhxwutu/gkMKojRu3NgeNOtvTNvCAJ9O0B977DHngiiJq2GVOqvHP3DgwIRtSjvVdleDKEOGDDH169e308p0gCYqTdXz5WrD99CLL77o1ej3U+Eijq/r8nltvq5LQzGKFi2a4rGher+42pdN0xx1oUNl7D7RMAJd8BBdGNCFKo24V1uJUaNGGVf5uq5ffvnFVKpUKdl2JV2o4X28SNMgikYc+0onQuFIXF2103117C5VqpSzGQ2h2AwNX+iEYcSIETY7yieqI4Q7BzBqaBxS3wld3VJ2lxocu3oyrv5W4Um4Ds70AR9+LxdffLHtQeQyje9UNk1i11xzjQ2MuUrBBb0mdVCmfgbSpk0bm1HkUlPBlOTMmdPs3r3bngwl5kOGnq8XcXxdl89r83VdCpCHWYixDav1M1ffP5RJo34ovgVRlCGaeDiBjjf0maZgl3p/ucrXdRUvXtxO2ow9f/nkk0/se0m8SNMgis8SN11VJF6pVYhvSscMJ1AAaUFXv9VZXR8goVq1apnJkyfbLA5Xx2yfeeaZtoO8rtyJGgqqzCVx6aar2V4qa9y0aZMNKqQUYD5y5IhxmRo4h9mHPlEgSNknyohKqbGsy3y9iOPrunxem6/rOtZMDq0vLH10hSalhjTSXoEufaalVK7v8pCF2M811yel+ryubt26mS5dutgsbP2tLVy40JYFKtNXWc3xIk2n88BdSqdSb4aURtaFpQiuUdq9rpjHXk2GG3RVWZ3+VSoST5Hq1FD9pzI0dLAZa+bMmTaQoppy165y6Wq/yjePVcL53nvvmSeffNJ2lnct8Br2FxKdFGjkYOidd96xZUo//vijcYW6+muynA6edf94XO5/pYNNn0a/A/h3Tu7CzGUFlxNPCdTnskbNatrc3Llznf0ci+VqD73wuYrCpYCer+uKpQzYfv362RJAKVSokD02jqfSdjJRTiA1k4p6NWv79u3GVTrwVFrmvn37bDBFM7pV26oPE6U2uhpEUbMiNc0tWbKkKVu2bLIIvNJPET9U6qJxe3feeacNLKjhVDg6USevKqVwzb333mu++uqrFH+mMbNqXqomn65RJl7s31NiKlVyrR9KSv2G1DAxMQWYe/bsaVwL5OkqpN7Ldf9YXDugjqX3i/Xr1xNEAZCq41/RcYbKklSaGgrLVOOp8eWp3DcvfK7+jmtZiL6uK3H2rjJE1Y9NGaM611SGV2zpXDwgE+UEGj16dJK6yP79+9sXQTjFQHOu1Yyvd+/e9mTJVTqZ0xxynRgpTV+NBnWCpNo8NTlq2bKlcZFOxpUmpvKJlNK7fe7h46ICBQrYvycdtOgNV0219FrU36GmvkT9oAFw6lH2k65yadKcD2nrvl7E8XVdPq/N13Ul1qFDB5uN4nIDaiSnkmllPCg7xyeurStr1qx2sle893QkiHKS6Cq4TsZ1Yp7Y888/bz777DMzceJE43JDPqUsKg1a9xUcUvmEtildP2xA6Br1aFAGg7JRfKUmkSrB0huT643D1INCzTzVZ0NTvPQBoVFoWp8yicI6bAD/jLKeNEFJHfFjM2z0Xunq9DxJ6WDS1bT12Is4J2IyYrzwdV0+r83XdaVETVhVbqCsWB2ThO8frlLPCV1E1FTAxDR04Y8//nAuszK1FBRTQ9PEfS194Nq6rrzySlsafbxs2Lignig48bJlyxasXLky2XZt089cljdv3mDFihX2fqlSpYJPPvnE3l+2bFmQNWvWwFXFihWza/DFgAEDgs8++8ze3759e3DVVVcF6dKls7f06dMHDRo0CHbs2BG4Sq+9cePGBXv37g3y5csXzJgxw25fsmRJkCdPnrR+eIDz9D6xefPmZNu3bt1qf+aytWvXHvd2Khg4cKDTnwGn2rp8Xptr69q2bVtQu3bthOOp1atX2+0dOnQIunXrFrjq7LPPDubOnZts+/z584Nzzjkn8F327NkTnkufuLaucePGBSVKlAiGDRsWfPXVV8F3332X5BYv3MjrcVCePHnMpEmTkm3XNv3MZZrd/fXXX9v7V1xxhenTp49tAKSooUZiukqp3SoJUf2dD1588UXbr0bUb0Jps998841d37fffmunpbhWu5uYXm+qlyxSpIgpWLCgjVzLl19+adPzAfxvjnVVVanBKuV0mbLxjncLKTNRo0x9NGDAAGfLKU7Fdfm8NtfWpeMPlQAq8zVxc1ll7mkMq6vUD0vHU7Hy5cvn7fsg4k/r1q1trx712NTU1IoVK9pzz/BrvKCx7EmiDsK33nqrnaihueuiche9ub766qvG9Q+7PXv22PuPP/64Ten+z3/+Y0fWKeXPVUOHDrVpmUplPOecc5LVyCvw4BKlXoZBFJWQKcU2fPNRHxGVljVp0sS46o477jBVq1a1zSHr1q2bkJ6vdEX1IwLwz+h9QsET3a666iqTMeP/P1RQmYsObho0aHBK7F4FZdW42ke+Dmf0dV0+r821dU2fPt32ZNNFnMR0HLxu3TrjKpVHa7JQ8eLFk2zXNpVMA/+GXxxpdkwQ5SRp37697ROiE/Nwqou+nzNnTkJQxeWpBiF1S3Y56p5Y3NfepZKupi5dutR+1clQ4hMh0Rg+TVdy/bWoBpB6w9VUJa3Rx542PoxvTgnriu/3QtVQqzl64qlDmkChILOL068A4ETQsVPiDJSQsmlie0i5RGOblWWjiXm1a9e222bMmGGzmbt3757WDw+niLPjvKFsiCDKSaRgicpc4AaV8vhEH4aaPKETbzU4VunOG2+8YYMNCjpoQlS9evWMq1SWdNdddyU0sVOTWWWhaFvhwoVNr169jKt8HN8srMut90IFS5Senjlz5rR+SAAQNy6//HLbePuxxx6z3+tC1dGjR81TTz1lh0q4SseMmi6qTF81EBe9/6uh7AMPPGB853JTYJ/WNWbMmOP+PF6a2hNEOcFXVcNxZ7p/PC6ORdMHQ+I/RF0Z9436hLz//vu2rEcfJiqHURmPSnx0Yu4SBU3CSTUKnOgkXKOpla2hOeyVK1c2b7/9tnGVPtA10lglc4lLC+rUqWP727gcRFEJwUMPPWTvT5gwwQZP9NpUwEilSq4GUViXW1yfnAEAJ8PTTz9tMzUWLVpkgw3K1Pjxxx9tJopKX1ykUk09dh079e7d246Y1cQhlSi5nF3jc1mZr+u6++67k3yvzChdOFUmrDLACKJ4KFeuXLbxkkpcNPo3pcifq+MTwxIln33//ff2BFwNExVwUCaHgigqx1Iw4u8io/FI5WTqVzN58mSzZs0ae6VETcPUqElrdS06nZjGhI8bN85ccsklSdZRrlw5GwRz2a5duxL62ahcTkETfXCoVEnBPVexLrfoc+rZZ5817777rn0PDK9MhlxqBAkAJ4JO6NTw8qOPPjKffvqpyZEjh9m7d69p2bKl6dKlS4qNWV2gEm9lJyt4op4oF198sTnV/PTTT172fnFtXTt27Ei2beXKlfZ8Jp6OgclEOYGUmRGe+HzxxRfGN75flezWrZsNFCkdUx+KoYYNG5obbrjBuEo9NHzqo5G4ca4ClinVKrscHAqbu82bN8++nyiIohKe8IPF5dIK1uVeg/TXXnvN1sI//PDDNjtKAWYFMDWVDe6XJOhKs298XZfPa3NpXRo6oItuunAaZoz6QhM2dcEttrGsixTUiirsXaljlHjn67r+jjKinnjiCXPTTTeZ5cuXm3hAEOUE0rjflO7DDRrb/PLLLyfbrjIejX1DfFGfkClTptgeKBIGTnTSd+mllxqXheOb1dCzWLFi3oxvZl1uUU8vTZNTBpRK5Nq0aWNLA9XMef78+fZqrKsUbM2WLdvf/t6DDz6YcHHEpSvKYVZsYup1oG1hJuzHH39sXOLrunxem6/r0onc66+/bk/qfKJyYZWCq9dLlSpVkr1HutSKQFnlPvJ1XVGoHcHGjRtNvCCIcpLoZOd41DTSJYq4R72672qKt2o+U+plo4al+fLlS5PHhOOP2r766qttmqJ6vAwZMsTe/+qrr8ysWbOc3nW+jm9mXW5R8DgM2imgp3Isady4sa2Zd5n6XKnRcceOHc1ll112zN9zsZniserfDx48aGvKXeXrunxem6/r0jHHiBEjzGeffZZisGHw4MHGRcq8lqZNmyY55nexFcHIkSONj3xdV2Iffvhhku/1+lMw9vnnn7ftCOIFQZSTJLxynFjiNySX3ojkueeeS3IFQSdyGn0ZXvFX6cG0adOcPrDWh8ajjz5q6//D50t9ANSV3NVGnj7TiY9GsOpKkE70pk+fbpvl6rXocraG7+ObWZc7ihQpYg9clA2l12D4N6asPdcbDb755ptm1KhRtjmkphApmKJmdS7VjafUAyv87FJGXuLR1Drm0MWd888/37jG13X5vDZf1xVaunSpfS8ML7Ql5nI5sY+tCGLLwH/++Wd7X5MrfblA6tu6mjdvnuxvSmvS5/WgQYNM3AhwUuzcuTPJ7Y8//gimT58eVKtWLfjss8+c3ustW7YMhg0blmy7tjVr1ixwlZ6nOnXqBDlz5gwyZMgQFC1aNDjttNOCmjVrBnv37k3rh4dTyJ9//hl07NjRvg51W716td1+5513BgMHDgxcxbrc0rNnz+Dxxx+39995550gY8aMwbnnnhucfvrp9mc+2LJlSzBo0KCgQoUKdn2NGjUKPvjgg+Dw4cOBa8455xx7S5cunf38Cr/X7bzzzgvq1asXzJ8/P3CNr+vyeW2+rgtu0jF8hw4d7PGUXpO66f1ex1k6LnGVr+tyBUGUf9nMmTODypUrBy7Lli1bsHLlymTbtU0/c92cOXOCF154IXjyySeDTz/9NPDNrl27ggkTJgQ//fRT4LL06dMHmzdvTrZ969at9mcu69q1a1ClSpVg9uzZ9m8qDKJMnDgxqFixYuAq1uW2r776ygYcPvzww8BHQ4cODTJlymQPRPPlyxf07t3byQPRK6+8Mti+fXvgG1/X5fPafF2X7/S+t2zZsuC7775LcnPVbbfdFpQoUSL4+OOP7TGwblOmTAlKliwZdO7cOXCVr+t65JFHUvzs3bdvn/1ZvCCI8i/Tm5LrgYZixYoFzzzzTLLt2qaf+WTHjh2B66677rqEzCG9AZUqVcpm2Cha/f777weu0olOSkGUDRs2BJkzZw5cpr+jefPm2fvZs2dPCKIoUJkjR47AVawL8WbTpk02YF6mTJkga9aswY033hh8/vnnwZgxY4Jy5coFdevWTeuHCAD/WmaesvF0ISqlm6vy5MkTfPHFF8m2670+b968gat8XVd6Ry6S0hPlJNH4s5iyKVtbrv4NFStWNC7T2Mtbb73VzJw501SrVs1uW7BggR3FqkkOrnryySdtbXyrVq3s92o6+MEHH5gCBQrYzvEXXnihcZFqj8MxfBMmTLCvxZ07d5rRo0fb3jau9Xvxvdba5/HNrMuNhm5q2KwxnrHN3VLqI+UqjX5Ugz718ipbtqxteqyJGzlz5kz4nerVqzs5Hl7vg+r3MmPGDLNlyxZz9OjRJD///PPPjYt8XZfPa/N1Xb7SBD0dH+qYXr0ddcy4efNme6wYV70oUmnfvn22mXgsHWfpZ67ydV3BfxsZx/ruu+/ialoeQZSTRIESvQBiO5NfcskltqO3y9q3b28PLHUyG84g1/dz5sxJCKq4aPjw4Xakp3z66af2NnXqVNtotkePHrapoos0USN801GgS0GTrFmz2ialWpdrnn32WftVf1t6zjRCMaRu/wqEabvLfB3fzLrcaOimqTw6CItt7paYa5MaYnXo0MG0bt3azJ0711x88cUp/o6azIYBaJfcfffd9sRV7/Hly5d3OvB6KqzL57X5ui5fKag1adIk+1mtqYBnn322nRCo0cYDBw50trm9jpv69u1rxowZYzJnzmy37d+/314UdvmYyrd15frvJFjdzjvvvGQDWfbu3Ws6d+5s4gVBlJNEEzUS05uROguHL3LXKVgSBhx8oROHokWL2vuTJ0+2mSj16tWzJ+UuB4e0Jk2sUSBFQZR33nnHbt+xY4eTr8fwb6tWrVo2iKc3Xd/4Or6ZdcW/xFeKY68a+0SZoQomH0+WLFnsAapr9B6v4H84rtQXvq7L57X5ui5fKds1zILVsZWyR3Uyq4mH3377rXGVjqE0UVQT58KscmU16BhY2Yiu8m1dzz33nL1Aqml5CgSdeeaZyS6SxlNwiCDKSaLoLdyiD4z169fboIOCDUpfFP1Bu3zFVemZN954oy170ajScPy2yl5cHgXs8yg+X8c3sy53HD582DRo0MBmdZUqVcr4YPfu3cf9PjFdeXWVDjbPPfdc4xtf1+Xz2nxdl680HlejcnWyqpPyl19+OSG7t2DBgsZVyoJauXKlvfi7fPlyu61Nmzb22FjBclf5tq527drZr8WLF7fltCorjmfp1BglrR+Ej8K+DVF07dr1pD4WRHPnnXfaDBSdMCxevNisXbvWBh50JeWpp55yOgq/aNEiGyBSWmbYQ0TlIqr/r1GjhnERtdbAyaXsSWU/+RJEUUbo35UThLXYLgfO1btgzZo15vnnn/eqfMLXdfm8Nl/X5as333zTZr+qbP+bb76xgfRt27bZYJj66IU9A11z4MABJzOvT9V1/frrr8f9uS4IxwOCKCeJomhKg1Njn7BRnZo1KX1YB6YJT0C6dPYDBvFx5VWpcQo26AOkUqVKCT04cuTIYZvpuuzQoUO2FKZkyZImY8aMXgS9wlprXSGJPUALe6e4SH1eVG4Q21xWBzPa5uoJHutyy7333msyZcpkM6J8kJpSuCuuuMK4qkWLFjZTTyWc5cqVS3Y1L+xl5hpf1+Xz2nxd16lC5zDKcNBJa968eY2rlFmo16Kah1911VU2oO4DX9eV/m8ueMTLMbD7Z1Jx6vHHHzcvvviief311216nChFrlOnTub222+3qVaIL/pwv++++1I8kXD9Q1ANSnUVQVasWGFKlChhtxUuXNj06tXLuMjnWutjJQgePHjQXhFyFetyi65IqhH6Z599ZqpUqWKyZcuW5OeDBw82LkkcGFHQ/Fipwlu3bjUu04UbHVj7xtd1+bw2X9flq27duqW4XSe0ynhQaVazZs3iakJKFDr+HTt2rH3s6rOhjBoFHtRA12W+rmvx4sVJvtfntbbpmEPn1/GCTJSTRFf733///YRshpDS46699tpkjWddooY/ythQdkZsQyqdmLs+fcg36o6vCRRq2KTUTI3fVhBFHdj79euX7M3KFZqcoTHbanrmWxmgAnePPfZYiuObVWbm2nPGutx6vkJq3nwsOqh2eTypppTpMzr2apfGeeqK3tKlS9PssQFAWr3nq3RdxxvhBWBdeFMW6fnnn28vBus9U9M4NRreNXv27LHv+2+//bb9/NKxsIIOffr0MS7zdV2x1Ibg6aeftsf+8YAgykmish2lDseOTly4cKFt7Ony/O5jpeTr6l2BAgXs1UvEV5PjcePG2fHaCnypc7feYFetWmWblR6vuWI887HWWmWAsm7dOtttPaXxzY8++qhz06JYl1vP16lAn80XXHCBzRYN6XOtdu3atuxAB6Qu0+ewDjRXr15tbrjhBvvev3HjRpv+nTg46xpf1+Xz2nxdl490sW327Nlm5MiRCc21d+3aZcvZ1Rhe2fR6DjVG18XpL4lp4qGqAnRhMV7KQ04EX9clOm9Rw2NdtI8LaiyLE69x48ZBpUqVgm+++SZh26JFi4LKlSsHTZo0cXKX79q1K9i5c2eQLl26YNWqVfb78LZ9+/Zg9OjRQcGCBdP6YSJGlixZgtWrV9v72bNnT7i/ZMmS4IwzznB2fzVv3jw488wzg+LFi9u/txYtWiS5uezKK6+0f1O+YV2IF1u2bAnOP//84N5777Xfb9iwITjvvPOC6667Lvjrr78Cl61du9auLWvWrEGGDBkS3vO7du0a3H777YGrfF2Xz2vzdV2+KlSoUPDjjz8m27506VL7M9F5TZ48eQIX7d+/Pxg3blzQrFmzIFOmTEGxYsWCnj17Bq7zbV27Ep1fhueey5YtC1q1ahVceOGFQbygJ8pJopIWjWpSXVpYd61ovOZ5v/baa8bV2lZd8dctpRIKbddcb8QXvQaVAqdSKwmzNvQ6jKd566nlc621r+ObWZebk73Ue0jd8tWc2pemkGrwrtHhuroqmsymzDyNinS9OZ9KOPW+r6zDPHnyJGzX+6WuJLvK13X5vDZf1+UrZZ1s2bIlWamOBmWEWcs69or9LIh3yppR75CJEyfawQpqq6D3/5o1axqX+bqunP8934ztqVe0aFHbDzFeEEQ5iQdoH3/8sa0lDGd3q57Q5f4NOgHSi1jpzh988EGSxlIqNVDZiPpUIL4MGDDAXH311TbFT4E89bPRfY0uTc20inijdFNf+Tq+mXW5RQcrbdu2tcF/HZjVq1fPfqapb4gPAUwdkH366afm8ssvt+Pf33jjDS9KA5WOr/f32CbUKgfcsGGDcZWv6/J5bb6uy1dqUKq+hyqXDtsRfP3113boQvPmzRPaErh2LqPPq8aNG5sxY8bYYQTHairuGl/X9UXMhURd2NB5tRobx9N00fh5JJ7SG41rbzZ/N9lATXE17syHg80odAVFVyhdrS3UldYlS5bYMaUVKlSwJ0Naz7x58+z3iM+rd+H45vLly3vzt8a63AvAalR4ly5dbB8DBWDV30YT5jRW3DW5cuVK8W9JPco++uijJFfKt2/fblyloGtKn1e//fZbsobwLvF1XT6vzdd1+erll1+2je1bt26d0N9QJ63KrNdnQXhB2LWMegX+o7zedJzcuXNnmwnhAp/WVblyZXvhUJ/TusCrwJ36i8YzGsue4NFgmqihMZDHGhPm6mjIxDQh5HhcTyNLKYiiKUux2QBIe2r+eKxSA3WYd1XevHkTriz4hHW5RZ9lP/74o71qrACDmkMq8Lps2TKbkahGrC4Jx7xHoZMGV2nMpcZdvvLKK/YAWw0GdRVPV5l1AcTVLD5f1+Xz2nxdl+/27t1rG/eLBhGcKg2A1UxXFx21Zp+4sK4sWbKYlStXJgxV2LRpk32viGdkopxAGjuqWdbhfV9pulCsxFf3XMvYaNmy5d/WiLqcCXCsaUrbtm2z21x7vhKPzX3ooYdM+/bt7bjmDh062O7/Sj3VlXOXKfVZaYu+YV1u0RUhjU6UwoUL27G/CqLs3LnTyQlzLgdGUkOp+CrBUl+DAwcO2GkaOjhVEFMjMF3l67p8Xpuv6/KdgiaaXnaqUcsCH7mwrooVK9rjeGXP6/FqlPGxgnfxMrqZTBSkmoIKiSlwpKBR7969zeOPP26uuuoqp/aqaghVD58/f/4Uf660bjUddDXYoFpCRXRjgygaMViyZEk7qs5FSint27evadOmTZLRzXpz1XOm0ceu8nF8s7Aut+iER00hwyzLYcOG2SvI6iOi1FuXG8uKgq66Eq6vKlXSe+TUqVPtFXKNOXaZUvHV00ZX/nVVWc+Xxl7qap/LfF2Xz2vzdV3wT+JjSZ+4sK6ff/7ZHtPr81iZ5Aq8ptT/RMfE8ZJpThDlX6Yms02bNrXN+XyjGjYdbH/zzTfGJYq2q1fDLbfckuLPlQJXpUoV54IoytQQ1bfqBChxRFdrUVnW2rVrnc2aUq2kygrU0FgnPzqx0/x4XeW65JJLbKaNy83C1FhLzZt1MhfbLMzVk1fW5QZlnKgXj4KRunqshuEqZ3zqqadsk8hSpUqZhx9+2GaquPx5pYbbNWrUsO+Fei/RAaZqxzWRSKWCAIBThwvBhlNhXemPcfE33lDO8y87ePCgjbL5SJkciiS6RgESRTWPFUTJlCmTvTLpmrAJmNLihg8fbst6EpdVqM+BtruqQIEC9iRPQRQ9P/Pnz7dBFDU+diF18VQc38y63AksazLDrbfeahsMhgc1vXr1Mr7QWvr3728D/4kb86nXi8tZbIkzDefMmZPidK+uXbsaV/m6Lp/X5uu6AJwcUXtQaviCmhynVaN7MlH+Za5PehGlZCamE1b13NAVPKVt6sPStcCWno947wL9T9WqVctmLrh81TglOsHTiFKl/73wwgumR48e9qqyriKrz83rr7+e1g8RcHYsqcpclI2hg5lrrrnG/r1pFLAvlJn3ww8/2GlDia/SKTtPpYLKwHGVJntpgpKC5WoInLgkUPfDhpGu8XVdPq/N13XBT65lbETFuk4Ogij/Mh+CKLoiqQ+/2Kv9KqEYMWKEPQAFTjad3OkW1kyq5josNQgP2gD8c3/++aedfqUTIQVW1OxYGXtq0KpMMJdpAoDWVr169SQHmBMmTLCjFV3OGFVwWeMsH3jgAft57Qtf1+Xz2nxdF/ykiYi6AJdWmQ0ni6/rypHGQS+CKP8yH4Io69atS/K9Phg1hipz5sxp9phwbHqt6SRI89dTSqf9/PPP2X1xyNfxzazLTatWrbLZKW+88YatVW7QoIH58MMPjasUKFmwYIF57733zHnnnWf/pjZv3mzatm1rb8pwc5Wu+C9cuNA2DveJr+vyeW2+rgvu0bGvPsdSOg6uWbOmcZWv63IhiEJY+ARTyYSaQR7r5kM6tHpQJL7pSgMBlPilprm6KZiiZpHqG5L45qpPPvkkSemYSno0Ik0TRXbs2GFcpqbAGvWmPkNq/Fu1alV7MKrUZzXDdBXrcpeyUB588EHbUFYHLlOmTDEuGzBggM2a1OeXJoZoEoAOOJWZojW6TNlCCg75xtd1+bw2X9cFt6hnnj7DypQpY9/nr7zyyoSbSt5d5eu6XEEmygk2evToSL+ndGiXKatBjUs10UD0B3zPPfeYOnXqpPVDQ4y8efOaMWPG2HQ+n1SoUME8+eSTdl3qbaBRrN27d7dTbXRypKvmrvJ1fDPrcpOm16hU84MPPrCZh9dff709OVIJp+uU6aVpRAqkVKpUyZYDuk4B88aNG9vx9XqfjJ3uNXjwYOMiX9fl89p8XRfcogtsyjh85JFHbElL4t48cuaZZxoX+bouVzJRmM5zgrkeHInixRdftJkN1157rf0aRkN1MqvASpcuXdL6ISIR9QZRpNo3msKjq8eik7smTZrYq8tKy3c9YKQTO10RlyxZspg9e/bY+zfffLM9cXU1iMK63JqooTJA3ZQqrNejMokUQMmWLZvxhXq76ARP5QZhfyXXDRw40EybNs2ULl3afh/bzNNVvq7L57X5ui64ZeXKlbaU2LdjYV/X5Qo/jhjwr9KJqoIld955Z5IxdZqMop/5EkTZvXu37ReiD39l2rhK2RlDhgyxJ94+HbQoOLRv3z57/7PPPrN9DERlc3ruXObr+GbW5QaVjOlvSlls+rvq2LFjwkmQL/TecddddyVkj65YscJezdK2woULOz3OedCgQTZzqH379sYnvq7L57X5ui64pVq1avZigG/BBl/XFZVKjHXMn1YIoiDVdu7caZsKxqpXr57p2bOns3tUV1hVU6jgkK5MqjxE4y510qrJLxrz6SL1DVGJy9SpU025cuWSpdNq/LGLLrvsMtOtWzcbvFPjunHjxiWcDGnyhstq165tm3aqvEC9Ue699157tSEc3+wq1uUGvUfo9aY0/AwZMhgfaVqI0oBnzpyZ5PNMJan9+vVzOoiSKVMm+77oG1/X5fPafF0X4t/333+fcF/BcV1QVFP0lMrKLrjgAuMKX9f1YSoa1Tdt2jThczwt0RMFqabGnTq569GjR5LtzzzzjD3JU8DB1avkSjvVFf+xY8fanhQ6yNaVyldeecU2+HSRTsKPx9XeISoNueOOO8z69ettJpR6NIgCDqrDVumBq3wd38y6EC+U5aXAq8rjEtdV66qeJui5nM2mEorff//d6ffAU2ldPq/N13Uh/ql/l7Kvj5W9G/5MX12amOrzuqKIp3URREEkiT8AdXCpgImuLlx66aV2m8oN5s6dayOirk42UO8JZTFoWoNS2AsVKmSeeOIJe7Ku3htqPAgAcF/WrFltQ1kFThIHUfRVGYm7du0yrmrRooUtRdVEL5+yD31dl89r83VdiH/r1q1LVVDdFb6uy0WU85wEhw8ftlMoJk+e7HQvjcTUAyV2lPNPP/1kb6GcOXPa2ldXgygKnsybN8/W12l8bphRo3G5jHCOP2ogqwMypTDKpEmTbFaNAl5Kx3c1W0P0+suePbstWQrHN7/66qt2bbqvvz8XsS7EC5Vrakyz0qEl7Bf12muvJVwccJU+i10u+zvV1uXz2nxdF+KfrwEEX9flIjJRThI1plNjPl+CKKeCcOqQTl7VzFPlO0ovGzZsmL1aor4irlJ/g3fffddm1Rw6dChZMMJFF198se1boF41a9assVe5dNXr66+/No0aNTLPPfeccZWv45tZF+KpV5Qa6N500012ApHK5HRRQGVzs2bNMlWqVEnrhwgAOEFlZfnz57dN0hPThd8//vjD2X6Ovq5L9Dmsqodly5bZ73URUW0kLr/8chMvohUgIdU0oUYnQUeOHPF27+lk/Oeff/ZmjeqvoUwUvfmoNCmsz1OKd//+/Y3LpVjqi6I3WgWGqlatalNrFXjQSYSrVHpVsWJFe/+9996zKfjqZaMTIo089nF8s7JQ1CDYVawL8UJZXird0eeXgnvTp083Z511lv0M8CGAonXpQs7LL7+cMCJdY6tdL0v1dV0+r83XdcEdeu3pAlQsXXwbPny4cZWv63rzzTdtk3eV3arnoW5quXDVVVfZ4/x4QTnPSaKr4TNmzLAHZjpAy5Ytmzd1oD6PhtQVf3Wz1sleyZIlbWNPZTW4nmGjxrht2rSxAYb777/fPl99+vSxY3RdpcZZalQqOkDTJJGwLGvr1q3GZb6Ob2ZdiBf6m6pVq5b9vNJ7vU9UM6+JQ8o8PHjwoKlbt67t+6ILO/re1YNrX9fl89p8XRfcouk1BQsWTLY9X758tvGxq3xd1+OPP26eeuopOygipEDK4MGDzWOPPWYHnMQDMlFOYh2oygzq169vG5SeeeaZSW6uRToTl3wkHg2ZuFeIoobhmFkX6aRVE14U+VQUVx/6ouCQGsy6SuuoXr26va9Ibngl6OabbzZvv/22cTngpQyhN954w6b9hcEuBcCUdeOycHyzPiw0vjlcm+vjm1kX4imgp1To8847zwZeVdajfigrV640rlNZqt4f1c9L7/khlTvq4o6rfF2Xz2vzdV1wi97jlWEeS9t0juYqX9e1Zs0am4Gd0mhjHePHCzJRThJXexakRKlizZo1M6+//rqpV6+emTBhgu2vodGQYTM+UeBh9erVxlWJg0O6cpI4OKRGpa5m2Gh0szJO1IxKvV40SUljnPVGdKwRaS5Qz5Mbb7zRTJw40Tz00EPm3HPPTej/EgaNXPX888/b8jKt5aWXXrIZXqJSnsSvTdewLsQLBUxkw4YN5ssvv7SB2EGDBtneKLqy99tvvxlXzZ492/Z2iW2ufc4559j1usrXdfm8Nl/XBbd06tTJ3HPPPXbwR+3ate02BfGUma1+c67ydV1Fixa16wiP60PKzNbP4gVBFPytK664wh5gKn1KQRSVSqh2PNaff/6ZJKjiGp2MK5PGt+CQ3lg//PBDU6lSJdsbRelxOjlftGiR013zVXalpquxnn76aZMhQwbjMgW7NN3r76ZkuYZ1Id5o0pV6ROmrMkhVwqlUaJepzPGvv/5Ktl2BIZVSuMrXdfm8Nl/XBbeoIem2bdvsxalwuIIy6dV4VRdQXeXrurp3727Ld5YsWZJwUVTZNWpJMGTIEBMvmM5zkhQvXvy4AQWlKrlGf6C6mqAGntddd50tc9GH4Pfff2/Xq++VCq0xpi5SGc/SpUttvxCtS1kpuq+vWvOuXbuMqwcxuunkQDS6WVeGSpUqZa+6ujwK2Fe+jm9mXYgXDz74oM06VLNtTdHTxYIrr7zSvte7OkI81KpVK1s2rF5Y4We0AkPKKFUg09VMWV/X5fPafF0X3KEgnk7AdTyl4ypNe1FpmY6BM2XKZFzl67pCqnpQdmg4nUef0woa6b0jXhBEOUliI2VKtdLBmgIMehG4Whri82hIX4NDPlFjVfUFyZs3rz3ROV6g0uWmub6Ob2ZdiBeavqaTOWXmKSNPvVF8oav86semck19dqknhb7qfVOlSyllkrrA13X5vDZf1wW3KDtDJ+M6pveJr+u69dZb7TmmLmzEM4Io/zKNKFUZhevRd5W3qNmqsjQ0pq5y5co2fSy8cu4iX4NDCv5kz57dNvUMX4OvvvqqzWrQfZeuumoiVOvWrW2UPZwOdSzt2rUzrtKVO2VtaGqIphh8/vnnZtq0afaqg9a/fv164yLWhXihzy69rysbRX0blN0VZqPo5npQRWNllXWoiwHhZ7R6SCVu7ukiX9fl89p8XRfcoeCdjqU0Itcnvq6rWbNm9phXFzo0WVTvF+rlGG8IovzLdFW5YsWKTo8p9ZmPwSE9dr3JNmzY0PYQ0Zuu6g2/+OIL2zTY9YCej8444wzzzTff2LRMjYTU+GZNOdCkpdKlS5v9+/cbF7EuxCu956vn0FtvvXXMPg4AADcvJqpHiCYe6oJotmzZkh2buMjXdYkmer333ntm7Nix9kKHzlcUTFF/TjWmjgcEUf5lmnv94osvmrVr1xpXqTfIp59+ategcgr1DVEU1OU/Vp8pC0W9XvSmo34auq/Gssp0UGBFc+ZdkZrgo8uvRzUDVgdyTYbS2G1lRKlLua6cK8PG1fcP1oV4ofICldgqE0U3ZSLq/UUNq5WR4loTZzUPj0pjIl3h67p8Xpuv64Lb5ZuhxGXg+hzQ964GzX1dV0plgW+//bYZMWKELQdUdls8YDrPSaJJKLEvaJ2s/vHHHzaI4qo333zT3HnnnclOZpWmP3z4cNtEzFWa6PL7778nq9FV52ttc/XNSGnq+/btSxgP1rZt24T+Iq5lRGl6xt9NgPLhw8PX8c2sC/FC73/KNlSKsIImGhV5+eWX2/cYFzVv3jzJ93oPjB1hH753uvTe6Ou6fF6br+uCu5R57SNf1xXbU1RtMBYsWGAvIObPn9/ECzJRTpJHHnkkxSZ2qrVWSpKLlLlQrVo1e3KnZnxahz4YdZVcJ0eqeVXjy3isW4tCz5ECXbFBlI0bN9reFK6WUOhKjyYr1ahRw6b8/fLLL6Zw4cJm+vTpNiCmRq2uUCZGVDox8s2BAwdssE+d2H3CuvBvmzJlig2auJyxdiwKlqsMdcCAAebSSy+12+bNm2cefvhhu00lgi7ydV0+r83XdQE4+QEilfJ88MEHtsRWDeB1/qmM5r+7mPpvIYiCyDp06GCv3KlGLSXXXnutPSBVupVLhg4dar8qMKQgg8pfQrpKog7yin4q9dtF6qOhGfJqRqq56yoPCder9YXrBwC4r3z58jYzNGwmHlJd+W233ZYwMtI1vq7L57X5ui64SVnZOibWhcXEVMbpMt/WVbhwYTths0GDBjZw0qRJk7gc20w5z0luUqqmnfqqkcfKcJg6daopVqyYHVnqGk0GOV4pUufOne3JumvC2ndl1ejDXlf6E5fCqJeItrtKr7fJkycn2+5azX8sdfpPiSLUGvumdcfjm+6pNr6Zdbn1fMF9OuZIqSxJZbeu9lPyeV0+r83XdcEtaqWgC8E6B0uJq2Vlvq6rX79+5rrrrov78lqCKCex7EDjclVCoUyGxx9/3AZRNAHg9ddft70NXKOyluONfdTPNmzYYFyj8hapVauWGT9+vFMjf6OWYan8I5wwNGnSJBvc04hjvVEpUOQiTbk6XqBBa1aPnpdfftkGVeKdglo5cuSw91Ue5wvWBfy7Lr74YtOtWzfzxhtvJNSPb9682fTo0cNUrVrV2afD13X5vDZf1wW33HPPPWbnzp22r4baKkyYMMG+Dvv3728GDRpkXOXrujp16mScEOCkuOSSS4JBgwbZ+9mzZw9Wr15t7y9YsCAoXLiwk3s9Xbp0webNm4/5802bNgXp06f/Vx8T/t5FF10UvP/++/a+XoeZM2cO2rRpE5x77rnB3Xff7ewunDhxYlC6dOngtddeC77//nt70/0yZcoE77zzTvDmm28GRYoUCbp3757WDxUA/jUrV64MypcvH5x++ulByZIl7U33y5UrZ3/mKl/X5fPafF0X3FKgQAF7/iU5cuQIfv75Z3t/0qRJQY0aNQJX+bouV5CJcpL88MMPtiFOLGWjbN261bhq2rRpNg0zJYqGukxpb6NGjTIzZswwW7ZssY2MEvv888+Ni1QioqwNUT+bmjVr2temyrNat27tbNaDsrtUJle/fv2Ebcq2KVKkiOndu7dZuHChyZYtm+nevbt55plnTLzzdXwz63Lr+YL7NM1L5Y6ffvqpWb58ud1WpkwZOzI9Xhry/RO+rsvntfm6Lrjlzz//TBgaoWxzlcEoe17HjMrWdpWv63IFQZSTRHVcGpdbvHjxJNvVnFQNc1zVrl274/7c5Q/Fu+++2wZRGjVqZJuhubyWxNTrJQwIqVN+48aN7f2iRYs6HdBToPLss89Otl3b9DNR8Eh/hy7wdXwz63Lr+YIf9D5Rr149e/OJr+vyeW2+rgvuKF26tPn5559tj0NNEFWZd9jvsGDBgsZVvq7LFQRRThJd4ddYN1351weITmJ15f++++4zbdu2NS6KzczwjUY0v/vuu6Zhw4bGJxdddJGtj9SVH/XqeemllxJ6wcTTvPXU0ojtJ554wrzyyisJfV00T17bwjHi6tHjyho1zs1HrAv49ymj8lhZla5N0DsV1uXz2nxdF9y6SBpeUOvbt6+d+vLmm2/aY8fRo0cbV/m6Llcw4vgk0ZipLl262MwGXYXMmDGj/XrDDTfYbYknwCA+FCpUyMycOfO4zXNdpFRajQjT+DM1eNMbrdx1111m27ZtKZadueCrr74yTZs2NenTp08Y46YMFP2daRrRJZdcYpvZbdq0yTaxA4BTwSOPPGIeffRRG0DX1cjYDDc1H3SRr+vyeW2+rgvG+ZHAKi/TFEdNRPSFr+uKVwRRTjKduC5dutTs3bvXVKpUyZQqVepk/5P4h9TJes2aNeb555/3ppTneA4cOGCDeZpi46o9e/aYt956y/Z9CVMbFagMp9y4yrfxzSHWBZx8Oll96qmnzM033+zV7vZ1XT6vzdd1wS26gHi8Yyr17mnWrJnJnTu3cYmv63IFQRTgv1q0aGFLD/RmU65cuWTBBY0/Bv4Nyq7xaXxziHW59XzBTXny5LGNtUuWLGl84uu6fF6br+uCW2rVqmUbrSpTWRfbRBffdCFR5d/qK6Jjrjlz5piyZcsaV/i6LlcQRPkXIoIpGTx48In8p3ECdOjQ4bg/HzlypDP7WYEgvZEqnU8du493Qr59+/Z/9bHh702aNMn2VFIZUtWqVe02HYgqW0rlWEeOHDG9evWygRQXJg+FWJdbzxfcpPeO7Nmz2yllPvF1XT6vzdd1wS2aQjl79mx7HB9Oy9u1a5e59dZbzWWXXWY6depks5j3799vp5C6wtd1uYIgygmOCEba6enSOTsuF25QQyk1N1bJx981l/q7iUv49ylw8thjjyUZ3yz6EAzHN0+cONGOb169erUzTxHrcuv5grvNBseMGWN7RekWm1Xp6kUcX9fl89p8XRfcoqmoGrMdm43x448/2qlRGkKgjA7dd2lqpa/rcgXTeU4gX6dQxFq/fr0NBBUpUsR+rxM6NSfVH/Ftt92W1g8PMYERgiTu8W18c4h1ufV8wU3qPaT3B1FPtsRc7vfl67p8Xpuv64JblJ2h6VCxwYY//vjD7N69297PmTOnHQriEl/X5QqCKEg1pYYpWKJGYZp8UrduXdtDRA0+9X2fPn2c3avvv/++HXOshsCxbzqK5roifPOMIkwBRPzwbXxziHW59XzBTb5e0PF1XT6vzdd1wS1qrtqxY0dbEn3xxRfbbV9//bW57777TPPmzRMuCLs2ndPXdbmCIMpJtGjRomOekLvcpFRXE8I+DVpf+fLlzdy5c8306dNN586dnQ2iDB061Dz00EOmffv2tneDeqQo9V5vSBpX7RJFnv/uKk8QBPZ31JDKRT5nRL3wwgt2fLPWltL4ZtEkqTvuuMO4hHW59XzBbatWrbKfYTVr1jRZsmRJeM93na/r8nltvq4LblAT/nvvvdeWuaunnGTMmNFmaj/77LMJF3lee+014xJf1+UKeqKcJO+8845p27at7Wmg4ILq0dToc/PmzXYKjEtNSmOpSZgCKeecc4490atRo4ZtHqZgkbpDq4GRi/RGo6adbdq0sSNyv/vuO1OiRAkbFFLzVY0+dsWsWbMi/+4VV1xhXHT55ZcnyYjSa08ZUStXrjR33XWXs8E838c3sy7g5Nq2bZu5/vrrbRaATlT1nqjPMl2xVKNxXbV0ka/r8nltvq4Lbtq7d6+9ACV6Hep8xge+rivuBTgpKlSoEDz//PP2fvbs2YPVq1cHR48eDTp16hT06dPH6b1etWrVoGfPnsGXX34ZZM6cOViyZIndPm/evKBw4cKBq7JkyRKsXbvW3s+XL1/CulasWBHkzp07jR8dYuXMmTNYvny5vT9kyJCgevXq9v60adOC4sWLs8MAnJJuvvnmoH79+sH69esTjj/kk08+CcqWLRu4ytd1+bw2X9cFAJTznCRKW2zUqJG9r54Gf/75p43CK+2qdu3a5pFHHjGuevLJJ202zdNPP21Txi688EK7/cMPP0wo83FRgQIFbMaJmncWK1bMzJ8/367tl19+samnLjd2S4lej5kzZ7Zr1RQf16hHSPi4P/vsM5sVFWYUudZwFQBOFGW/apJXWOoYKlWqlFm3bp2zO9rXdfm8Nl/XBQAEUU4SpSkqbT0cQaXylwoVKpidO3eaffv2Of3Ku/LKK+2oLDUv1TpDKq3ImjWrcZWCWwoEVapUyfZDUcBLjWbV26Zly5bGVeqMf7zaY40cbNWqla2tVFDFFSrdGT58uA1WasSbRgLLxo0bTZ48edL64QFAmtBFm5Q+i3WRwMWAue/r8nltvq4LANKzC04ONc/SiZ1cd9115u677zadOnWy/Tauuuoq53d7hgwZkgRQRD1SzjrrLOMqTUJRY1lRI9kRI0aYMmXKmEcffdS89NJLxlUTJkywV320viVLltib7qvHhhqxvv766+bzzz83Dz/8sHEtI0qBHwX19HflS0YUAPyv/aLGjBmT8L2C6EePHjVPPfWUqVWrlrM719d1+bw2X9cFADSWPcGUcaJpNYqyHzhwwBQqVCjhA+Orr76yJ7M6WY0NQMS7ypUrmxkzZtjHrUyN42U2uDQK+FSggIKyNNTkODGl2Pbu3dtOtZk4caLp3r27LUNziabVxGZErV271l75cjmgBwD/1I8//mgzK/W5rQC5Sh21TcclmqRXsmRJJ3eur+vyeW2+rgsAKOc5wTSOVLO6b731VjtyStKnT2969erl9KtNs8jD1Mtw9rhvPvnkE9vR+rLLLksYx/rqq6/akbm671rgK6TRuOrzEkvb9LOw5MfFPiLqVfPNN9/Y4E84uUY9iFwuK/N5fDPrAk5+r6iuXbuajz76yGbD6j1RkxtUkqoMy4IFCzr5FPi6Lp/X5uu6AMCit+6JpYk1HTp0CHLkyBFky5YtaNu2rd2G+Fe+fPlgypQp9v73338fnH766cEDDzwQXHLJJUH79u0DV1WsWDFo165dcPDgwYRthw4dstv0M5kzZ05wzjnnBC7RJKXzzz8/yJo1a5AhQ4aErv9du3YNbr/99sBll112WTBmzBh7//fffw/OOOOM4NJLLw3y5s0bPPLII4GrWBdw8ul9QlPlfOPrunxem6/rAgB6opyE+k/10tBV/WHDhtnSgiuuuMKcd955tofDpk2bCN/FKU3h0ZV++eCDD0yTJk3MgAEDbBbK1KlTjav0+CdPnmyzGurUqWNvuq9tYa8XzZe/4447jEvUZ+iiiy4yO3bsMFmyZEnYrslRKj1zvSww7Ovy7rvv2hJBlQO+9dZbZtSoUcZVrAs4+W666Sbb68o3vq7L57X5ui4AoJznJMmWLZud8KLbqlWrzMiRI+3JrHpQNGjQwDa/dJXKk47XE0V9KlykMpBwcpJG5rZt29bez507t+274arq1avbAJFOwFesWJHQ7Dgsf5Gbb77ZuGb27Nk2sKDnLbbB8YYNG4zLfB3fzLqAk+/IkSP2Yo7eO6pUqWKPRxIbPHiwk0+Dr+vyeW2+rgsACKL8C84991zz4IMP2h4UDzzwgJkyZYrTrzxNe4k9MVq8eLEZPXq0eeSRR4yr1AulW7dupkaNGrYHxbhx4+x2BR7C3hSuUrCkc+fOxidq2JxSwO63335LCA65ytfxzawL+HcyvtTIU8LAeeh4F0Dina/r8nltvq4LAJjOc5J9+eWXNgqv8hBlcFx//fXmlltuMZdccol3rz41vlTgYdKkScZFv/76qy1pUfNLNUPT8yT33nuvPVkfOnRoWj9EJNKqVStz5pln2nHNCpp8//33Jl++fLYJcrFixWz2l6tmzpxpy5KUAdWuXTv7HiIKxi5fvtyMHz/euIh1AQAAwHUEUU4CXS1W3wLdVMqjcgqdkCuAEpvK6BP11dB0InVfB042ZZxobLMm9KxcudL2R9HXvHnz2uCl6yOOfR3fzLoAAADgMsp5TrCrr77a1n7qRE49NTp27GhKly5tfLd//36bqVG4cGHjqm+//dacdtpppkKFCvZ7ZdQom0HNZvv165es9wbSlkqsvvvuO5v9pK8K3ilYeeONNyZpNOsqX8c3sy4AAAC4jEyUE0wNIHUi17hxY5MhQwbjI10ZT1zLqpOiPXv22JO7N998M6EJpmsuvvhi06tXL3PNNdfYrBr1b1BJxddff217Uzz33HNp/RBxili3bp1tQK0Ss4MHD9pa8hIlStiJRPpe/VJcxLoAAADgOjJRTjCXp+5EFRtMUK8X9aKoVq1aktID1+hEtWLFivb+e++9Z2rWrGn7vMydO9e0bt3a2SCKerwo6BU2x1XTXK1LGTa33XabcdXAgQNN/vz5bbZXYuof8scff5iePXsaV4Xjm5Vhk7iRrIJ6nTp1Mq5iXQAAAHAdQRSkmhpd+kgZNZr4IirJUjaRFC1a1GzdutW4SqUgCpZojPGmTZtM3bp1bZaNRh7r+z59+hgXvfzyyzYYFEtrU9DL5SCKr+ObWRcAAABcRxAF/8iOHTvM66+/bpYtW2a/V1ZDhw4dTO7cuZ3do7ry379/f1OnTh0za9Ys89JLL9ntv/zyi814cHnEYNWqVe39d99915QvX95m10yfPt2OPXY1iKIAUMGCBZNtV1bU77//blzm6/hm1gUAAADXpU/rBwD3aPKJroirkayCKbrpfvHixe3PXKVyHTWXvfPOO81DDz1kzj33XLv9/ffftxOWXHX48GGTKVOmhAybsGfN+eef73SwQRlCCgbF0rZChQoZl9WrVy9J+ZjKsdQ4t2/fvqZhw4bGVawLAAAArqOxLFJN02suvfRSm6kRNs/VVfM77rjDliD88MMPXu3VAwcO2HVqco+L1KumVq1atjmuTmLnz59vLrzwQvv12muvtdkNLnrqqafs7emnnza1a9e222bMmGHuv/9+0717d/PAAw8YV/k6vpl1AQAAwHUEUZBqGh+7ZMmSZKObf/75Z9uYVeOOET9mzpxpG5Lu3r3b9rNR41V58MEHzfLly8348eONixRg0DQlZUEdOnTIbsucObPtheJqiVJiR44cSTK+uXLlyl6Mb2ZdAAAAcBlBFKRajRo1TI8ePUzz5s2TbJ84caJ54oknbIaDK9TDRVN5dIU/dnRzrO3btxtXKVNIQZTE05PWrl1rx1K7mtUQUoBBvXkUXChVqlRC6RIAAAAAnGg0lkWqde3a1Y4qXbVqlbnkkkvsNgVOXnjhBRtE+f777xN+94ILLojrPfzss88mNOp0dYRx1KyNb775xqxevdpO69GaNflFQRTXZc+e3Vx88cXGJ76Ob2ZdAAAAcB2ZKEi19OmP349Y2Rw6adfXlCaM4N+1bt0606BBA/Prr7+agwcP2sybEiVK2ECYvh8+fLiTT8mff/5pg3bqg7Jly5aE8dShNWvWGFepcbPGN8c2NF6wYIEd36yJUS5iXQAAAHAdmShINVdP4FKiEpeozjjjDOMiBUvUmFS9NfLkyZOwXX1SOnXqZFx166232lHUN998sx11fLxSLNf4Or6ZdQEAAMB1BFGQameffbY3ey1nzpx/e/LtelbN7Nmz7dQkle/EZgVs2LAhzR7X/2rq1KlmypQptkePb8LxzRob7tP4ZtYFAAAA1xFEwT/yxhtv2DIQZaXMmzfPBlbUU0Qnfc2aNXNmr37xxRfGdypzSSkApHGzYT8YF6lJrhoD+0gZQvfcc485fPhwiuObXcW6AAAA4Dp6oiDVXnrpJTtCVid5jz/+uFm6dKntsTFq1CgzevToUyIw4ZJWrVqZM88807zyyis2aKLGvyoLUbCrWLFiZuTIkcZFb775ppk0aZJ9zfnQIPdUGN/MugAAAOA6gihItbJly5oBAwbYEcc6KVevDQVRFEy58sorzdatW53cq4mnCiWmUh6dwCrg4OL4XGWc1K9f357Arly50vZH0VeNdf7yyy+dHXFcqVIlO21I61Jp0mmnnZbk599++61xna/jm1kXAAAAXEUQBammE7rly5fbEp7EQRSdmGuk8f79+52dOnS8/ig6SVdWx8svv2yDKi45cuSIGTdunH2udAJbuXJlc+ONN9rn0lWPPPLIcX/et2/ff+2xAAAAADg10BMFqaa+J0uWLEnWYPaTTz4xZcqUcXaPTpgwwZZL9OjRw1StWtVuW7hwoRk0aJA9IVcgQiUWDz/8sHnmmWeMSzJmzGiDJrr5wucgia/jm1kXAAAAXEcQBanWrVs306VLF3PgwAFbSqFAw9tvv20GDhxoXnvtNWf3qPq7DBkyxJa+hCpUqGCKFClievfubdeZLVs229jTpSCKnpf8+fObjh07Jtk+YsQI88cff9jAEeKLr+ObWRcAAABcRzkP/pG33nrL9OvXz/akEI1dVXnFLbfc4uweVWnL4sWLzfnnn59ku0qX1H9DZUpr1661PWH27dtnXKF+IWPHjjXVq1dPsn3BggWmdevWdsKSizRx6NlnnzXvvvuu+fXXXxMasIa2b99uXB697eP4ZtYFAAAA16VP6wcAN6ksRD1Q1F9j06ZNtnmpywEUUfBEJRSJT8Y1YlbbwsDKhg0bbFaHS/T8KJshlib0/P7778ZVCtoNHjzY9qnZtWuXzZBq2bKl7W2jAJ/LfB3fzLoAAADgOoIo+Ec0gWfRokV2ckiGDBm82IsvvPCCmTx5si3fqVOnjr3pvrZprHPYi+KOO+4wLilatKiZO3dusu3apgwil7OhXn31VVtepZ4vbdq0seVkGgE8f/5847LHHnvMrsOljKcoWBcAAABcRzkPUuXHH380//nPf5KdlF9xxRU20FC6dGmn9+iePXvsyfmKFSvs91rPDTfcYKcQueqpp56yt6efftrUrl3bblPD0vvvv98GIB544AHjIvWnURBPo6eVaaPyF00dUqBL5VfKTnGVr+ObWRcAAABcR2NZpKosRMESlYGojEIlLjrJ++mnn2xGwOWXX26WLl1qzjrrLGf3qoIlnTt3Nj7RtKFt27bZDJqwVEkjmtVQ1tUAiihLSOVICqKULFnSTJ8+3QZRvv76a5MpUybjsubNmxsfsS4AAAC4jkwURKaT7s8++8xmoegkPDE1Xb3ssstMvXr17DQYxB/1r1HmhhrolipVyvlAg8ZNn3HGGebBBx8048aNMzfddJPN2lCT2Xvvvdf2sgEAAACAE4kgCiLTVX6duF5//fUp/vydd96xZSOulhrAbfPmzbM3BYiaNGmS1g8HAAAAgIcIoiBV40nVTPbcc89N8eerVq0yF110kdm5cyd7NY78+eefNitDfVC2bNlijh49muTn6iGC+OLr+GbWBQAAANfREwWparqq8onj9RNRyQjiy6233mpmzZplbr75ZtuANV26dMYXGzduNHPmzEkxONS1a1fj8vhmTRpS49+HH37YPPTQQ2bt2rVm4sSJdmqPq1gXAAAAXEcmCiLTKGNNrVFj2ZRs3rzZNpvV1WYXrV+/3gYY1LBUFi5caMaOHWvKli1rbrvtNuNyBpEm19SoUcP4ZNSoUeb22283p59+usmTJ0+S4JDuu5xho0a5Q4cONY0aNbLBySVLliRs0/hmvS5dxLoAAADguvRp/QDgDk3iOe+880yuXLlSvLk+3lijjL/44ouESUR169a1gRRlATz66KPGVXpucufObXzTu3dvm5WhUcbK0vjll18Sbi4HUMLXX4UKFez97NmzJ4xrbty4sQ2IuYp1AQAAwHWU8yCyMMDgK41nrlq1qr2vXhTly5e3k4g0Oldjj10to3jsscfsYx89erTJmjWr8cW+fftM69atTfr0/sWCfR3fzLoAAADgOoIoiOyKK67wem8dPnw44QRVo5ybNm1q76tESSe0rho0aJBZvXq1yZ8/vx0BfNpppyX5uavTlG655Rbz3nvv2YlRvmnRooVtBFytWjVz11132fHNr7/+esL4ZlexLgAAALiOnijAf+mEtVatWrYPRb169WzviQsvvNB+vfbaa81vv/3mbDPP4+nbt69xkXrvqLxl//79tvQlNjg0ePBg4wtfxzezLgAAALiGIArwXzNnzrRXynfv3m3atWtnRowYYbc/+OCDZvny5Wb8+PHsqzjSv39/W6akXjzKsoltLPv555+n6eMDAAAA4B+CKEBMdoOCKGrGGlLTUvUSOeuss9hXcUTP0bPPPmvat29vfOTr+GbWBQAAAJcRRAESOXLkiM1IUQ8RTevReFmd9J1xxhl2SoqrgSEFG9QsVz01Dh06lOTn27dvNy4qUKCAmT17ti1x8Y2v45tZFwAAAFxHEAX/M2VuqHRCZRVlypRxdo+uW7fONGjQwAYaDh48aFasWGFKlChh7r77bvv98OHDjYtU8vLaa6+Z7t27m4cfftiObFZ2zcSJE+3PXM1qGDhwoG34O3ToUOObokWL2olQDzzwgFfTh1gXAAAAXEcQBal2/fXXm5o1a5o777zTNvVU81WdlAdBYN555x1zzTXXOLlXmzdvbjNPNAVFV/+/++47G0RRZkqnTp3MypUrjYs0IleBBjXM1fqWLFmSsE1Nc8eOHWtcpP41Ct7puSpXrlyyxrIu97DRmhYuXGifJ5+wLgAAALjOn0uc+Nd8+eWX5vLLL7f3J0yYYIMnO3futCflavbpKpWGKFNDJRSJaSzwhg0bjKs2bdpkp9eISpJ27dpl72uyzZQpU4yrcubMaVq2bGlHb+fNm9eceeaZSW4uC8c3+4Z1AQAAwHUZ0/oBwD06Cc+dO7e9/8knn9jMEzVeVaZDjx49jKvUvFP9Q2JptLEyOFxVpEgRW/ZSrFgxm9kwffp0U7lyZfP111+bTJkyGVd712gctUZRqzeKb1SqpCCX/r58Gt/MugAAAOA6gij4R30N5s2bZwMpOslTCY/s2LHDZM6c2dk9qhPy5557zrzyyisJDTz37t1r+vbtaxo2bGhcpbKXGTNmmGrVqpm77rrL3HTTTbZkSb1f7r33XuOijBkz2p4hy5YtMz5SsGHatGm2z5DENpZ1FesCAACA6+iJglR78cUXbbNVlYYou2Hx4sW2+eWwYcNsH4ovvvjCyb2qjJP69evb8iT1P7nooovsV5WKqITJlxHHCoDppqk2TZo0Ma668sorzT333GN72fjG1/HNrAsAAACuI4iCf2TRokVm/fr1pm7dugmjf9VfQ30qatSo4exeVZnIuHHjbFNZZaGo7OXGG280WbJkSeuHhhga2azpNcqmqVKlismWLVuSn19wwQXO7jNfxzezLgAAALiOIAr+sUOHDplffvnF9tlQeQXi18aNG82cOXPMli1bbO+XxFwdcZzS6F+VuiiTSF9T6m/jCl/HN7MuAAAAuI4gClJt3759trfG6NGj7fcrVqywo4C1rXDhwqZXr17OnuDlz5/fdOzYMcn2ESNGmD/++MP07NnTuGjUqFHm9ttvt1OHNGI2tr/GmjVrjIvWrVt33J+fffbZxlW+jm9mXQAAAHAd6QNINZVQqNxl5syZpkGDBgnb69SpY/r16+dsEOXll182Y8eOTbZdJ7GtW7d2NojSu3dv06dPH/u8pZS94SqXgyRRxzf7hnUBAADAdQRRkGoTJ060fUMuueSSJFkNCjasXr3a2T26adMmU7BgwWTb8+XLZ0srXM4cUhDIpwBKSK83TVQKp/SULVvWNj1WiZmrfB3fzLoAAADgA//OqnDSqbQlpUk1f/75p9PjVzW6ee7cucm2a1uhQoWMq2655Rbz3nvvGd9oBLCCJgsXLrRNZHVbsGCBDeZ9+umnxlXh+OaDBw8an7AuAAAA+IBMFKSaRv9qEo96oEgYOHnttdfMpZde6uwe7dSpkx2Ze/jwYVO7dm27bcaMGeb+++833bt3N65Sr5fGjRubTz75xFSoUCFZf43BgwcbF6lsTJN5nnjiiWTbVXqlyVGuqlq1qh0d7lvJEusCAACA6wiiINUGDBhgrr76avPTTz/ZFP0hQ4bY+1999ZWZNWuWs3u0R48eZtu2beaOO+6wk4ckc+bM9oRc/URcDqIoa6N06dL2+9jGsq5SCY/GHMdSY2CV+LhMr0EF7n777TevxjezLgAAALiO6Tz4x70olAGgBrN79+41lStXtsEGZTq4TuvRCXqWLFlMqVKlTKZMmYzLcuXKZZ599lnTvn174xOVXymL5rrrrkuyXYGV++67z/z666/GVb6Ob2ZdAAAAcB2ZKPhH1Ljz1Vdf9XLvZc+e3Vx88cXGFwoC1ahRw/hG5Ve33XabHdFcvXr1hP41Tz75pOnWrZtx2S+//GJ8xLoAAADgOjJRkGoZMmSw02pim8uqFEbbXL1Krsa4yq5RH5QtW7aYo0ePJvm5TtZdLefR8zV06FDjE2VlqGxn0KBBZuPGjXabGgCrLKtr165OlyoBAAAAiE8EUfCPUvI1Djg2iKITWWWo7N+/38m92qZNG9vT5eabb7ajjmNPwjU610UtWrQwn3/+ucmTJ4+dXBPbWHb8+PHGFR9++KHtxxO7hj179tivOXLkML7wcXyzsC4AAAC4jHIeRBZmMii4oEk8KnsJKfvkyy+/NOeff76ze3Tq1Kl26pBvpS85c+Y0LVu2ND5QQEgBvHz58iXJiPIpeCJqBNy0aVNTsWLFhNejSpUUBPvoo4+cnTzEugAAAOA6MlEQWfHixe3XdevWmSJFitiT2NDpp59uzjnnHPPoo4+aatWqObu+jz/+2JQpU8b4QtOTxo4da+rVq2cKFChgXKc1qBdPkyZNbEbU5s2bbUDFN5UqVTL169dPcXzz9OnTzbfffmtcxLoAAADgOoIoSLVatWrZEhBNffHJm2++aSZNmmRGjx5tsmbNanyhtagk5Oyzzzau69evnw3URel34mpvnnC09g8//GCnQyW2YsUKO974wIEDxkWsCwAAAK6jnAep9sUXX3i519SgVP0a8ufPb7NqYvtuuHr1v2rVqmbx4sXeBFFat25tVq1aZctdRo4cacuVfKPsmiVLliQLomhbbC8il7AuAAAAuI4gClJNV/hHjRp1zCk2amLqoubNmxsf3XHHHaZ79+7mt99+M1WqVDHZsmVL8nNlNrhEfXdKly5t2rVrZ6655pokvXl84ev4ZtYFAAAA11HOg1S78847bRClUaNGKU6xefbZZ9mrcUS9Q2LpOdOIYH11sexFgTuVhvz444/JsjV84Ov4ZtYFAAAA1xFEQarlzZvXjBkzxjRs2JC95wA1Aj4eV8t8NKnm9ddfN5dcconxga/jm1kXAAAAfEIQBammK+IzZ8405513nld7TxkZyqJ59913za+//moOHTqU5Ofbt29Ps8eG5DTq96mnnjIvvfSSKV++vPO7SNOuUhrf7DrWBQAAAJ8kz/MH/ob6awwZMsSm5vvkkUceMYMHDzatWrUyu3btsr0nWrZsacth1NDUZWqYe9ddd5k6derYm0pCtM1lbdu2NQsXLjQXXnihyZIli8mdO3eSm2sUPJk/f769H5Za+YB1AQAAwCc0lkWqzZkzx07omTp1qi2piC0/0PhjF7311lvm1Vdftb1eFDRp06aNKVmypG28qpNbBR5cNG3aNDvJpmLFiqZGjRoJTUr13Cmbo27dusZF6hnik86dO5tmzZrZ4IluBQoUOObvutTHhnW59XwBAADg+CjnQap16NDhuD/X2FkXaWrNsmXLTLFixWzD3ClTppjKlSvbCSmVKlWy2Sku0mOvX7++eeKJJ5Js79Wrl5k+fbqzo5t9tHz58kjjmxVscQnrcuv5AgAAwLERRAH+S2Nz1TC3WrVq5rLLLjONGze2gYZx48bZUhiNc3aRptj88MMPyabYrFixwmbZHDhwwLhKJUkKNuirSszUQ0QZUgqEKdPGRSrl6dixoxk2bJhX45tZFwAAAHxATxTgv1q0aGFmzJhh7yto0rt3bxt4UO8NndS63JNiyZIlybZrm8uNS2fNmmUqVKhgFixYYEvI9u7da7d/9913pm/fvsblYINKy9RY1iesCwAAAD6gJwr+kffff/+YU2xcLQ9JXO6i5rLKZpg3b54NpDRp0sS4qlOnTua2226zZUnVq1dP6Iny5JNP2ua5rlKWUP/+/e0aEo//rV27tnn++eeNq9TIWK+5bdu2JcsechnrAgAAgA/IREGqDR061PZFyZ8/v1m8eLGpWrWqyZMnjz1Jv/rqq73Zo5deeqk9QXc5gCLKqOnTp48tD7niiivsTUEGNc99+OGHjatUoqTsoVjKrtm6datxmQJ6PXr0MEuXLjU+YV0AAABwHT1RkGrnn3++LZfQ9BplAKh8okSJEvZEffv27U5nAWzcuNFOH1L/k6NHjyb5mUvTeT788EMb0IqdnLRnzx77NXHmhquKFClis6GUXZP4dThhwgRz3333OT3COVeuXGbfvn3myJEj5vTTT7cjnBPT35mLWBcAAABcRzkPUk0lPGFZiE7uwhPzm2++2VxyySXOBlFGjRplbr/9dnvSqswajZkN6b5LQRRlaGzatMn2Q8mQIYPtr6EMDR+CJ6HWrVubnj17mvfee88+Pwp6qUxJART1sXGZb+ObQ6wLAAAAriMTBammq/0ffPCBHZ170UUX2Z4bCj5oXK5ObF29Sl60aFHTuXNn88ADD9j+DS4rUKCAefXVV20pktayefNmG1DxiXrxdOnSxQa//vrrL5MxY0b79YYbbrDbFDwCAAAAgBPJ7TNFpAk17lS5iKg3yr333mvq1q1rm7Gm1KPCFSqfUBDI9QCKKBjUrFkzG0hQloaCKrqf0s1VyhhSoEi9eCZPnmzefPNNs3z5cvPGG284va6QypHUs0Zlc+F4bY1v/vHHH43LWBcAAABcRiYKUk1lE7rpyr+888475quvvrKTRMJyGBfdf//9Jnfu3Hbqiw8UUFi1apVp2rSpGTlypMmZM2eKv6dgi0v02nv66adtIE/ZKFdddZXt0RPbN8RlGt+snjY1atQwX375pVm2bJnNAFNj1kWLFtnpWC5iXQAAAHAdQRTgv1QK0rhxY7N//35ToUKFZE1ZBw8e7Ny+CoLAdOzY0U7myZ49u/HBY489ZicL1alTxwZOpk2bZrM1RowYYXyaDHXdddcljG8Om+YuXLjQtGzZ0vz222/GRawLAAAArnO/bgH/uk8++cROsAm98MILpmLFirYXxY4dO5x9RgYOHGhPyNU/RONzNb45vC1ZssS4SEGUt956yzaW9cWYMWPMiy++aJ+riRMnmo8++siuMXaakst8Hd/MugAAAOA6gihItR49epjdu3cnnBTpannDhg3NL7/8Yu+7atCgQTabQaUTM2fONF988UXC7fPPPzcuUn8XlVlt27bN+DQdSq+3kDJS1PdF46l9odKrlAJfCugVLlzYuIp1AQAAwHUEUZBqCpaULVvW3teUHk2AGTBggM1IUeNLV2XKlMn2oPCN+mgo8LV06VLjgyNHjpjMmTMn2abSq8OHDxvfxjdrTLVP45tZFwAAAFxHTxSkmpqvqpxHgZTLLrvMntTddtttZu3atXabpty4Ws6jq/9Dhw41PsmVK5d9ThR8UNPf2Aasro2kVnaNmq4q6BVSSY+mRmXLli1h2/jx442rfB3fzLoAAADgOoIoSDVNe9HJkLI21ORTmSkqMZg+fbq58847zYoVK5zcq+pBobKdPHnymHLlyiVrLOvqSfno0aOP+/N27doZl2isdhSaSOS69evX25K5vXv3mkqVKtnSLB+wLgAAALiKIAr+UU+KO+64w54Ide3a1dxyyy12+7333muvlruayfF3J+c+nJQjvvk6vpl1AQAAwBcEUYD/9tkYO3asqVevnilQoIB3+2T16tU2CKSvQ4YMsVNe1L+mWLFiNusG8cHX8c2sCwAAAL4giIJU+/bbb22pS4UKFez3kyZNsifo6oeiE0D13XBR1qxZ7WSes88+2/hk1qxZtoeIyq++/PJLu8YSJUrYhrOLFi0y77//flo/RPyXynXUPPb222+333/22WemUaNGZv/+/bYXjKtYFwAAAHzh7lE50oxO8MK+J2vWrLETNxSAeO+998z999/v7DNTtWpVO0LWN7169TL9+/c3n376aZIAlxqxzp8/P00fG06N8c2sCwAAAL7ImNYPAO5RAKVixYr2vgInNWvWtKUwGsGqgMpzzz1nXKQ+L927dze//fabqVKlSpJJL3LBBRcYF6kxqZ6fWCrp2bp1a5o8Jpxa45tZFwAAAHxBEAWpFgSBbRQZlhs0btzY3i9atKjTJ+UKAIma5YaUBaD16qua5rooZ86cdnRz8eLFk2xX1o2mKiF+6LXWvn37JOObDxw4YDp37uz0+GbW5dbzBQAAgGMjiIJUu+iii2x5iEoN1G/jpZdests16jh//vzO7lE9fh8pONSzZ0+bNaRgkAJgyhpS7422bdum9cPD34ybvummm5zfR6wLAAAAvqCxLFLt+++/NzfeeKPtc9CtWzc7glXuuusus23bthRLR5B2NCq3S5cuZtSoUTabJmPGjPbrDTfcYLdlyJCBpwcAAAAAIiCIghNGZQc6IVcPB1dpBLB6umiCjWji0N13321KlixpXLd+/XrbH2Xv3r2mUqVKdmIKAAAAACA6gijAf02bNs00bdrUNs3VOGBR2ct3331nPvroI1O3bl2n9pXKdp5++mnz4Ycf2myUq666ymYNZcmSJa0fGgAAAAA4iSAKIsmdO7edypM3b16TK1cu21vjWLZv3+7kXlV2Rv369c0TTzyRbETw9OnTzbfffmtc8thjj5l+/frZ3jUKnChI1KZNGzNixIi0fmgAAAAA4CSCKIhk9OjRtkGppobofmqbSLpAo2VV7hJb5qLgkcYbq1zJJVqHmsfefvvtCZOUGjVqZPbv32/Sp0+f1g8PAAAAAJzDdB5Ekjgw4mqQ5O/ky5fPLFmyJFkQRdvOOuss4xo1/m3YsGHC98pIUQbRxo0bTZEiRdL0sQEAAACAiwiiIJLdu3dH3lNnnHGGk3u1U6dO5rbbbjNr1qwx1atXT+iJ8uSTT9opRK45cuSIza5JTE1/Dx8+nGaPCQAAAABcRjkPIlH5x/H6oEgQBPZ3ND7XRXr8mswzaNAgm60hhQoVMj169DBdu3b92/XH43N29dVX2xKskBrk1q5d22TLli1h2/jx49PoEQIAAACAWwiiIJJZs2ZF3lNXXHGFM3tVk2sUaIgdy7xnzx77NUeOHMZVHTp0iPR7I0eOPOmPBQAAAAB8QBAFp7QMGTKYTZs22X4ouv/777872f8EAAAAAHDy0RMFqfb999+nuF3lLurBUaxYsSQlJPFMwZP58+ebJk2aJJQjAQAAAACQEoIoSLWKFSseN9ig0phWrVqZl19+OVlj03jTuXNn06xZM7se3QoUKHDM33W11wsAAAAA4MSgnAepNmnSJNOzZ0/bcLVq1ap228KFC21D1r59+9qpML169bKBlGeeeSbu9/Dy5cvNqlWrTNOmTW1/kJw5c6b4ewq2AAAAAABOXQRRkGoKnDz22GOmfv36SbZPmzbN9O7d2wZUJk6caLp3725Wr17txB5WKU/Hjh3NsGHDTPbs2dP64QAAAAAA4lD6tH4AcM8PP/xgzj777GTbtU0/C0t+1KTVFQqivPXWW049ZgAAAADAv4sgClLt/PPPN0888YQ5dOhQwrbDhw/bbfqZbNiwweTPn9+ZvZs+fXpTqlQps23btrR+KAAAAACAOEVjWaTaCy+8YPuHFClSxFxwwQV2mzJQ1Hh18uTJ9vs1a9aYO+64w6m9qyCQ+ry89NJLpnz58mn9cAAAAAAAcYaeKPhH9uzZY8tfVqxYYb8vXbq0ueGGG0yOHDmc3aO5cuUy+/bts41xTz/9dJMlS5YkP9++fXuaPTYAAAAAQNojiAL81+jRo4+7L9q1a8e+AgAAAIBTGEEUAAAAAACACGgsCySikcwPP/ywadOmjdmyZYvdNnXqVPPjjz+ynwAAAADgFEcQBfivWbNmmQoVKpgFCxaY8ePHm71799rt3333nenbty/7CQAAAABOcQRRgP/q1auX6d+/v/n0009tY9lQ7dq1zfz589lPAAAAAHCKI4iCVFu/fr357bffEr5fuHChueeee8wrr7zi9N7UmOYWLVok237WWWeZrVu3psljAgAAAADED4IoSDWNMv7iiy/s/U2bNpm6devaQMpDDz1kHn30UWf3aM6cOc3vv/+ebPvixYtN4cKF0+QxAQAAAADiB0EUpNrSpUtN1apV7f13333XlC9f3nz11VfmrbfeMqNGjXJ2j7Zu3dr07NnTBobSpUtnjh49aubOnWvuu+8+07Zt27R+eAAAAACANEYQBal2+PBhkylTJnv/s88+M02bNrX3zz///BQzOVwxYMAAu4aiRYvaprJly5Y1NWvWNNWrV7cTewAAAAAAp7Z0QRAEaf0g4JZq1aqZWrVqmUaNGpl69erZpqsXXnih/Xrttdcm6Zfias8X9UdRIKVSpUqmVKlSaf2QAAAAAABxIGNaPwC458knn7QNWJ9++mnTrl07G0CRDz/8MKHMxyUq29Fa9PgPHTpkrrrqKjvSOEuWLGn90AAAAAAAcYRMFPwjf/31l9m9e7fJlStXwra1a9earFmz2mk2LnnsscdMv379TJ06dWzgZNq0aaZNmzZmxIgRaf3QAAAAAABxhCAK/pEjR46YmTNnmtWrV9tpPTly5DAbN240Z5xxhsmePbtTe1XlOmoee/vttyf0eVGp0v79+0369LQNAgAAAAD8H4IoSLV169aZBg0amF9//dUcPHjQrFixwpQoUcLcfffd9vvhw4c7tVfVJHfVqlW2oWwoc+bMdluRIkXS9LEBAAAAAOIHl9mRagqWXHTRRWbHjh1J+oaoT8qMGTOczKpR0CSx0047zU4hAgAAAAAgRGNZpNrs2bPNV199ZU4//fQk28855xyzYcMG5/aoBlS1b98+YWyzHDhwwHTu3Nlky5YtYdv48ePT6BECAAAAAOIBQRT8o2k2aiwbS6ON1RvFNZowFOumm25Kk8cCAAAAAIhf9ERBqrVq1cqceeaZ5pVXXrFBk++//97ky5fPNGvWzBQrVsyMHDmSvQoAAAAA8A5BFKSaMk7q169vy2BWrlxp+6Poa968ec2XX37p3IhjAAAAAACiIIiCf9yMddy4cea7774ze/fuNZUrVzY33nhjkkazAAAAAAD4hCAKAAAAAABABIw4RqoNHDjQjBgxItl2bXvyySfZowAAAAAALxFEQaq9/PLL5vzzz0+2vVy5cmb48OHsUQAAAACAlwiiINU2bdpkChYsmGy7JvT8/vvv7FEAAAAAgJcIoiDVihYtaubOnZtsu7YVKlSIPQoAAAAA8FLGtH4AcE+nTp3MPffcYw4fPmxq165tt82YMcPcf//9pnv37mn98AAAAAAAOCmYzoNUC4LA9OrVywwdOtQcOnTIbsucObPp2bOn6dOnD3sUAAAAAOAlgij4x/bu3WuWLVtmsmTJYkqVKmUyZcrE3gQAAAAAeIsgCgAAAAAAQAT0REGq/fnnn+aJJ56wfVC2bNlijh49muTna9asYa8CAAAAALxDEAWpduutt5pZs2aZm2++2Y46TpcuHXsRAAAAAOA9ynmQajlz5jRTpkwxNWrUYO8BAAAAAE4Z6dP6AcA9uXLlMrlz507rhwEAAAAAwL+KIApS7bHHHrOjjPft28feAwAAAACcMijnQapVqlTJrF692gRBYM455xxz2mmnJfn5t99+y14FAAAAAHiHxrJItebNm7PXAAAAAACnHDJRAAAAAAAAIqAnCgAAAAAAQASU8yDV/vrrL/Pss8+ad9991/z666/m0KFDSX6+fft29ioAAAAAwDtkoiDVHnnkETN48GDTqlUrs2vXLtOtWzfTsmVLkz59etOvXz/2KAAAAADAS/REQaqVLFnSDB061DRq1MjkyJHDLFmyJGHb/PnzzdixY9mrAAAAAADvkImCVNu0aZOpUKGCvZ89e3abjSKNGzc2U6ZMYY8CAAAAALxEEAWpVqRIEfP777/b+8pAmT59ur3/9ddfm0yZMrFHAQAAAABeIoiCVGvRooWZMWOGvX/XXXeZ3r17m1KlSpm2bduajh07skcBAAAAAF6iJwr+Z/PmzbM3BVKaNGnCHgUAAAAAeIkgCgAAAAAAQAQZo/wSEGvjxo1mzpw5ZsuWLebo0aNJfta1a1d2GAAAAADAO2SiINVGjRplbr/9dnP66aebPHnymHTp0v3/F1S6dGbNmjXsVQAAAACAdwiiINWKFi1qOnfubB544AGTPj29iQEAAAAApwbOgJFq+/btM61btyaAAgAAAAA4pRBEQardcsst5r333mPPAQAAAABOKZTzINX++usv07hxY7N//35ToUIFc9pppyX5+eDBg9mrAAAAAADvMJ0HqTZw4EAzbdo0U7p0aft9bGNZAAAAAAB8RCYKUi1Xrlzm2WefNe3bt2fvAQAAAABOGfREQaplypTJ1KhRgz0HAAAAADilEERBqt19991m2LBh7DkAAAAAwCmFch6kWosWLcznn39u8uTJY8qVK5essez48ePZqwAAAAAA79BYFqmWM2dO07JlS/YcAAAAAOCUQhAFqXLkyBFTq1YtU69ePVOgQAH2HgAAAADglEE5D1Ita9asZtmyZebss89m7wEAAAAAThk0lkWqVa1a1SxevJg9BwAAAAA4pVDOg1S74447TPfu3c1vv/1mqlSpYrJly5bk5xdccAF7FQAAAADgHcp5kGrp0ydPYEqXLp0JgsB+/euvv9irAAAAAADvkImCVPvll1/YawAAAACAUw6ZKAAAAAAAABGQiYJ/ZPXq1ea5556zU3qkbNmy5u677zYlS5ZkjwIAAAAAvMR0HqTatGnTbNBk4cKFtomsbgsWLDDlypUzn376KXsUAAAAAOAlynmQapUqVTL169c3TzzxRJLtvXr1MtOnTzfffvstexUAAAAA4B2CKEi1zJkzmx9++MGUKlUqyfYVK1bYrJQDBw6wVwEAAAAA3qGcB6mWL18+s2TJkmTbte2ss85ijwIAAAAAvERjWaRap06dzG233WbWrFljqlevbrfNnTvXPPnkk6Zbt27sUQAAAACAlyjnQaoFQWAn8wwaNMhs3LjRbitUqJDp0aOH6dq1q0mXLh17FQAAAADgHYIoiOTDDz80V199tTnttNOSbN+zZ4/9miNHDvYkAAAAAMBrBFEQSYYMGcymTf+vvft3xXaP4wD+8etBDCxSGI0G/wKjIhsSslBWIikLpSzkD+AvMFgMLAbFJKEMt8lAwiTk5+m+6tE5Oadz3U+dns51v151x/1xD3fvTO+u7+d7nexDyf9+dXVl/wkAAABFxWJZUsmXJwcHB1/HeRzZAQAAoNhYLEsq4+Pj0dPTk5Qn+VdjY+M/fvb9/V2qAAAAZI7jPKR2fn4euVwuuru7Y319Perq6v72c/myBQAAALJGiUJB8kd5RkdHY21tLWpra6UHAABA0VCiUJCPj4+oqqqKs7OzaG1tlR4AAABFw2JZCvuHKS1NypO7uzvJAQAAUFSUKBRsaWkppqam4vT0VHoAAAAUDcd5KFh9fX08Pj7G29tb/PjxI6qrq//y9/v7e6kCAACQOa44pmArKytSAwAAoOh4EgUAAAAgBTtR+CUXFxcxNzcX/f39cXNzk8y2t7eTW3sAAAAgi5QoFGxvby/a2tri8PAwNjc34+HhIZkfHx/H/Py8RAEAAMgkJQoFm5mZiYWFhdjZ2UkWy/7U0dERBwcHEgUAACCTlCgU7OTkJHp7e7/NGxoa4vb2VqIAAABkkhKFgtXV1cXV1dW3+dHRUTQ1NUkUAACATFKiULC+vr6Ynp6O6+vrKCkpiY+Pj9jf34/JyckYGhqSKAAAAJnkimMK9vLyEhMTE7GxsRHv7+9RXl6e/BwYGEhmZWVlUgUAACBzlCj8ssvLy2Q/Sv52nvb29mhtbZUmAAAAmVX+u78A/x/5YzvLy8uxtbWVPI3S2dmZXGlcXV39u78aAAAA/OfsRCG1xcXFmJ2djdra2mSB7OrqanKsBwAAAIqB4zyklj+uk18eOzY2lrzf3d2Nrq6ueHp6itJSfRwAAADZpkQhtcrKysjlctHS0vI1q6qqSmbNzc2SBAAAINM8PkBqb29vSWnyZxUVFfH6+ipFAAAAMs9iWVL7/PyMkZGR5ImUn56fn2N8fDxqamq+Zpubm1IFAAAgc5QopDY8PPxtNjg4KEEAAACKgp0oAAAAACnYiQIAAACQghIFAAAAIAUlCgAAAEAKShQAAACAFJQoAAAAACkoUQAAAABSUKIAAAAApKBEAQAAAEhBiQIAAAAQ/+4PL0fZMGE6U2gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "sns.heatmap(\n",
    "    df_lagged.isna(),\n",
    "    yticklabels=False,\n",
    "    cbar=False\n",
    ")\n",
    "plt.title(\"Missing values heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b2b9535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>weekly_mean</th>\n",
       "      <th>rendement_lag_1</th>\n",
       "      <th>rendement_lag_2</th>\n",
       "      <th>rendement_lag_3</th>\n",
       "      <th>rendement_lag_4</th>\n",
       "      <th>returns</th>\n",
       "      <th>garch_vol</th>\n",
       "      <th>garch_vol_lag_1</th>\n",
       "      <th>garch_vol_lag_2</th>\n",
       "      <th>vol_future_2w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>549.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.33</td>\n",
       "      <td>2.47</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>38.14</td>\n",
       "      <td>-0.827123</td>\n",
       "      <td>11613.8460</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.004610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>548.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.23</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.53</td>\n",
       "      <td>10.83</td>\n",
       "      <td>9.63</td>\n",
       "      <td>36.87</td>\n",
       "      <td>-0.696358</td>\n",
       "      <td>11532.9720</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.004539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>545.32</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1.90</td>\n",
       "      <td>10.52</td>\n",
       "      <td>8.99</td>\n",
       "      <td>36.51</td>\n",
       "      <td>-1.441762</td>\n",
       "      <td>11366.6940</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>544.22</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.08</td>\n",
       "      <td>4.55</td>\n",
       "      <td>10.38</td>\n",
       "      <td>8.71</td>\n",
       "      <td>35.47</td>\n",
       "      <td>-0.126193</td>\n",
       "      <td>11352.3500</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>546.67</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.58</td>\n",
       "      <td>8.68</td>\n",
       "      <td>11.52</td>\n",
       "      <td>9.36</td>\n",
       "      <td>35.74</td>\n",
       "      <td>0.097636</td>\n",
       "      <td>11363.4340</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.001298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>747.63</td>\n",
       "      <td>17.17</td>\n",
       "      <td>0.89</td>\n",
       "      <td>7.61</td>\n",
       "      <td>18.52</td>\n",
       "      <td>33.91</td>\n",
       "      <td>39.30</td>\n",
       "      <td>44.95</td>\n",
       "      <td>0.954530</td>\n",
       "      <td>19493.9240</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.014799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>740.59</td>\n",
       "      <td>16.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.85</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32.80</td>\n",
       "      <td>39.53</td>\n",
       "      <td>42.39</td>\n",
       "      <td>-0.037494</td>\n",
       "      <td>19486.6150</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.017265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>18751.5620</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.013888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>18255.5225</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>18500.0160</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.003946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "0   2021-02-12              549.92   \n",
       "1   2021-02-19              548.67   \n",
       "2   2021-02-26              545.32   \n",
       "3   2021-03-05              544.22   \n",
       "4   2021-03-12              546.67   \n",
       "..         ...                 ...   \n",
       "223 2025-10-31              747.63   \n",
       "224 2025-11-07              740.59   \n",
       "225 2025-11-14              726.77   \n",
       "226 2025-11-21              715.36   \n",
       "227 2025-11-28              723.81   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "0                                            2.15   \n",
       "1                                            1.92   \n",
       "2                                            1.30   \n",
       "3                                            1.09   \n",
       "4                                            1.55   \n",
       "..                                            ...   \n",
       "223                                         17.17   \n",
       "224                                         16.06   \n",
       "225                                         13.90   \n",
       "226                                         12.11   \n",
       "227                                         13.43   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "0                                 0.23                            7.33   \n",
       "1                                 0.23                            7.05   \n",
       "2                                 0.61                            6.71   \n",
       "3                                 0.20                            6.08   \n",
       "4                                 0.45                            6.58   \n",
       "..                                 ...                             ...   \n",
       "223                               0.89                            7.61   \n",
       "224                               0.94                            5.85   \n",
       "225                               1.87                            3.89   \n",
       "226                               1.57                            1.21   \n",
       "227                               1.18                            2.42   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "0                            2.47                          11.25   \n",
       "1                            1.53                          10.83   \n",
       "2                            1.90                          10.52   \n",
       "3                            4.55                          10.38   \n",
       "4                            8.68                          11.52   \n",
       "..                            ...                            ...   \n",
       "223                         18.52                          33.91   \n",
       "224                         16.00                          32.80   \n",
       "225                         13.26                          29.74   \n",
       "226                         11.56                          27.49   \n",
       "227                         13.34                          29.42   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "0                            10.05                          38.14   \n",
       "1                             9.63                          36.87   \n",
       "2                             8.99                          36.51   \n",
       "3                             8.71                          35.47   \n",
       "4                             9.36                          35.74   \n",
       "..                             ...                            ...   \n",
       "223                          39.30                          44.95   \n",
       "224                          39.53                          42.39   \n",
       "225                          35.37                          39.45   \n",
       "226                          32.53                          36.14   \n",
       "227                          33.47                          38.04   \n",
       "\n",
       "     Variation %  weekly_mean  rendement_lag_1  rendement_lag_2  \\\n",
       "0      -0.827123   11613.8460             0.19             0.56   \n",
       "1      -0.696358   11532.9720             0.23             0.19   \n",
       "2      -1.441762   11366.6940             0.23             0.23   \n",
       "3      -0.126193   11352.3500             0.61             0.23   \n",
       "4       0.097636   11363.4340             0.20             0.61   \n",
       "..           ...          ...              ...              ...   \n",
       "223     0.954530   19493.9240             2.30             0.26   \n",
       "224    -0.037494   19486.6150             0.89             2.30   \n",
       "225    -3.772092   18751.5620             0.94             0.89   \n",
       "226    -2.645324   18255.5225             1.87             0.94   \n",
       "227     1.339285   18500.0160             1.57             1.87   \n",
       "\n",
       "     rendement_lag_3  rendement_lag_4  returns  garch_vol  garch_vol_lag_1  \\\n",
       "0               0.71             0.18   0.0023   0.005896         0.005777   \n",
       "1               0.56             0.71   0.0023   0.005920         0.005896   \n",
       "2               0.19             0.56   0.0061   0.005929         0.005920   \n",
       "3               0.23             0.19   0.0020   0.005852         0.005929   \n",
       "4               0.23             0.23   0.0045   0.005919         0.005852   \n",
       "..               ...              ...      ...        ...              ...   \n",
       "223             0.83             1.51   0.0089   0.008109         0.006085   \n",
       "224             0.26             0.83   0.0094   0.006902         0.008109   \n",
       "225             2.30             0.26   0.0187   0.006384         0.006902   \n",
       "226             0.89             2.30   0.0157   0.007349         0.006384   \n",
       "227             0.94             0.89   0.0118   0.007228         0.007349   \n",
       "\n",
       "     garch_vol_lag_2  vol_future_2w  \n",
       "0           0.005751       0.004610  \n",
       "1           0.005777       0.004539  \n",
       "2           0.005896       0.003482  \n",
       "3           0.005920       0.003377  \n",
       "4           0.005929       0.001298  \n",
       "..               ...            ...  \n",
       "223         0.006339       0.014799  \n",
       "224         0.006085       0.017265  \n",
       "225         0.008109       0.013888  \n",
       "226         0.006902       0.008930  \n",
       "227         0.006384       0.003946  \n",
       "\n",
       "[228 rows x 20 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged.reset_index(drop = True, inplace = True)\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f765950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged.to_csv(\"final_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3fa1bd",
   "metadata": {},
   "source": [
    "# **Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "297cc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "03144733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Valeur Liquidative</th>\n",
       "      <th>Performances glissantes Depuis Début d'année</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>Performances glissantes 6 mois</th>\n",
       "      <th>Performances glissantes 1 an</th>\n",
       "      <th>Performances glissantes 2 ans</th>\n",
       "      <th>Performances glissantes 3 ans</th>\n",
       "      <th>Performances glissantes 5 ans</th>\n",
       "      <th>Variation %</th>\n",
       "      <th>...</th>\n",
       "      <th>rendement_lag_3</th>\n",
       "      <th>rendement_lag_4</th>\n",
       "      <th>returns</th>\n",
       "      <th>garch_vol</th>\n",
       "      <th>garch_vol_lag_1</th>\n",
       "      <th>garch_vol_lag_2</th>\n",
       "      <th>vol_future_2w</th>\n",
       "      <th>vol_future_2w_1</th>\n",
       "      <th>vol_future_2w_2</th>\n",
       "      <th>vol_future_2w_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>545.32</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1.90</td>\n",
       "      <td>10.52</td>\n",
       "      <td>8.99</td>\n",
       "      <td>36.51</td>\n",
       "      <td>-1.441762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>544.22</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.08</td>\n",
       "      <td>4.55</td>\n",
       "      <td>10.38</td>\n",
       "      <td>8.71</td>\n",
       "      <td>35.47</td>\n",
       "      <td>-0.126193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>546.67</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.58</td>\n",
       "      <td>8.68</td>\n",
       "      <td>11.52</td>\n",
       "      <td>9.36</td>\n",
       "      <td>35.74</td>\n",
       "      <td>0.097636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>545.78</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.16</td>\n",
       "      <td>6.88</td>\n",
       "      <td>12.27</td>\n",
       "      <td>11.08</td>\n",
       "      <td>9.43</td>\n",
       "      <td>34.87</td>\n",
       "      <td>1.075538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>545.27</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7.21</td>\n",
       "      <td>11.96</td>\n",
       "      <td>11.63</td>\n",
       "      <td>9.01</td>\n",
       "      <td>34.09</td>\n",
       "      <td>-0.308019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>747.63</td>\n",
       "      <td>17.17</td>\n",
       "      <td>0.89</td>\n",
       "      <td>7.61</td>\n",
       "      <td>18.52</td>\n",
       "      <td>33.91</td>\n",
       "      <td>39.30</td>\n",
       "      <td>44.95</td>\n",
       "      <td>0.954530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.016367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>740.59</td>\n",
       "      <td>16.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.85</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32.80</td>\n",
       "      <td>39.53</td>\n",
       "      <td>42.39</td>\n",
       "      <td>-0.037494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.017439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>726.77</td>\n",
       "      <td>13.90</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>29.74</td>\n",
       "      <td>35.37</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-3.772092</td>\n",
       "      <td>...</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.009153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>715.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.53</td>\n",
       "      <td>36.14</td>\n",
       "      <td>-2.645324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.014799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>723.81</td>\n",
       "      <td>13.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.34</td>\n",
       "      <td>29.42</td>\n",
       "      <td>33.47</td>\n",
       "      <td>38.04</td>\n",
       "      <td>1.339285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.017265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Valeur Liquidative  \\\n",
       "2   2021-02-26              545.32   \n",
       "3   2021-03-05              544.22   \n",
       "4   2021-03-12              546.67   \n",
       "5   2021-03-19              545.78   \n",
       "6   2021-03-26              545.27   \n",
       "..         ...                 ...   \n",
       "223 2025-10-31              747.63   \n",
       "224 2025-11-07              740.59   \n",
       "225 2025-11-14              726.77   \n",
       "226 2025-11-21              715.36   \n",
       "227 2025-11-28              723.81   \n",
       "\n",
       "     Performances glissantes Depuis Début d'année  \\\n",
       "2                                            1.30   \n",
       "3                                            1.09   \n",
       "4                                            1.55   \n",
       "5                                            1.38   \n",
       "6                                            1.29   \n",
       "..                                            ...   \n",
       "223                                         17.17   \n",
       "224                                         16.06   \n",
       "225                                         13.90   \n",
       "226                                         12.11   \n",
       "227                                         13.43   \n",
       "\n",
       "     Performances glissantes 1 semaine  Performances glissantes 6 mois  \\\n",
       "2                                 0.61                            6.71   \n",
       "3                                 0.20                            6.08   \n",
       "4                                 0.45                            6.58   \n",
       "5                                 0.16                            6.88   \n",
       "6                                 0.09                            7.21   \n",
       "..                                 ...                             ...   \n",
       "223                               0.89                            7.61   \n",
       "224                               0.94                            5.85   \n",
       "225                               1.87                            3.89   \n",
       "226                               1.57                            1.21   \n",
       "227                               1.18                            2.42   \n",
       "\n",
       "     Performances glissantes 1 an  Performances glissantes 2 ans  \\\n",
       "2                            1.90                          10.52   \n",
       "3                            4.55                          10.38   \n",
       "4                            8.68                          11.52   \n",
       "5                           12.27                          11.08   \n",
       "6                           11.96                          11.63   \n",
       "..                            ...                            ...   \n",
       "223                         18.52                          33.91   \n",
       "224                         16.00                          32.80   \n",
       "225                         13.26                          29.74   \n",
       "226                         11.56                          27.49   \n",
       "227                         13.34                          29.42   \n",
       "\n",
       "     Performances glissantes 3 ans  Performances glissantes 5 ans  \\\n",
       "2                             8.99                          36.51   \n",
       "3                             8.71                          35.47   \n",
       "4                             9.36                          35.74   \n",
       "5                             9.43                          34.87   \n",
       "6                             9.01                          34.09   \n",
       "..                             ...                            ...   \n",
       "223                          39.30                          44.95   \n",
       "224                          39.53                          42.39   \n",
       "225                          35.37                          39.45   \n",
       "226                          32.53                          36.14   \n",
       "227                          33.47                          38.04   \n",
       "\n",
       "     Variation %  ...  rendement_lag_3  rendement_lag_4  returns  garch_vol  \\\n",
       "2      -1.441762  ...             0.19             0.56   0.0061   0.005929   \n",
       "3      -0.126193  ...             0.23             0.19   0.0020   0.005852   \n",
       "4       0.097636  ...             0.23             0.23   0.0045   0.005919   \n",
       "5       1.075538  ...             0.61             0.23   0.0016   0.005852   \n",
       "6      -0.308019  ...             0.20             0.61   0.0009   0.005944   \n",
       "..           ...  ...              ...              ...      ...        ...   \n",
       "223     0.954530  ...             0.83             1.51   0.0089   0.008109   \n",
       "224    -0.037494  ...             0.26             0.83   0.0094   0.006902   \n",
       "225    -3.772092  ...             2.30             0.26   0.0187   0.006384   \n",
       "226    -2.645324  ...             0.89             2.30   0.0157   0.007349   \n",
       "227     1.339285  ...             0.94             0.89   0.0118   0.007228   \n",
       "\n",
       "     garch_vol_lag_1  garch_vol_lag_2  vol_future_2w  vol_future_2w_1  \\\n",
       "2           0.005920         0.005896       0.003482              NaN   \n",
       "3           0.005929         0.005920       0.003377         0.003482   \n",
       "4           0.005852         0.005929       0.001298         0.003377   \n",
       "5           0.005919         0.005852       0.002761         0.001298   \n",
       "6           0.005852         0.005919       0.002797         0.002761   \n",
       "..               ...              ...            ...              ...   \n",
       "223         0.006085         0.006339       0.014799         0.009153   \n",
       "224         0.008109         0.006085       0.017265         0.014799   \n",
       "225         0.006902         0.008109       0.013888         0.017265   \n",
       "226         0.006384         0.006902       0.008930         0.013888   \n",
       "227         0.007349         0.006384       0.003946         0.008930   \n",
       "\n",
       "     vol_future_2w_2  vol_future_2w_3  \n",
       "2                NaN              NaN  \n",
       "3                NaN              NaN  \n",
       "4           0.003482              NaN  \n",
       "5           0.003377         0.003482  \n",
       "6           0.001298         0.003377  \n",
       "..               ...              ...  \n",
       "223         0.017439         0.016367  \n",
       "224         0.009153         0.017439  \n",
       "225         0.014799         0.009153  \n",
       "226         0.017265         0.014799  \n",
       "227         0.013888         0.017265  \n",
       "\n",
       "[226 rows x 23 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged['vol_future_2w_1'] = df_lagged['vol_future_2w'].shift(1)\n",
    "df_lagged['vol_future_2w_2'] = df_lagged['vol_future_2w'].shift(2)\n",
    "df_lagged['vol_future_2w_3'] = df_lagged['vol_future_2w'].shift(3)\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "01c69ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c2a1fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"vol_future_2w\"   \n",
    "\n",
    "\n",
    "df_model = df_lagged.copy()\n",
    "\n",
    "#X = df_model.drop(columns=[TARGET])\n",
    "#X = df_model[[\"vol_future_2w_1\", \"vol_future_2w_2\", \"vol_future_2w_3\", \"returns\", \"rendement_lag_1\", \"rendement_lag_2\"]]\n",
    "X = df_model[[\"vol_future_2w_1\", \"vol_future_2w_2\", \"vol_future_2w_3\", \"Performances glissantes 1 semaine\", \"garch_vol\", \"Variation %\"]]\n",
    "#X = df_model[[\"vol_future_2w_1\", \"vol_future_2w_2\", \"vol_future_2w_3\"]]\n",
    "y = df_model[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52a956ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=[\"Date\", \"Valeur Liquidative\", \"weekly_mean\" , \"Performances glissantes 1 semaine\", \"garch_vol_lag_1\", \"garch_vol_lag_2\", \"Performances glissantes Depuis Début d'année\", \"Performances glissantes 1 an\", \"Performances glissantes 2 ans\", \"Performances glissantes 3 ans\", \"Performances glissantes 5 ans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b65a0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "split_idx = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "de58521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_future_2w_1</th>\n",
       "      <th>vol_future_2w_2</th>\n",
       "      <th>vol_future_2w_3</th>\n",
       "      <th>Performances glissantes 1 semaine</th>\n",
       "      <th>garch_vol</th>\n",
       "      <th>Variation %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>1.075538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>-0.308019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.626972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.214423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.716789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.954530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>-0.037494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>-3.772092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>-2.645324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>1.339285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vol_future_2w_1  vol_future_2w_2  vol_future_2w_3  \\\n",
       "5           0.001298         0.003377         0.003482   \n",
       "6           0.002761         0.001298         0.003377   \n",
       "7           0.002797         0.002761         0.001298   \n",
       "8           0.002527         0.002797         0.002761   \n",
       "9           0.002628         0.002527         0.002797   \n",
       "..               ...              ...              ...   \n",
       "223         0.009153         0.017439         0.016367   \n",
       "224         0.014799         0.009153         0.017439   \n",
       "225         0.017265         0.014799         0.009153   \n",
       "226         0.013888         0.017265         0.014799   \n",
       "227         0.008930         0.013888         0.017265   \n",
       "\n",
       "     Performances glissantes 1 semaine  garch_vol  Variation %  \n",
       "5                                 0.16   0.005852     1.075538  \n",
       "6                                 0.09   0.005944    -0.308019  \n",
       "7                                 0.38   0.006029     0.626972  \n",
       "8                                 0.11   0.005913     0.214423  \n",
       "9                                 0.34   0.006002     0.716789  \n",
       "..                                 ...        ...          ...  \n",
       "223                               0.89   0.008109     0.954530  \n",
       "224                               0.94   0.006902    -0.037494  \n",
       "225                               1.87   0.006384    -3.772092  \n",
       "226                               1.57   0.007349    -2.645324  \n",
       "227                               1.18   0.007228     1.339285  \n",
       "\n",
       "[223 rows x 6 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00d32e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=2000,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5660cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=0.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa5f9a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, min_samples_leaf=2, n_estimators=2000,\n",
       "                      n_jobs=-1, random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=criterion,-%7B%22squared_error%22%2C%20%22absolute_error%22%2C%20%22friedman_mse%22%2C%20%22poisson%22%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%22squared_error%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"},             default=\"squared_error\"<br><br>The function to measure the quality of a split. Supported criteria<br>are \"squared_error\" for the mean squared error, which is equal to<br>variance reduction as feature selection criterion and minimizes the L2<br>loss using the mean of each terminal node, \"friedman_mse\", which uses<br>mean squared error with Friedman's improvement score for potential<br>splits, \"absolute_error\" for the mean absolute error, which minimizes<br>the L1 loss using the median of each terminal node, and \"poisson\" which<br>uses reduction in Poisson deviance to find splits.<br>Training using \"absolute_error\" is significantly slower<br>than when using \"squared_error\".<br><br>.. versionadded:: 0.18<br>   Mean Absolute Error (MAE) criterion.<br><br>.. versionadded:: 1.0<br>   Poisson criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D1.0\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=1.0<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None or 1.0, then `max_features=n_features`.<br><br>.. note::<br>    The default of 1.0 is equivalent to bagged trees and more<br>    randomness can be achieved by setting smaller values, e.g. 0.3.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to 1.0.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.r2_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonically increasing<br>  - 0: no constraint<br>  - -1: monotonically decreasing<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multioutput regressions (i.e. when `n_outputs_ > 1`),<br>  - regressions trained on data with missing values.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, min_samples_leaf=2, n_estimators=2000,\n",
       "                      n_jobs=-1, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eae8bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.002981\n",
      "MAE  : 0.001416\n",
      "R²   : 0.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 2000 out of 2000 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = rf.predict(X_train)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6b58ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.006059\n",
      "MAE  : 0.003972\n",
      "R²   : 0.1865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 2000 out of 2000 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5e043c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive R2: 0.2825617110660017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\714085508.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  y_naive = y_test.shift(1).fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "y_naive = y_test.shift(1).fillna(method=\"bfill\")\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Naive R2:\", r2_score(y_test, y_naive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eddbab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.006404735160123848)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged[\"vol_future_2w\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a65a79",
   "metadata": {},
   "source": [
    "## **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff2f2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f18e8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a24e9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [2, 4, 10, 16],\n",
    "    \"min_child_weight\": [2, 10, 20, 30],\n",
    "    \"subsample\": [0.6, 0.8, 1],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1],\n",
    "    \"learning_rate\": [0.02, 0.04, 0.08],\n",
    "    \"n_estimators\": [300, 600]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e0dd2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ff3d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=tscv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "60083ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-23.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-23.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-23 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-23 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-23 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-23 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-23 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-23 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-23 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-23 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-23 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False,\n",
       "                                    eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "                                    feature_weights=None, gamma=No...\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=-1, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1],\n",
       "                         &#x27;learning_rate&#x27;: [0.02, 0.04, 0.08],\n",
       "                         &#x27;max_depth&#x27;: [2, 4, 10, 16],\n",
       "                         &#x27;min_child_weight&#x27;: [2, 10, 20, 30],\n",
       "                         &#x27;n_estimators&#x27;: [300, 600],\n",
       "                         &#x27;subsample&#x27;: [0.6, 0.8, 1]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">XGBRegressor(...ree=None, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;colsample_bytree&#x27;: [0.6, 0.8, ...], &#x27;learning_rate&#x27;: [0.02, 0.04, ...], &#x27;max_depth&#x27;: [2, 4, ...], &#x27;min_child_weight&#x27;: [2, 10, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;neg_root_mean_squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">TimeSeriesSpl...est_size=None)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=&#x27;rmse&#x27;, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=600, n_jobs=-1,\n",
       "             num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=objective,-typing.Union%5Bstr%2C%20xgboost.sklearn._SklObjWProto%2C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%2C%20NoneType%5D\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=base_score,-typing.Union%5Bfloat%2C%20typing.List%5Bfloat%5D%2C%20NoneType%5D\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: typing.Union[float, typing.List[float], NoneType]<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=callbacks,-typing.Optional%5Btyping.List%5Bxgboost.callback.TrainingCallback%5D%5D\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.Optional[typing.List[xgboost.callback.TrainingCallback]]<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bylevel,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: typing.Optional[float]<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bynode,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: typing.Optional[float]<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bytree,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: typing.Optional[float]<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=device,-typing.Optional%5Bstr%5D\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=early_stopping_rounds,-typing.Optional%5Bint%5D\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: typing.Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=eval_metric,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Union%5Bstr%2C%20typing.Callable%5D%5D%2C%20typing.Callable%2C%20NoneType%5D\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: typing.Union[str, typing.List[typing.Union[str, typing.Callable]], typing.Callable, NoneType]<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;rmse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_types,-typing.Optional%5Btyping.Sequence%5Bstr%5D%5D\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Optional[typing.Sequence[str]]<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=gamma,-typing.Optional%5Bfloat%5D\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: typing.Optional[float]<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=grow_policy,-typing.Optional%5Bstr%5D\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: typing.Optional[str]<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=interaction_constraints,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%2C%20NoneType%5D\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: typing.Union[str, typing.List[typing.Tuple[str]], NoneType]<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=learning_rate,-typing.Optional%5Bfloat%5D\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: typing.Optional[float]<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.02</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_bin,-typing.Optional%5Bint%5D\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: typing.Optional[int]<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_threshold,-typing.Optional%5Bint%5D\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: typing.Optional[int]<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_delta_step,-typing.Optional%5Bfloat%5D\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: typing.Optional[float]<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_depth,-%20typing.Optional%5Bint%5D\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  typing.Optional[int]<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_leaves,-typing.Optional%5Bint%5D\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: typing.Optional[int]<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=min_child_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: typing.Optional[float]<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=monotone_constraints,-typing.Union%5Btyping.Dict%5Bstr%2C%20int%5D%2C%20str%2C%20NoneType%5D\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Union[typing.Dict[str, int], str, NoneType]<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=multi_strategy,-typing.Optional%5Bstr%5D\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_estimators,-typing.Optional%5Bint%5D\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: typing.Optional[int]<br><br>Number of gradient boosted trees.  Equivalent to number of boosting<br>rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">600</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_jobs,-typing.Optional%5Bint%5D\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: typing.Optional[int]<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=random_state,-typing.Union%5Bnumpy.random.mtrand.RandomState%2C%20numpy.random._generator.Generator%2C%20int%2C%20NoneType%5D\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_alpha,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: typing.Optional[float]<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_lambda,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: typing.Optional[float]<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=sampling_method,-typing.Optional%5Bstr%5D\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: typing.Optional[str]<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=scale_pos_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: typing.Optional[float]<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=subsample,-typing.Optional%5Bfloat%5D\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: typing.Optional[float]<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=tree_method,-typing.Optional%5Bstr%5D\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: typing.Optional[str]<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=validate_parameters,-typing.Optional%5Bbool%5D\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: typing.Optional[bool]<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=verbosity,-typing.Optional%5Bint%5D\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: typing.Optional[int]<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-23');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False,\n",
       "                                    eval_metric='rmse', feature_types=None,\n",
       "                                    feature_weights=None, gamma=No...\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=-1, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.6, 0.8, 1],\n",
       "                         'learning_rate': [0.02, 0.04, 0.08],\n",
       "                         'max_depth': [2, 4, 10, 16],\n",
       "                         'min_child_weight': [2, 10, 20, 30],\n",
       "                         'n_estimators': [300, 600],\n",
       "                         'subsample': [0.6, 0.8, 1]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "07727d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 1, 'learning_rate': 0.02, 'max_depth': 2, 'min_child_weight': 10, 'n_estimators': 600, 'subsample': 0.6}\n",
      "Best CV RMSE: 0.004222983784383379\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV RMSE:\", -grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1797fe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-24.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-24.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-24 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-24 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-24 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-24 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-24 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-24 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-24 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-24 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=&#x27;rmse&#x27;, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=600, n_jobs=-1,\n",
       "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" checked><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=objective,-typing.Union%5Bstr%2C%20xgboost.sklearn._SklObjWProto%2C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%2C%20NoneType%5D\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=base_score,-typing.Union%5Bfloat%2C%20typing.List%5Bfloat%5D%2C%20NoneType%5D\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: typing.Union[float, typing.List[float], NoneType]<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=callbacks,-typing.Optional%5Btyping.List%5Bxgboost.callback.TrainingCallback%5D%5D\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.Optional[typing.List[xgboost.callback.TrainingCallback]]<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bylevel,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: typing.Optional[float]<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bynode,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: typing.Optional[float]<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bytree,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: typing.Optional[float]<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=device,-typing.Optional%5Bstr%5D\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=early_stopping_rounds,-typing.Optional%5Bint%5D\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: typing.Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=eval_metric,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Union%5Bstr%2C%20typing.Callable%5D%5D%2C%20typing.Callable%2C%20NoneType%5D\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: typing.Union[str, typing.List[typing.Union[str, typing.Callable]], typing.Callable, NoneType]<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;rmse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_types,-typing.Optional%5Btyping.Sequence%5Bstr%5D%5D\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Optional[typing.Sequence[str]]<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=gamma,-typing.Optional%5Bfloat%5D\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: typing.Optional[float]<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=grow_policy,-typing.Optional%5Bstr%5D\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: typing.Optional[str]<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=interaction_constraints,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%2C%20NoneType%5D\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: typing.Union[str, typing.List[typing.Tuple[str]], NoneType]<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=learning_rate,-typing.Optional%5Bfloat%5D\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: typing.Optional[float]<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.02</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_bin,-typing.Optional%5Bint%5D\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: typing.Optional[int]<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_threshold,-typing.Optional%5Bint%5D\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: typing.Optional[int]<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_delta_step,-typing.Optional%5Bfloat%5D\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: typing.Optional[float]<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_depth,-%20typing.Optional%5Bint%5D\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  typing.Optional[int]<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_leaves,-typing.Optional%5Bint%5D\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: typing.Optional[int]<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=min_child_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: typing.Optional[float]<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=monotone_constraints,-typing.Union%5Btyping.Dict%5Bstr%2C%20int%5D%2C%20str%2C%20NoneType%5D\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Union[typing.Dict[str, int], str, NoneType]<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=multi_strategy,-typing.Optional%5Bstr%5D\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_estimators,-typing.Optional%5Bint%5D\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: typing.Optional[int]<br><br>Number of gradient boosted trees.  Equivalent to number of boosting<br>rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">600</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_jobs,-typing.Optional%5Bint%5D\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: typing.Optional[int]<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=random_state,-typing.Union%5Bnumpy.random.mtrand.RandomState%2C%20numpy.random._generator.Generator%2C%20int%2C%20NoneType%5D\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_alpha,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: typing.Optional[float]<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_lambda,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: typing.Optional[float]<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=sampling_method,-typing.Optional%5Bstr%5D\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: typing.Optional[str]<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=scale_pos_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: typing.Optional[float]<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=subsample,-typing.Optional%5Bfloat%5D\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: typing.Optional[float]<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=tree_method,-typing.Optional%5Bstr%5D\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: typing.Optional[str]<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=validate_parameters,-typing.Optional%5Bbool%5D\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: typing.Optional[bool]<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=verbosity,-typing.Optional%5Bint%5D\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: typing.Optional[int]<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-24');</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric='rmse', feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=600, n_jobs=-1,\n",
       "             num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid.best_params_\n",
    "\n",
    "xgb_final = XGBRegressor(\n",
    "    **best_params,\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    #early_stopping_rounds=200\n",
    ")\n",
    "\n",
    "xgb_final.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #eval_set=[(X_test, y_test)],\n",
    "    verbose=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a6cfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.04,\n",
    "    max_depth=6,\n",
    "    min_child_weight=3,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    eval_metric=\"rmse\",\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=200\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6194865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.00834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalidation_0-rmse:0.00669\n",
      "[100]\tvalidation_0-rmse:0.00683\n",
      "[150]\tvalidation_0-rmse:0.00686\n",
      "[200]\tvalidation_0-rmse:0.00685\n",
      "[250]\tvalidation_0-rmse:0.00684\n",
      "[252]\tvalidation_0-rmse:0.00684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-10.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-10.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             device=None, early_stopping_rounds=200, enable_categorical=False,\n",
       "             eval_metric=&#x27;rmse&#x27;, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
       "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=objective,-typing.Union%5Bstr%2C%20xgboost.sklearn._SklObjWProto%2C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%2C%20NoneType%5D\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=base_score,-typing.Union%5Bfloat%2C%20typing.List%5Bfloat%5D%2C%20NoneType%5D\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: typing.Union[float, typing.List[float], NoneType]<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=callbacks,-typing.Optional%5Btyping.List%5Bxgboost.callback.TrainingCallback%5D%5D\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.Optional[typing.List[xgboost.callback.TrainingCallback]]<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bylevel,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: typing.Optional[float]<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bynode,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: typing.Optional[float]<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=colsample_bytree,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: typing.Optional[float]<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=device,-typing.Optional%5Bstr%5D\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=early_stopping_rounds,-typing.Optional%5Bint%5D\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: typing.Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=eval_metric,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Union%5Bstr%2C%20typing.Callable%5D%5D%2C%20typing.Callable%2C%20NoneType%5D\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: typing.Union[str, typing.List[typing.Union[str, typing.Callable]], typing.Callable, NoneType]<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;rmse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_types,-typing.Optional%5Btyping.Sequence%5Bstr%5D%5D\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Optional[typing.Sequence[str]]<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=gamma,-typing.Optional%5Bfloat%5D\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: typing.Optional[float]<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=grow_policy,-typing.Optional%5Bstr%5D\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: typing.Optional[str]<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=interaction_constraints,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%2C%20NoneType%5D\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: typing.Union[str, typing.List[typing.Tuple[str]], NoneType]<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=learning_rate,-typing.Optional%5Bfloat%5D\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: typing.Optional[float]<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.04</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_bin,-typing.Optional%5Bint%5D\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: typing.Optional[int]<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_threshold,-typing.Optional%5Bint%5D\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: typing.Optional[int]<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_delta_step,-typing.Optional%5Bfloat%5D\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: typing.Optional[float]<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_depth,-%20typing.Optional%5Bint%5D\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  typing.Optional[int]<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=max_leaves,-typing.Optional%5Bint%5D\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: typing.Optional[int]<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=min_child_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: typing.Optional[float]<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=monotone_constraints,-typing.Union%5Btyping.Dict%5Bstr%2C%20int%5D%2C%20str%2C%20NoneType%5D\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Union[typing.Dict[str, int], str, NoneType]<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=multi_strategy,-typing.Optional%5Bstr%5D\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_estimators,-typing.Optional%5Bint%5D\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: typing.Optional[int]<br><br>Number of gradient boosted trees.  Equivalent to number of boosting<br>rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=n_jobs,-typing.Optional%5Bint%5D\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: typing.Optional[int]<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=random_state,-typing.Union%5Bnumpy.random.mtrand.RandomState%2C%20numpy.random._generator.Generator%2C%20int%2C%20NoneType%5D\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_alpha,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: typing.Optional[float]<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=reg_lambda,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: typing.Optional[float]<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=sampling_method,-typing.Optional%5Bstr%5D\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: typing.Optional[str]<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=scale_pos_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: typing.Optional[float]<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=subsample,-typing.Optional%5Bfloat%5D\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: typing.Optional[float]<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=tree_method,-typing.Optional%5Bstr%5D\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: typing.Optional[str]<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=validate_parameters,-typing.Optional%5Bbool%5D\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: typing.Optional[bool]<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBRegressor#:~:text=verbosity,-typing.Optional%5Bint%5D\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: typing.Optional[int]<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-10');</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             device=None, early_stopping_rounds=200, enable_categorical=False,\n",
       "             eval_metric='rmse', feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
       "             num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    \n",
    "    verbose=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "82c6a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.002741\n",
      "MAE  : 0.001453\n",
      "R²   : 0.6938\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = xgb_final.predict(X_train)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "37f2ef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.006548\n",
      "MAE  : 0.004391\n",
      "R²   : 0.0429\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_final.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"R²   : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "930891fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.002259\n",
      "MAE  : 0.001190\n",
      "R²   : 0.7905\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = xgb.predict(X_train)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6284d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.006679\n",
      "MAE  : 0.004533\n",
      "R²   : 0.0113\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fe4e71e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1,\n",
       " 'learning_rate': 0.02,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 10,\n",
       " 'n_estimators': 600,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "71fec1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage du forecast dynamique avec ré-entraînement...\n",
      "Progression: 4/45 (8.9%)\n",
      "Progression: 8/45 (17.8%)\n",
      "Progression: 12/45 (26.7%)\n",
      "Progression: 16/45 (35.6%)\n",
      "Progression: 20/45 (44.4%)\n",
      "Progression: 24/45 (53.3%)\n",
      "Progression: 28/45 (62.2%)\n",
      "Progression: 32/45 (71.1%)\n",
      "Progression: 36/45 (80.0%)\n",
      "Progression: 40/45 (88.9%)\n",
      "Progression: 44/45 (97.8%)\n",
      "\n",
      "==================================================\n",
      "RÉSULTATS DU FORECAST DYNAMIQUE\n",
      "==================================================\n",
      "RMSE : 0.006471\n",
      "MAE  : 0.004382\n",
      "R²   : 0.0653\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration initiale\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# 2. Initialisation des listes pour stocker les résultats\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "# 3. Forecast dynamique avec ré-entraînement\n",
    "print(\"Démarrage du forecast dynamique avec ré-entraînement...\")\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    # Créer les ensembles d'entraînement élargis\n",
    "    # À chaque itération, on ajoute une observation de plus au train\n",
    "    X_train_extended = pd.concat([X_train, X_test.iloc[:i]]) if i > 0 else X_train\n",
    "    y_train_extended = pd.concat([y_train, y_test.iloc[:i]]) if i > 0 else y_train\n",
    "    \n",
    "    # Ré-entraîner le modèle\n",
    "    xgb_dynamic = XGBRegressor(\n",
    "        **best_params,\n",
    "        objective=\"reg:squarederror\",\n",
    "        eval_metric=\"rmse\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    xgb_dynamic.fit(\n",
    "        X_train_extended,\n",
    "        y_train_extended,\n",
    "        verbose=0  # Désactiver les logs pour ne pas polluer la sortie\n",
    "    )\n",
    "    \n",
    "    # Prédire le point suivant\n",
    "    y_pred_single = xgb_dynamic.predict(X_test.iloc[[i]])[0]\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    predictions.append(y_pred_single)\n",
    "    actuals.append(y_test.iloc[i])\n",
    "    \n",
    "    # Afficher la progression tous les 10%\n",
    "    if (i + 1) % max(1, len(X_test) // 10) == 0:\n",
    "        print(f\"Progression: {i+1}/{len(X_test)} ({(i+1)/len(X_test)*100:.1f}%)\")\n",
    "\n",
    "# 4. Calculer les métriques\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "rmse_dynamic = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "mae_dynamic = mean_absolute_error(actuals, predictions)\n",
    "r2_dynamic = r2_score(actuals, predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RÉSULTATS DU FORECAST DYNAMIQUE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE : {rmse_dynamic:.6f}\")\n",
    "print(f\"MAE  : {mae_dynamic:.6f}\")\n",
    "print(f\"R²   : {r2_dynamic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1ad65b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage du forecast dynamique avec ré-entraînement...\n",
      "Progression: 4/45 (8.9%)\n",
      "Progression: 8/45 (17.8%)\n",
      "Progression: 12/45 (26.7%)\n",
      "Progression: 16/45 (35.6%)\n",
      "Progression: 20/45 (44.4%)\n",
      "Progression: 24/45 (53.3%)\n",
      "Progression: 28/45 (62.2%)\n",
      "Progression: 32/45 (71.1%)\n",
      "Progression: 36/45 (80.0%)\n",
      "Progression: 40/45 (88.9%)\n",
      "Progression: 44/45 (97.8%)\n",
      "\n",
      "==================================================\n",
      "RÉSULTATS DU FORECAST DYNAMIQUE\n",
      "==================================================\n",
      "RMSE : 0.005389\n",
      "MAE  : 0.003517\n",
      "R²   : 0.3517\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration initiale\n",
    "best_params = {'max_depth': 4, \n",
    "'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.006, 'n_estimators': 2200}\n",
    "\n",
    "# 2. Initialisation des listes pour stocker les résultats\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "# 3. Forecast dynamique avec ré-entraînement\n",
    "print(\"Démarrage du forecast dynamique avec ré-entraînement...\")\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    # Créer les ensembles d'entraînement élargis\n",
    "    # À chaque itération, on ajoute une observation de plus au train\n",
    "    X_train_extended = pd.concat([X_train, X_test.iloc[:i]]) if i > 0 else X_train\n",
    "    y_train_extended = pd.concat([y_train, y_test.iloc[:i]]) if i > 0 else y_train\n",
    "    \n",
    "    # Ré-entraîner le modèle\n",
    "    xgb_dynamic = XGBRegressor(\n",
    "        **best_params,\n",
    "        objective=\"reg:squarederror\",\n",
    "        eval_metric=\"rmse\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    xgb_dynamic.fit(\n",
    "        X_train_extended,\n",
    "        y_train_extended,\n",
    "        verbose=0  # Désactiver les logs pour ne pas polluer la sortie\n",
    "    )\n",
    "    \n",
    "    # Prédire le point suivant\n",
    "    y_pred_single = xgb_dynamic.predict(X_test.iloc[[i]])[0]\n",
    "    \n",
    "    # Stocker les résultats\n",
    "    predictions.append(y_pred_single)\n",
    "    actuals.append(y_test.iloc[i])\n",
    "    \n",
    "    # Afficher la progression tous les 10%\n",
    "    if (i + 1) % max(1, len(X_test) // 10) == 0:\n",
    "        print(f\"Progression: {i+1}/{len(X_test)} ({(i+1)/len(X_test)*100:.1f}%)\")\n",
    "\n",
    "# 4. Calculer les métriques\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "rmse_dynamic = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "mae_dynamic = mean_absolute_error(actuals, predictions)\n",
    "r2_dynamic = r2_score(actuals, predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RÉSULTATS DU FORECAST DYNAMIQUE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE : {rmse_dynamic:.6f}\")\n",
    "print(f\"MAE  : {mae_dynamic:.6f}\")\n",
    "print(f\"R²   : {r2_dynamic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2b760e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_train = df_lagged[\"returns\"].iloc[:split_idx]\n",
    "returns_test  = df_lagged[\"returns\"].iloc[split_idx:]\n",
    "vol_future_2w_test = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3f84ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage du forecast GARCH dynamique sur le test set...\n",
      "Progression: 4/45 (8.9%)\n",
      "Progression: 8/45 (17.8%)\n",
      "Progression: 12/45 (26.7%)\n",
      "Progression: 16/45 (35.6%)\n",
      "Progression: 20/45 (44.4%)\n",
      "Progression: 24/45 (53.3%)\n",
      "Progression: 28/45 (62.2%)\n",
      "Progression: 32/45 (71.1%)\n",
      "Progression: 36/45 (80.0%)\n",
      "Progression: 40/45 (88.9%)\n"
     ]
    }
   ],
   "source": [
    "# Convert to percent for GARCH\n",
    "returns_train_pct = returns_train * 100\n",
    "returns_test_pct = returns_test * 100\n",
    "\n",
    "garch_predictions = []\n",
    "garch_actuals = []\n",
    "\n",
    "print(\"Démarrage du forecast GARCH dynamique sur le test set...\")\n",
    "\n",
    "for i in range(len(returns_test) - 2):\n",
    "    # 1️⃣ Expanding history (train + past test)\n",
    "    returns_extended = (\n",
    "        pd.concat([returns_train_pct, returns_test_pct.iloc[:i]])\n",
    "        if i > 0 else returns_train_pct\n",
    "    ).dropna()\n",
    "    \n",
    "    # Minimum history check\n",
    "    if len(returns_extended) < 20:\n",
    "        garch_predictions.append(np.nan)\n",
    "        garch_actuals.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # 2️⃣ Fit GARCH\n",
    "    model = arch_model(\n",
    "        returns_extended,\n",
    "        vol=\"Garch\",\n",
    "        p=1,\n",
    "        q=1,\n",
    "        mean=\"Zero\",\n",
    "        dist=\"normal\"\n",
    "    )\n",
    "    \n",
    "    res = model.fit(disp=\"off\")\n",
    "\n",
    "    # 3️⃣ Forecast 2 weeks ahead\n",
    "    forecast = res.forecast(horizon=2)\n",
    "\n",
    "    var_1 = forecast.variance.iloc[-1, 0]\n",
    "    var_2 = forecast.variance.iloc[-1, 1]\n",
    "\n",
    "    # 4️⃣ Aggregate variance → volatility\n",
    "    vol_2w = np.sqrt(var_1 + var_2) / 100\n",
    "\n",
    "    garch_predictions.append(vol_2w)\n",
    "\n",
    "    # 5️⃣ Store realized volatility (target)\n",
    "    garch_actuals.append(vol_future_2w_test.iloc[i])\n",
    "\n",
    "    # Progress display\n",
    "    if (i + 1) % max(1, len(returns_test) // 10) == 0:\n",
    "        print(\n",
    "            f\"Progression: {i+1}/{len(returns_test)} \"\n",
    "            f\"({(i+1)/len(returns_test)*100:.1f}%)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e7362d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RÉSULTATS GARCH DYNAMIQUE (TEST SET)\n",
      "==================================================\n",
      "RMSE : 0.010402\n",
      "MAE  : 0.008643\n",
      "R²   : -1.3655\n"
     ]
    }
   ],
   "source": [
    "mask = ~np.isnan(garch_predictions)\n",
    "\n",
    "rmse_garch = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        np.array(garch_actuals)[mask],\n",
    "        np.array(garch_predictions)[mask]\n",
    "    )\n",
    ")\n",
    "\n",
    "mae_garch = mean_absolute_error(\n",
    "    np.array(garch_actuals)[mask],\n",
    "    np.array(garch_predictions)[mask]\n",
    ")\n",
    "\n",
    "r2_garch = r2_score(\n",
    "    np.array(garch_actuals)[mask],\n",
    "    np.array(garch_predictions)[mask]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RÉSULTATS GARCH DYNAMIQUE (TEST SET)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RMSE : {rmse_garch:.6f}\")\n",
    "print(f\"MAE  : {mae_garch:.6f}\")\n",
    "print(f\"R²   : {r2_garch:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a2262f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSTIC DES DONNÉES\n",
      "==================================================\n",
      "Shape X_train: (178, 6)\n",
      "Shape y_train: (178,)\n",
      "Shape X_test: (45, 6)\n",
      "Shape y_test: (45,)\n",
      "\n",
      "Statistiques y_train:\n",
      "count    178.000000\n",
      "mean       0.005403\n",
      "std        0.004968\n",
      "min        0.000316\n",
      "25%        0.002767\n",
      "50%        0.004127\n",
      "75%        0.007008\n",
      "max        0.040385\n",
      "Name: vol_future_2w, dtype: float64\n",
      "\n",
      "Valeurs manquantes X_train: 0\n",
      "Valeurs manquantes y_train: 0\n",
      "\n",
      "Premières valeurs y_train:\n",
      "5    0.002761\n",
      "6    0.002797\n",
      "7    0.002527\n",
      "8    0.002628\n",
      "9    0.004168\n",
      "Name: vol_future_2w, dtype: float64\n",
      "\n",
      "==================================================\n",
      "TEST AVEC ORDRE SIMPLE (1,0,0)\n",
      "==================================================\n",
      "✓ Modèle (1,0,0) fonctionne !\n",
      "AIC: -1473.04\n",
      "✗ Erreur avec modèle simple: 0\n",
      "\n",
      "Le problème vient probablement des données elles-mêmes.\n",
      "Vérifiez:\n",
      "1. Pas de valeurs infinies ou NaN\n",
      "2. Les features ne sont pas constantes\n",
      "3. L'échelle des données (standardisation peut aider)\n",
      "\n",
      "==================================================\n",
      "FORECAST DYNAMIQUE AVEC ORDRES MULTIPLES\n",
      "==================================================\n",
      "Progression: 4/45 (8.9%) - Succès: 0, Échecs: 4\n",
      "Progression: 8/45 (17.8%) - Succès: 0, Échecs: 8\n",
      "Progression: 12/45 (26.7%) - Succès: 0, Échecs: 12\n",
      "Progression: 16/45 (35.6%) - Succès: 0, Échecs: 16\n",
      "Progression: 20/45 (44.4%) - Succès: 0, Échecs: 20\n",
      "Progression: 24/45 (53.3%) - Succès: 0, Échecs: 24\n",
      "Progression: 28/45 (62.2%) - Succès: 0, Échecs: 28\n",
      "Progression: 32/45 (71.1%) - Succès: 0, Échecs: 32\n",
      "Progression: 36/45 (80.0%) - Succès: 0, Échecs: 36\n",
      "Progression: 40/45 (88.9%) - Succès: 0, Échecs: 40\n",
      "Progression: 44/45 (97.8%) - Succès: 0, Échecs: 44\n",
      "\n",
      "==================================================\n",
      "RÉSULTATS DU FORECAST DYNAMIQUE SARIMAX\n",
      "==================================================\n",
      "Fits réussis: 0/45 (0.0%)\n",
      "Fits échoués: 45/45 (100.0%)\n",
      "\n",
      "RMSE : 0.005753\n",
      "MAE  : 0.003857\n",
      "R²   : 0.2613\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Diagnostiquer le problème d'abord\n",
    "print(\"DIAGNOSTIC DES DONNÉES\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Shape X_train: {X_train.shape}\")\n",
    "print(f\"Shape y_train: {y_train.shape}\")\n",
    "print(f\"Shape X_test: {X_test.shape}\")\n",
    "print(f\"Shape y_test: {y_test.shape}\")\n",
    "print(f\"\\nStatistiques y_train:\")\n",
    "print(y_train.describe())\n",
    "print(f\"\\nValeurs manquantes X_train: {X_train.isna().sum().sum()}\")\n",
    "print(f\"Valeurs manquantes y_train: {y_train.isna().sum()}\")\n",
    "print(f\"\\nPremières valeurs y_train:\")\n",
    "print(y_train.head())\n",
    "\n",
    "# 2. Test avec un modèle simple pour identifier le problème\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST AVEC ORDRE SIMPLE (1,0,0)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Test avec le modèle le plus simple possible\n",
    "    test_model = SARIMAX(\n",
    "        endog=y_train,\n",
    "        exog=X_train,\n",
    "        order=(1, 0, 0),  # Ordre le plus simple\n",
    "        seasonal_order=(0, 0, 0, 0),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    test_fit = test_model.fit(disp=False, maxiter=50, method='lbfgs')\n",
    "    print(\"✓ Modèle (1,0,0) fonctionne !\")\n",
    "    print(f\"AIC: {test_fit.aic:.2f}\")\n",
    "    \n",
    "    # Tester une prédiction\n",
    "    test_pred = test_fit.forecast(steps=1, exog=X_test.iloc[[0]].values)\n",
    "    print(f\"✓ Prédiction test réussie: {test_pred[0]:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Erreur avec modèle simple: {str(e)}\")\n",
    "    print(\"\\nLe problème vient probablement des données elles-mêmes.\")\n",
    "    print(\"Vérifiez:\")\n",
    "    print(\"1. Pas de valeurs infinies ou NaN\")\n",
    "    print(\"2. Les features ne sont pas constantes\")\n",
    "    print(\"3. L'échelle des données (standardisation peut aider)\")\n",
    "\n",
    "# 3. VERSION CORRIGÉE avec plusieurs ordres à tester\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FORECAST DYNAMIQUE AVEC ORDRES MULTIPLES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Tester plusieurs ordres du plus simple au plus complexe\n",
    "orders_to_try = [\n",
    "    (1, 0, 0),  # Le plus simple\n",
    "    (1, 0, 1),\n",
    "    (1, 1, 1),\n",
    "    (2, 0, 1),\n",
    "    (2, 1, 2),  # Votre ordre original\n",
    "]\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "successful_fits = 0\n",
    "failed_fits = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_train_extended = pd.concat([X_train, X_test.iloc[:i]]) if i > 0 else X_train\n",
    "    y_train_extended = pd.concat([y_train, y_test.iloc[:i]]) if i > 0 else y_train\n",
    "    \n",
    "    prediction_made = False\n",
    "    \n",
    "    # Essayer différents ordres jusqu'à ce qu'un fonctionne\n",
    "    for order in orders_to_try:\n",
    "        try:\n",
    "            sarimax_dynamic = SARIMAX(\n",
    "                endog=y_train_extended,\n",
    "                exog=X_train_extended,\n",
    "                order=order,\n",
    "                seasonal_order=(0, 0, 0, 0),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            \n",
    "            sarimax_fit = sarimax_dynamic.fit(\n",
    "                disp=False, \n",
    "                maxiter=50,\n",
    "                method='lbfgs',  # Méthode plus stable\n",
    "                low_memory=True\n",
    "            )\n",
    "            \n",
    "            y_pred_single = sarimax_fit.forecast(steps=1, exog=X_test.iloc[[i]].values)[0]\n",
    "            \n",
    "            predictions.append(y_pred_single)\n",
    "            actuals.append(y_test.iloc[i])\n",
    "            successful_fits += 1\n",
    "            prediction_made = True\n",
    "            break  # Sortir de la boucle des ordres\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue  # Essayer l'ordre suivant\n",
    "    \n",
    "    # Si aucun ordre n'a fonctionné, utiliser prédiction naïve\n",
    "    if not prediction_made:\n",
    "        predictions.append(y_train_extended.iloc[-1])\n",
    "        actuals.append(y_test.iloc[i])\n",
    "        failed_fits += 1\n",
    "    \n",
    "    if (i + 1) % max(1, len(X_test) // 10) == 0:\n",
    "        print(f\"Progression: {i+1}/{len(X_test)} ({(i+1)/len(X_test)*100:.1f}%) - \"\n",
    "              f\"Succès: {successful_fits}, Échecs: {failed_fits}\")\n",
    "\n",
    "# 4. Résultats\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "rmse_dynamic = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "mae_dynamic = mean_absolute_error(actuals, predictions)\n",
    "r2_dynamic = r2_score(actuals, predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RÉSULTATS DU FORECAST DYNAMIQUE SARIMAX\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Fits réussis: {successful_fits}/{len(X_test)} ({successful_fits/len(X_test)*100:.1f}%)\")\n",
    "print(f\"Fits échoués: {failed_fits}/{len(X_test)} ({failed_fits/len(X_test)*100:.1f}%)\")\n",
    "print(f\"\\nRMSE : {rmse_dynamic:.6f}\")\n",
    "print(f\"MAE  : {mae_dynamic:.6f}\")\n",
    "print(f\"R²   : {r2_dynamic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b530d556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_future_2w_1</th>\n",
       "      <th>vol_future_2w_2</th>\n",
       "      <th>vol_future_2w_3</th>\n",
       "      <th>returns</th>\n",
       "      <th>rendement_lag_1</th>\n",
       "      <th>rendement_lag_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vol_future_2w_1  vol_future_2w_2  vol_future_2w_3  returns  \\\n",
       "5           0.001298         0.003377         0.003482   0.0016   \n",
       "6           0.002761         0.001298         0.003377   0.0009   \n",
       "7           0.002797         0.002761         0.001298   0.0038   \n",
       "8           0.002527         0.002797         0.002761   0.0011   \n",
       "9           0.002628         0.002527         0.002797   0.0034   \n",
       "..               ...              ...              ...      ...   \n",
       "222         0.017439         0.016367         0.006150   0.0230   \n",
       "223         0.009153         0.017439         0.016367   0.0089   \n",
       "224         0.014799         0.009153         0.017439   0.0094   \n",
       "225         0.017265         0.014799         0.009153   0.0187   \n",
       "226         0.013888         0.017265         0.014799   0.0157   \n",
       "\n",
       "     rendement_lag_1  rendement_lag_2  \n",
       "5               0.45             0.20  \n",
       "6               0.16             0.45  \n",
       "7               0.09             0.16  \n",
       "8               0.38             0.09  \n",
       "9               0.11             0.38  \n",
       "..               ...              ...  \n",
       "222             0.26             0.83  \n",
       "223             2.30             0.26  \n",
       "224             0.89             2.30  \n",
       "225             0.94             0.89  \n",
       "226             1.87             0.94  \n",
       "\n",
       "[222 rows x 6 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2b02f097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DÉMARRAGE DE LA VALIDATION CROISÉE AVEC RÉ-ENTRAÎNEMENT DYNAMIQUE\n",
      "======================================================================\n",
      "Test de 864 combinaisons de paramètres...\n",
      "Avec 5 folds de validation croisée\n",
      "======================================================================\n",
      "\n",
      "Combinaison 1/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003425\n",
      "  Fold 2/5... RMSE = 0.009762\n",
      "  Fold 3/5... RMSE = 0.002618\n",
      "  Fold 4/5... RMSE = 0.002570\n",
      "  Fold 5/5... RMSE = 0.002555\n",
      "  Score moyen: 0.004186 (+/- 0.002807)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 2/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003441\n",
      "  Fold 2/5... RMSE = 0.009646\n",
      "  Fold 3/5... RMSE = 0.002763\n",
      "  Fold 4/5... RMSE = 0.002486\n",
      "  Fold 5/5... RMSE = 0.002408\n",
      "  Score moyen: 0.004149 (+/- 0.002772)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 3/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003400\n",
      "  Fold 2/5... RMSE = 0.009711\n",
      "  Fold 3/5... RMSE = 0.002891\n",
      "  Fold 4/5... RMSE = 0.002701\n",
      "  Fold 5/5... RMSE = 0.002466\n",
      "  Score moyen: 0.004234 (+/- 0.002756)\n",
      "\n",
      "Combinaison 4/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003430\n",
      "  Fold 2/5... RMSE = 0.009620\n",
      "  Fold 3/5... RMSE = 0.003229\n",
      "  Fold 4/5... RMSE = 0.002634\n",
      "  Fold 5/5... RMSE = 0.002441\n",
      "  Score moyen: 0.004271 (+/- 0.002699)\n",
      "\n",
      "Combinaison 5/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003476\n",
      "  Fold 2/5... RMSE = 0.009610\n",
      "  Fold 3/5... RMSE = 0.003013\n",
      "  Fold 4/5... RMSE = 0.002806\n",
      "  Fold 5/5... RMSE = 0.002599\n",
      "  Score moyen: 0.004301 (+/- 0.002670)\n",
      "\n",
      "Combinaison 6/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003485\n",
      "  Fold 2/5... RMSE = 0.009568\n",
      "  Fold 3/5... RMSE = 0.003392\n",
      "  Fold 4/5... RMSE = 0.002876\n",
      "  Fold 5/5... RMSE = 0.002552\n",
      "  Score moyen: 0.004375 (+/- 0.002619)\n",
      "\n",
      "Combinaison 7/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003380\n",
      "  Fold 2/5... RMSE = 0.009813\n",
      "  Fold 3/5... RMSE = 0.002510\n",
      "  Fold 4/5... RMSE = 0.002595\n",
      "  Fold 5/5... RMSE = 0.002464\n",
      "  Score moyen: 0.004153 (+/- 0.002850)\n",
      "\n",
      "Combinaison 8/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003444\n",
      "  Fold 2/5... RMSE = 0.009712\n",
      "  Fold 3/5... RMSE = 0.002693\n",
      "  Fold 4/5... RMSE = 0.002501\n",
      "  Fold 5/5... RMSE = 0.002337\n",
      "  Score moyen: 0.004137 (+/- 0.002813)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 9/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003422\n",
      "  Fold 2/5... RMSE = 0.009708\n",
      "  Fold 3/5... RMSE = 0.002751\n",
      "  Fold 4/5... RMSE = 0.002628\n",
      "  Fold 5/5... RMSE = 0.002404\n",
      "  Score moyen: 0.004183 (+/- 0.002783)\n",
      "\n",
      "Combinaison 10/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003457\n",
      "  Fold 2/5... RMSE = 0.009607\n",
      "  Fold 3/5... RMSE = 0.003227\n",
      "  Fold 4/5... RMSE = 0.002658\n",
      "  Fold 5/5... RMSE = 0.002486\n",
      "  Score moyen: 0.004287 (+/- 0.002684)\n",
      "\n",
      "Combinaison 11/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003401\n",
      "  Fold 2/5... RMSE = 0.009685\n",
      "  Fold 3/5... RMSE = 0.003040\n",
      "  Fold 4/5... RMSE = 0.002736\n",
      "  Fold 5/5... RMSE = 0.002450\n",
      "  Score moyen: 0.004262 (+/- 0.002729)\n",
      "\n",
      "Combinaison 12/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003404\n",
      "  Fold 2/5... RMSE = 0.009608\n",
      "  Fold 3/5... RMSE = 0.003424\n",
      "  Fold 4/5... RMSE = 0.002811\n",
      "  Fold 5/5... RMSE = 0.002435\n",
      "  Score moyen: 0.004337 (+/- 0.002662)\n",
      "\n",
      "Combinaison 13/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003292\n",
      "  Fold 2/5... RMSE = 0.009752\n",
      "  Fold 3/5... RMSE = 0.002604\n",
      "  Fold 4/5... RMSE = 0.002531\n",
      "  Fold 5/5... RMSE = 0.002410\n",
      "  Score moyen: 0.004118 (+/- 0.002834)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 14/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003435\n",
      "  Fold 2/5... RMSE = 0.009671\n",
      "  Fold 3/5... RMSE = 0.002735\n",
      "  Fold 4/5... RMSE = 0.002513\n",
      "  Fold 5/5... RMSE = 0.002292\n",
      "  Score moyen: 0.004129 (+/- 0.002798)\n",
      "\n",
      "Combinaison 15/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003402\n",
      "  Fold 2/5... RMSE = 0.009714\n",
      "  Fold 3/5... RMSE = 0.002706\n",
      "  Fold 4/5... RMSE = 0.002400\n",
      "  Fold 5/5... RMSE = 0.002311\n",
      "  Score moyen: 0.004107 (+/- 0.002830)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 16/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003434\n",
      "  Fold 2/5... RMSE = 0.009637\n",
      "  Fold 3/5... RMSE = 0.003037\n",
      "  Fold 4/5... RMSE = 0.002492\n",
      "  Fold 5/5... RMSE = 0.002338\n",
      "  Score moyen: 0.004187 (+/- 0.002753)\n",
      "\n",
      "Combinaison 17/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003435\n",
      "  Fold 2/5... RMSE = 0.009568\n",
      "  Fold 3/5... RMSE = 0.003124\n",
      "  Fold 4/5... RMSE = 0.002447\n",
      "  Fold 5/5... RMSE = 0.002499\n",
      "  Score moyen: 0.004215 (+/- 0.002703)\n",
      "\n",
      "Combinaison 18/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003444\n",
      "  Fold 2/5... RMSE = 0.009537\n",
      "  Fold 3/5... RMSE = 0.003444\n",
      "  Fold 4/5... RMSE = 0.002481\n",
      "  Fold 5/5... RMSE = 0.002563\n",
      "  Score moyen: 0.004294 (+/- 0.002654)\n",
      "\n",
      "Combinaison 19/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003547\n",
      "  Fold 2/5... RMSE = 0.009832\n",
      "  Fold 3/5... RMSE = 0.002588\n",
      "  Fold 4/5... RMSE = 0.002655\n",
      "  Fold 5/5... RMSE = 0.002574\n",
      "  Score moyen: 0.004239 (+/- 0.002820)\n",
      "\n",
      "Combinaison 20/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003545\n",
      "  Fold 2/5... RMSE = 0.009682\n",
      "  Fold 3/5... RMSE = 0.002743\n",
      "  Fold 4/5... RMSE = 0.002605\n",
      "  Fold 5/5... RMSE = 0.002381\n",
      "  Score moyen: 0.004191 (+/- 0.002773)\n",
      "\n",
      "Combinaison 21/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003530\n",
      "  Fold 2/5... RMSE = 0.009731\n",
      "  Fold 3/5... RMSE = 0.002927\n",
      "  Fold 4/5... RMSE = 0.002624\n",
      "  Fold 5/5... RMSE = 0.002381\n",
      "  Score moyen: 0.004239 (+/- 0.002773)\n",
      "\n",
      "Combinaison 22/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003535\n",
      "  Fold 2/5... RMSE = 0.009584\n",
      "  Fold 3/5... RMSE = 0.003318\n",
      "  Fold 4/5... RMSE = 0.002681\n",
      "  Fold 5/5... RMSE = 0.002340\n",
      "  Score moyen: 0.004292 (+/- 0.002681)\n",
      "\n",
      "Combinaison 23/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003560\n",
      "  Fold 2/5... RMSE = 0.009681\n",
      "  Fold 3/5... RMSE = 0.003149\n",
      "  Fold 4/5... RMSE = 0.002815\n",
      "  Fold 5/5... RMSE = 0.002397\n",
      "  Score moyen: 0.004320 (+/- 0.002707)\n",
      "\n",
      "Combinaison 24/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003563\n",
      "  Fold 2/5... RMSE = 0.009609\n",
      "  Fold 3/5... RMSE = 0.003365\n",
      "  Fold 4/5... RMSE = 0.002856\n",
      "  Fold 5/5... RMSE = 0.002415\n",
      "  Score moyen: 0.004362 (+/- 0.002654)\n",
      "\n",
      "Combinaison 25/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003531\n",
      "  Fold 2/5... RMSE = 0.009830\n",
      "  Fold 3/5... RMSE = 0.002576\n",
      "  Fold 4/5... RMSE = 0.002661\n",
      "  Fold 5/5... RMSE = 0.002510\n",
      "  Score moyen: 0.004222 (+/- 0.002828)\n",
      "\n",
      "Combinaison 26/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003546\n",
      "  Fold 2/5... RMSE = 0.009728\n",
      "  Fold 3/5... RMSE = 0.002712\n",
      "  Fold 4/5... RMSE = 0.002642\n",
      "  Fold 5/5... RMSE = 0.002372\n",
      "  Score moyen: 0.004200 (+/- 0.002792)\n",
      "\n",
      "Combinaison 27/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003492\n",
      "  Fold 2/5... RMSE = 0.009764\n",
      "  Fold 3/5... RMSE = 0.002862\n",
      "  Fold 4/5... RMSE = 0.002626\n",
      "  Fold 5/5... RMSE = 0.002325\n",
      "  Score moyen: 0.004214 (+/- 0.002801)\n",
      "\n",
      "Combinaison 28/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003505\n",
      "  Fold 2/5... RMSE = 0.009641\n",
      "  Fold 3/5... RMSE = 0.003270\n",
      "  Fold 4/5... RMSE = 0.002753\n",
      "  Fold 5/5... RMSE = 0.002287\n",
      "  Score moyen: 0.004291 (+/- 0.002708)\n",
      "\n",
      "Combinaison 29/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003486\n",
      "  Fold 2/5... RMSE = 0.009755\n",
      "  Fold 3/5... RMSE = 0.003014\n",
      "  Fold 4/5... RMSE = 0.002745\n",
      "  Fold 5/5... RMSE = 0.002388\n",
      "  Score moyen: 0.004278 (+/- 0.002762)\n",
      "\n",
      "Combinaison 30/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003488\n",
      "  Fold 2/5... RMSE = 0.009709\n",
      "  Fold 3/5... RMSE = 0.003284\n",
      "  Fold 4/5... RMSE = 0.002794\n",
      "  Fold 5/5... RMSE = 0.002389\n",
      "  Score moyen: 0.004333 (+/- 0.002715)\n",
      "\n",
      "Combinaison 31/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003512\n",
      "  Fold 2/5... RMSE = 0.009793\n",
      "  Fold 3/5... RMSE = 0.002634\n",
      "  Fold 4/5... RMSE = 0.002703\n",
      "  Fold 5/5... RMSE = 0.002479\n",
      "  Score moyen: 0.004224 (+/- 0.002808)\n",
      "\n",
      "Combinaison 32/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003574\n",
      "  Fold 2/5... RMSE = 0.009736\n",
      "  Fold 3/5... RMSE = 0.002840\n",
      "  Fold 4/5... RMSE = 0.002694\n",
      "  Fold 5/5... RMSE = 0.002339\n",
      "  Score moyen: 0.004237 (+/- 0.002779)\n",
      "\n",
      "Combinaison 33/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003469\n",
      "  Fold 2/5... RMSE = 0.009724\n",
      "  Fold 3/5... RMSE = 0.002820\n",
      "  Fold 4/5... RMSE = 0.002651\n",
      "  Fold 5/5... RMSE = 0.002211\n",
      "  Score moyen: 0.004175 (+/- 0.002804)\n",
      "\n",
      "Combinaison 34/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003490\n",
      "  Fold 2/5... RMSE = 0.009674\n",
      "  Fold 3/5... RMSE = 0.003239\n",
      "  Fold 4/5... RMSE = 0.002734\n",
      "  Fold 5/5... RMSE = 0.002233\n",
      "  Score moyen: 0.004274 (+/- 0.002734)\n",
      "\n",
      "Combinaison 35/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003488\n",
      "  Fold 2/5... RMSE = 0.009625\n",
      "  Fold 3/5... RMSE = 0.003193\n",
      "  Fold 4/5... RMSE = 0.002672\n",
      "  Fold 5/5... RMSE = 0.002239\n",
      "  Score moyen: 0.004243 (+/- 0.002725)\n",
      "\n",
      "Combinaison 36/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003489\n",
      "  Fold 2/5... RMSE = 0.009587\n",
      "  Fold 3/5... RMSE = 0.003426\n",
      "  Fold 4/5... RMSE = 0.002640\n",
      "  Fold 5/5... RMSE = 0.002269\n",
      "  Score moyen: 0.004282 (+/- 0.002693)\n",
      "\n",
      "Combinaison 37/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003727\n",
      "  Fold 2/5... RMSE = 0.009817\n",
      "  Fold 3/5... RMSE = 0.002679\n",
      "  Fold 4/5... RMSE = 0.002804\n",
      "  Fold 5/5... RMSE = 0.002516\n",
      "  Score moyen: 0.004309 (+/- 0.002786)\n",
      "\n",
      "Combinaison 38/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003731\n",
      "  Fold 2/5... RMSE = 0.009647\n",
      "  Fold 3/5... RMSE = 0.002758\n",
      "  Fold 4/5... RMSE = 0.002825\n",
      "  Fold 5/5... RMSE = 0.002404\n",
      "  Score moyen: 0.004273 (+/- 0.002723)\n",
      "\n",
      "Combinaison 39/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003758\n",
      "  Fold 2/5... RMSE = 0.009856\n",
      "  Fold 3/5... RMSE = 0.002726\n",
      "  Fold 4/5... RMSE = 0.002871\n",
      "  Fold 5/5... RMSE = 0.002508\n",
      "  Score moyen: 0.004344 (+/- 0.002789)\n",
      "\n",
      "Combinaison 40/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003758\n",
      "  Fold 2/5... RMSE = 0.009707\n",
      "  Fold 3/5... RMSE = 0.003088\n",
      "  Fold 4/5... RMSE = 0.003086\n",
      "  Fold 5/5... RMSE = 0.002692\n",
      "  Score moyen: 0.004466 (+/- 0.002643)\n",
      "\n",
      "Combinaison 41/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003810\n",
      "  Fold 2/5... RMSE = 0.009682\n",
      "  Fold 3/5... RMSE = 0.003169\n",
      "  Fold 4/5... RMSE = 0.003204\n",
      "  Fold 5/5... RMSE = 0.002720\n",
      "  Score moyen: 0.004517 (+/- 0.002606)\n",
      "\n",
      "Combinaison 42/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003810\n",
      "  Fold 2/5... RMSE = 0.009682\n",
      "  Fold 3/5... RMSE = 0.003156\n",
      "  Fold 4/5... RMSE = 0.003196\n",
      "  Fold 5/5... RMSE = 0.002779\n",
      "  Score moyen: 0.004525 (+/- 0.002600)\n",
      "\n",
      "Combinaison 43/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003789\n",
      "  Fold 2/5... RMSE = 0.009857\n",
      "  Fold 3/5... RMSE = 0.002679\n",
      "  Fold 4/5... RMSE = 0.002750\n",
      "  Fold 5/5... RMSE = 0.002468\n",
      "  Score moyen: 0.004309 (+/- 0.002812)\n",
      "\n",
      "Combinaison 44/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003799\n",
      "  Fold 2/5... RMSE = 0.009866\n",
      "  Fold 3/5... RMSE = 0.002845\n",
      "  Fold 4/5... RMSE = 0.002963\n",
      "  Fold 5/5... RMSE = 0.002491\n",
      "  Score moyen: 0.004393 (+/- 0.002770)\n",
      "\n",
      "Combinaison 45/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003795\n",
      "  Fold 2/5... RMSE = 0.009792\n",
      "  Fold 3/5... RMSE = 0.002876\n",
      "  Fold 4/5... RMSE = 0.002929\n",
      "  Fold 5/5... RMSE = 0.002408\n",
      "  Score moyen: 0.004360 (+/- 0.002753)\n",
      "\n",
      "Combinaison 46/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003795\n",
      "  Fold 2/5... RMSE = 0.009604\n",
      "  Fold 3/5... RMSE = 0.003121\n",
      "  Fold 4/5... RMSE = 0.003173\n",
      "  Fold 5/5... RMSE = 0.002607\n",
      "  Score moyen: 0.004460 (+/- 0.002599)\n",
      "\n",
      "Combinaison 47/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003781\n",
      "  Fold 2/5... RMSE = 0.009758\n",
      "  Fold 3/5... RMSE = 0.003140\n",
      "  Fold 4/5... RMSE = 0.003180\n",
      "  Fold 5/5... RMSE = 0.002603\n",
      "  Score moyen: 0.004493 (+/- 0.002659)\n",
      "\n",
      "Combinaison 48/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003781\n",
      "  Fold 2/5... RMSE = 0.009758\n",
      "  Fold 3/5... RMSE = 0.003160\n",
      "  Fold 4/5... RMSE = 0.003193\n",
      "  Fold 5/5... RMSE = 0.002598\n",
      "  Score moyen: 0.004498 (+/- 0.002656)\n",
      "\n",
      "Combinaison 49/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003811\n",
      "  Fold 2/5... RMSE = 0.009795\n",
      "  Fold 3/5... RMSE = 0.002642\n",
      "  Fold 4/5... RMSE = 0.002898\n",
      "  Fold 5/5... RMSE = 0.002425\n",
      "  Score moyen: 0.004314 (+/- 0.002781)\n",
      "\n",
      "Combinaison 50/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003817\n",
      "  Fold 2/5... RMSE = 0.009831\n",
      "  Fold 3/5... RMSE = 0.002868\n",
      "  Fold 4/5... RMSE = 0.003076\n",
      "  Fold 5/5... RMSE = 0.002543\n",
      "  Score moyen: 0.004427 (+/- 0.002734)\n",
      "\n",
      "Combinaison 51/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003842\n",
      "  Fold 2/5... RMSE = 0.009869\n",
      "  Fold 3/5... RMSE = 0.002836\n",
      "  Fold 4/5... RMSE = 0.002994\n",
      "  Fold 5/5... RMSE = 0.002503\n",
      "  Score moyen: 0.004409 (+/- 0.002766)\n",
      "\n",
      "Combinaison 52/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003842\n",
      "  Fold 2/5... RMSE = 0.009674\n",
      "  Fold 3/5... RMSE = 0.003074\n",
      "  Fold 4/5... RMSE = 0.003315\n",
      "  Fold 5/5... RMSE = 0.002695\n",
      "  Score moyen: 0.004520 (+/- 0.002604)\n",
      "\n",
      "Combinaison 53/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003823\n",
      "  Fold 2/5... RMSE = 0.009602\n",
      "  Fold 3/5... RMSE = 0.003162\n",
      "  Fold 4/5... RMSE = 0.003277\n",
      "  Fold 5/5... RMSE = 0.002692\n",
      "  Score moyen: 0.004511 (+/- 0.002571)\n",
      "\n",
      "Combinaison 54/864: {'max_depth': 2, 'min_child_weight': 2, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003823\n",
      "  Fold 2/5... RMSE = 0.009602\n",
      "  Fold 3/5... RMSE = 0.003160\n",
      "  Fold 4/5... RMSE = 0.003302\n",
      "  Fold 5/5... RMSE = 0.002724\n",
      "  Score moyen: 0.004522 (+/- 0.002564)\n",
      "\n",
      "Combinaison 55/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003415\n",
      "  Fold 2/5... RMSE = 0.010058\n",
      "  Fold 3/5... RMSE = 0.002754\n",
      "  Fold 4/5... RMSE = 0.002515\n",
      "  Fold 5/5... RMSE = 0.002080\n",
      "  Score moyen: 0.004164 (+/- 0.002978)\n",
      "\n",
      "Combinaison 56/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003410\n",
      "  Fold 2/5... RMSE = 0.010113\n",
      "  Fold 3/5... RMSE = 0.002798\n",
      "  Fold 4/5... RMSE = 0.002520\n",
      "  Fold 5/5... RMSE = 0.001931\n",
      "  Score moyen: 0.004154 (+/- 0.003017)\n",
      "\n",
      "Combinaison 57/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003415\n",
      "  Fold 2/5... RMSE = 0.010093\n",
      "  Fold 3/5... RMSE = 0.002833\n",
      "  Fold 4/5... RMSE = 0.002641\n",
      "  Fold 5/5... RMSE = 0.001909\n",
      "  Score moyen: 0.004178 (+/- 0.002996)\n",
      "\n",
      "Combinaison 58/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003514\n",
      "  Fold 2/5... RMSE = 0.010186\n",
      "  Fold 3/5... RMSE = 0.003231\n",
      "  Fold 4/5... RMSE = 0.002797\n",
      "  Fold 5/5... RMSE = 0.001884\n",
      "  Score moyen: 0.004323 (+/- 0.002983)\n",
      "\n",
      "Combinaison 59/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003484\n",
      "  Fold 2/5... RMSE = 0.010140\n",
      "  Fold 3/5... RMSE = 0.003140\n",
      "  Fold 4/5... RMSE = 0.002918\n",
      "  Fold 5/5... RMSE = 0.001857\n",
      "  Score moyen: 0.004308 (+/- 0.002966)\n",
      "\n",
      "Combinaison 60/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003619\n",
      "  Fold 2/5... RMSE = 0.010253\n",
      "  Fold 3/5... RMSE = 0.003502\n",
      "  Fold 4/5... RMSE = 0.003174\n",
      "  Fold 5/5... RMSE = 0.001898\n",
      "  Score moyen: 0.004489 (+/- 0.002946)\n",
      "\n",
      "Combinaison 61/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003406\n",
      "  Fold 2/5... RMSE = 0.010004\n",
      "  Fold 3/5... RMSE = 0.002690\n",
      "  Fold 4/5... RMSE = 0.002503\n",
      "  Fold 5/5... RMSE = 0.001968\n",
      "  Score moyen: 0.004114 (+/- 0.002981)\n",
      "\n",
      "Combinaison 62/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003414\n",
      "  Fold 2/5... RMSE = 0.010037\n",
      "  Fold 3/5... RMSE = 0.002735\n",
      "  Fold 4/5... RMSE = 0.002565\n",
      "  Fold 5/5... RMSE = 0.001860\n",
      "  Score moyen: 0.004122 (+/- 0.002998)\n",
      "\n",
      "Combinaison 63/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003449\n",
      "  Fold 2/5... RMSE = 0.010061\n",
      "  Fold 3/5... RMSE = 0.002780\n",
      "  Fold 4/5... RMSE = 0.002551\n",
      "  Fold 5/5... RMSE = 0.001814\n",
      "  Score moyen: 0.004131 (+/- 0.003010)\n",
      "\n",
      "Combinaison 64/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003534\n",
      "  Fold 2/5... RMSE = 0.010179\n",
      "  Fold 3/5... RMSE = 0.003103\n",
      "  Fold 4/5... RMSE = 0.002674\n",
      "  Fold 5/5... RMSE = 0.001811\n",
      "  Score moyen: 0.004260 (+/- 0.003014)\n",
      "\n",
      "Combinaison 65/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003506\n",
      "  Fold 2/5... RMSE = 0.010027\n",
      "  Fold 3/5... RMSE = 0.003217\n",
      "  Fold 4/5... RMSE = 0.002685\n",
      "  Fold 5/5... RMSE = 0.001919\n",
      "  Score moyen: 0.004271 (+/- 0.002928)\n",
      "\n",
      "Combinaison 66/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003634\n",
      "  Fold 2/5... RMSE = 0.010224\n",
      "  Fold 3/5... RMSE = 0.003403\n",
      "  Fold 4/5... RMSE = 0.002989\n",
      "  Fold 5/5... RMSE = 0.001997\n",
      "  Score moyen: 0.004449 (+/- 0.002941)\n",
      "\n",
      "Combinaison 67/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003385\n",
      "  Fold 2/5... RMSE = 0.009982\n",
      "  Fold 3/5... RMSE = 0.002699\n",
      "  Fold 4/5... RMSE = 0.002527\n",
      "  Fold 5/5... RMSE = 0.001954\n",
      "  Score moyen: 0.004109 (+/- 0.002972)\n",
      "\n",
      "Combinaison 68/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003446\n",
      "  Fold 2/5... RMSE = 0.010010\n",
      "  Fold 3/5... RMSE = 0.002780\n",
      "  Fold 4/5... RMSE = 0.002554\n",
      "  Fold 5/5... RMSE = 0.001817\n",
      "  Score moyen: 0.004121 (+/- 0.002990)\n",
      "\n",
      "Combinaison 69/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003423\n",
      "  Fold 2/5... RMSE = 0.010028\n",
      "  Fold 3/5... RMSE = 0.002861\n",
      "  Fold 4/5... RMSE = 0.002607\n",
      "  Fold 5/5... RMSE = 0.001875\n",
      "  Score moyen: 0.004159 (+/- 0.002976)\n",
      "\n",
      "Combinaison 70/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003557\n",
      "  Fold 2/5... RMSE = 0.010110\n",
      "  Fold 3/5... RMSE = 0.003164\n",
      "  Fold 4/5... RMSE = 0.002640\n",
      "  Fold 5/5... RMSE = 0.001899\n",
      "  Score moyen: 0.004274 (+/- 0.002970)\n",
      "\n",
      "Combinaison 71/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003498\n",
      "  Fold 2/5... RMSE = 0.010020\n",
      "  Fold 3/5... RMSE = 0.003051\n",
      "  Fold 4/5... RMSE = 0.002665\n",
      "  Fold 5/5... RMSE = 0.001981\n",
      "  Score moyen: 0.004243 (+/- 0.002931)\n",
      "\n",
      "Combinaison 72/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003651\n",
      "  Fold 2/5... RMSE = 0.010139\n",
      "  Fold 3/5... RMSE = 0.003472\n",
      "  Fold 4/5... RMSE = 0.002941\n",
      "  Fold 5/5... RMSE = 0.002108\n",
      "  Score moyen: 0.004462 (+/- 0.002889)\n",
      "\n",
      "Combinaison 73/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003417\n",
      "  Fold 2/5... RMSE = 0.009988\n",
      "  Fold 3/5... RMSE = 0.002562\n",
      "  Fold 4/5... RMSE = 0.002611\n",
      "  Fold 5/5... RMSE = 0.002125\n",
      "  Score moyen: 0.004141 (+/- 0.002953)\n",
      "\n",
      "Combinaison 74/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003451\n",
      "  Fold 2/5... RMSE = 0.009948\n",
      "  Fold 3/5... RMSE = 0.002653\n",
      "  Fold 4/5... RMSE = 0.002551\n",
      "  Fold 5/5... RMSE = 0.001913\n",
      "  Score moyen: 0.004103 (+/- 0.002963)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 75/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003437\n",
      "  Fold 2/5... RMSE = 0.009956\n",
      "  Fold 3/5... RMSE = 0.002719\n",
      "  Fold 4/5... RMSE = 0.002716\n",
      "  Fold 5/5... RMSE = 0.001956\n",
      "  Score moyen: 0.004157 (+/- 0.002937)\n",
      "\n",
      "Combinaison 76/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003490\n",
      "  Fold 2/5... RMSE = 0.009952\n",
      "  Fold 3/5... RMSE = 0.003179\n",
      "  Fold 4/5... RMSE = 0.002747\n",
      "  Fold 5/5... RMSE = 0.001948\n",
      "  Score moyen: 0.004263 (+/- 0.002891)\n",
      "\n",
      "Combinaison 77/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003480\n",
      "  Fold 2/5... RMSE = 0.009943\n",
      "  Fold 3/5... RMSE = 0.003124\n",
      "  Fold 4/5... RMSE = 0.003001\n",
      "  Fold 5/5... RMSE = 0.002098\n",
      "  Score moyen: 0.004329 (+/- 0.002843)\n",
      "\n",
      "Combinaison 78/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003509\n",
      "  Fold 2/5... RMSE = 0.009889\n",
      "  Fold 3/5... RMSE = 0.003754\n",
      "  Fold 4/5... RMSE = 0.003131\n",
      "  Fold 5/5... RMSE = 0.002255\n",
      "  Score moyen: 0.004507 (+/- 0.002738)\n",
      "\n",
      "Combinaison 79/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003387\n",
      "  Fold 2/5... RMSE = 0.009927\n",
      "  Fold 3/5... RMSE = 0.002536\n",
      "  Fold 4/5... RMSE = 0.002646\n",
      "  Fold 5/5... RMSE = 0.002083\n",
      "  Score moyen: 0.004116 (+/- 0.002936)\n",
      "\n",
      "Combinaison 80/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003438\n",
      "  Fold 2/5... RMSE = 0.009910\n",
      "  Fold 3/5... RMSE = 0.002587\n",
      "  Fold 4/5... RMSE = 0.002574\n",
      "  Fold 5/5... RMSE = 0.001908\n",
      "  Score moyen: 0.004083 (+/- 0.002953)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 81/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003446\n",
      "  Fold 2/5... RMSE = 0.009915\n",
      "  Fold 3/5... RMSE = 0.002693\n",
      "  Fold 4/5... RMSE = 0.002689\n",
      "  Fold 5/5... RMSE = 0.001941\n",
      "  Score moyen: 0.004137 (+/- 0.002928)\n",
      "\n",
      "Combinaison 82/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003473\n",
      "  Fold 2/5... RMSE = 0.009925\n",
      "  Fold 3/5... RMSE = 0.003178\n",
      "  Fold 4/5... RMSE = 0.002822\n",
      "  Fold 5/5... RMSE = 0.001982\n",
      "  Score moyen: 0.004276 (+/- 0.002868)\n",
      "\n",
      "Combinaison 83/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003489\n",
      "  Fold 2/5... RMSE = 0.009853\n",
      "  Fold 3/5... RMSE = 0.003118\n",
      "  Fold 4/5... RMSE = 0.002644\n",
      "  Fold 5/5... RMSE = 0.001950\n",
      "  Score moyen: 0.004211 (+/- 0.002867)\n",
      "\n",
      "Combinaison 84/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003525\n",
      "  Fold 2/5... RMSE = 0.009800\n",
      "  Fold 3/5... RMSE = 0.003737\n",
      "  Fold 4/5... RMSE = 0.002883\n",
      "  Fold 5/5... RMSE = 0.002100\n",
      "  Score moyen: 0.004409 (+/- 0.002755)\n",
      "\n",
      "Combinaison 85/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003330\n",
      "  Fold 2/5... RMSE = 0.009866\n",
      "  Fold 3/5... RMSE = 0.002616\n",
      "  Fold 4/5... RMSE = 0.002595\n",
      "  Fold 5/5... RMSE = 0.002091\n",
      "  Score moyen: 0.004100 (+/- 0.002910)\n",
      "\n",
      "Combinaison 86/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003422\n",
      "  Fold 2/5... RMSE = 0.009894\n",
      "  Fold 3/5... RMSE = 0.002615\n",
      "  Fold 4/5... RMSE = 0.002544\n",
      "  Fold 5/5... RMSE = 0.002009\n",
      "  Score moyen: 0.004097 (+/- 0.002933)\n",
      "\n",
      "Combinaison 87/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003426\n",
      "  Fold 2/5... RMSE = 0.009870\n",
      "  Fold 3/5... RMSE = 0.002659\n",
      "  Fold 4/5... RMSE = 0.002676\n",
      "  Fold 5/5... RMSE = 0.001999\n",
      "  Score moyen: 0.004126 (+/- 0.002907)\n",
      "\n",
      "Combinaison 88/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003484\n",
      "  Fold 2/5... RMSE = 0.009864\n",
      "  Fold 3/5... RMSE = 0.002987\n",
      "  Fold 4/5... RMSE = 0.002749\n",
      "  Fold 5/5... RMSE = 0.001988\n",
      "  Score moyen: 0.004214 (+/- 0.002866)\n",
      "\n",
      "Combinaison 89/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003486\n",
      "  Fold 2/5... RMSE = 0.009851\n",
      "  Fold 3/5... RMSE = 0.003094\n",
      "  Fold 4/5... RMSE = 0.002663\n",
      "  Fold 5/5... RMSE = 0.002058\n",
      "  Score moyen: 0.004231 (+/- 0.002850)\n",
      "\n",
      "Combinaison 90/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003539\n",
      "  Fold 2/5... RMSE = 0.009775\n",
      "  Fold 3/5... RMSE = 0.003562\n",
      "  Fold 4/5... RMSE = 0.002854\n",
      "  Fold 5/5... RMSE = 0.002181\n",
      "  Score moyen: 0.004382 (+/- 0.002744)\n",
      "\n",
      "Combinaison 91/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003349\n",
      "  Fold 2/5... RMSE = 0.009862\n",
      "  Fold 3/5... RMSE = 0.002554\n",
      "  Fold 4/5... RMSE = 0.002477\n",
      "  Fold 5/5... RMSE = 0.002302\n",
      "  Score moyen: 0.004109 (+/- 0.002899)\n",
      "\n",
      "Combinaison 92/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003403\n",
      "  Fold 2/5... RMSE = 0.009865\n",
      "  Fold 3/5... RMSE = 0.002844\n",
      "  Fold 4/5... RMSE = 0.002451\n",
      "  Fold 5/5... RMSE = 0.002279\n",
      "  Score moyen: 0.004168 (+/- 0.002874)\n",
      "\n",
      "Combinaison 93/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003417\n",
      "  Fold 2/5... RMSE = 0.009874\n",
      "  Fold 3/5... RMSE = 0.002798\n",
      "  Fold 4/5... RMSE = 0.002523\n",
      "  Fold 5/5... RMSE = 0.002292\n",
      "  Score moyen: 0.004181 (+/- 0.002872)\n",
      "\n",
      "Combinaison 94/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003417\n",
      "  Fold 2/5... RMSE = 0.009894\n",
      "  Fold 3/5... RMSE = 0.003548\n",
      "  Fold 4/5... RMSE = 0.002598\n",
      "  Fold 5/5... RMSE = 0.002441\n",
      "  Score moyen: 0.004379 (+/- 0.002791)\n",
      "\n",
      "Combinaison 95/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003437\n",
      "  Fold 2/5... RMSE = 0.009927\n",
      "  Fold 3/5... RMSE = 0.003489\n",
      "  Fold 4/5... RMSE = 0.002693\n",
      "  Fold 5/5... RMSE = 0.002465\n",
      "  Score moyen: 0.004402 (+/- 0.002792)\n",
      "\n",
      "Combinaison 96/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003437\n",
      "  Fold 2/5... RMSE = 0.009926\n",
      "  Fold 3/5... RMSE = 0.004072\n",
      "  Fold 4/5... RMSE = 0.002877\n",
      "  Fold 5/5... RMSE = 0.002558\n",
      "  Score moyen: 0.004574 (+/- 0.002725)\n",
      "\n",
      "Combinaison 97/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003356\n",
      "  Fold 2/5... RMSE = 0.009818\n",
      "  Fold 3/5... RMSE = 0.002479\n",
      "  Fold 4/5... RMSE = 0.002431\n",
      "  Fold 5/5... RMSE = 0.002329\n",
      "  Score moyen: 0.004082 (+/- 0.002891)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 98/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003402\n",
      "  Fold 2/5... RMSE = 0.009869\n",
      "  Fold 3/5... RMSE = 0.002909\n",
      "  Fold 4/5... RMSE = 0.002474\n",
      "  Fold 5/5... RMSE = 0.002418\n",
      "  Score moyen: 0.004214 (+/- 0.002849)\n",
      "\n",
      "Combinaison 99/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003418\n",
      "  Fold 2/5... RMSE = 0.009833\n",
      "  Fold 3/5... RMSE = 0.002906\n",
      "  Fold 4/5... RMSE = 0.002504\n",
      "  Fold 5/5... RMSE = 0.002432\n",
      "  Score moyen: 0.004219 (+/- 0.002829)\n",
      "\n",
      "Combinaison 100/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003418\n",
      "  Fold 2/5... RMSE = 0.009869\n",
      "  Fold 3/5... RMSE = 0.003627\n",
      "  Fold 4/5... RMSE = 0.002686\n",
      "  Fold 5/5... RMSE = 0.002557\n",
      "  Score moyen: 0.004431 (+/- 0.002749)\n",
      "\n",
      "Combinaison 101/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003433\n",
      "  Fold 2/5... RMSE = 0.009924\n",
      "  Fold 3/5... RMSE = 0.003617\n",
      "  Fold 4/5... RMSE = 0.002662\n",
      "  Fold 5/5... RMSE = 0.002578\n",
      "  Score moyen: 0.004443 (+/- 0.002771)\n",
      "\n",
      "Combinaison 102/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003433\n",
      "  Fold 2/5... RMSE = 0.009929\n",
      "  Fold 3/5... RMSE = 0.004181\n",
      "  Fold 4/5... RMSE = 0.002781\n",
      "  Fold 5/5... RMSE = 0.002629\n",
      "  Score moyen: 0.004591 (+/- 0.002725)\n",
      "\n",
      "Combinaison 103/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003354\n",
      "  Fold 2/5... RMSE = 0.009763\n",
      "  Fold 3/5... RMSE = 0.002576\n",
      "  Fold 4/5... RMSE = 0.002436\n",
      "  Fold 5/5... RMSE = 0.002129\n",
      "  Score moyen: 0.004052 (+/- 0.002884)\n",
      "  *** Nouveau meilleur score ! ***\n",
      "\n",
      "Combinaison 104/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003397\n",
      "  Fold 2/5... RMSE = 0.009804\n",
      "  Fold 3/5... RMSE = 0.002920\n",
      "  Fold 4/5... RMSE = 0.002531\n",
      "  Fold 5/5... RMSE = 0.002268\n",
      "  Score moyen: 0.004184 (+/- 0.002836)\n",
      "\n",
      "Combinaison 105/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003405\n",
      "  Fold 2/5... RMSE = 0.009806\n",
      "  Fold 3/5... RMSE = 0.002925\n",
      "  Fold 4/5... RMSE = 0.002545\n",
      "  Fold 5/5... RMSE = 0.002277\n",
      "  Score moyen: 0.004192 (+/- 0.002833)\n",
      "\n",
      "Combinaison 106/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003405\n",
      "  Fold 2/5... RMSE = 0.009911\n",
      "  Fold 3/5... RMSE = 0.003539\n",
      "  Fold 4/5... RMSE = 0.002710\n",
      "  Fold 5/5... RMSE = 0.002573\n",
      "  Score moyen: 0.004428 (+/- 0.002767)\n",
      "\n",
      "Combinaison 107/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003401\n",
      "  Fold 2/5... RMSE = 0.009863\n",
      "  Fold 3/5... RMSE = 0.003512\n",
      "  Fold 4/5... RMSE = 0.002745\n",
      "  Fold 5/5... RMSE = 0.002582\n",
      "  Score moyen: 0.004421 (+/- 0.002745)\n",
      "\n",
      "Combinaison 108/864: {'max_depth': 2, 'min_child_weight': 10, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003401\n",
      "  Fold 2/5... RMSE = 0.009869\n",
      "  Fold 3/5... RMSE = 0.003980\n",
      "  Fold 4/5... RMSE = 0.002786\n",
      "  Fold 5/5... RMSE = 0.002686\n",
      "  Score moyen: 0.004545 (+/- 0.002703)\n",
      "\n",
      "Combinaison 109/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003765\n",
      "  Fold 2/5... RMSE = 0.009858\n",
      "  Fold 3/5... RMSE = 0.002899\n",
      "  Fold 4/5... RMSE = 0.002606\n",
      "  Fold 5/5... RMSE = 0.002211\n",
      "  Score moyen: 0.004268 (+/- 0.002841)\n",
      "\n",
      "Combinaison 110/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003691\n",
      "  Fold 2/5... RMSE = 0.009762\n",
      "  Fold 3/5... RMSE = 0.002926\n",
      "  Fold 4/5... RMSE = 0.002576\n",
      "  Fold 5/5... RMSE = 0.002097\n",
      "  Score moyen: 0.004210 (+/- 0.002824)\n",
      "\n",
      "Combinaison 111/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003712\n",
      "  Fold 2/5... RMSE = 0.009729\n",
      "  Fold 3/5... RMSE = 0.002957\n",
      "  Fold 4/5... RMSE = 0.002700\n",
      "  Fold 5/5... RMSE = 0.002116\n",
      "  Score moyen: 0.004243 (+/- 0.002791)\n",
      "\n",
      "Combinaison 112/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003632\n",
      "  Fold 2/5... RMSE = 0.009689\n",
      "  Fold 3/5... RMSE = 0.003056\n",
      "  Fold 4/5... RMSE = 0.002733\n",
      "  Fold 5/5... RMSE = 0.002139\n",
      "  Score moyen: 0.004250 (+/- 0.002762)\n",
      "\n",
      "Combinaison 113/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003658\n",
      "  Fold 2/5... RMSE = 0.009623\n",
      "  Fold 3/5... RMSE = 0.003108\n",
      "  Fold 4/5... RMSE = 0.002853\n",
      "  Fold 5/5... RMSE = 0.002148\n",
      "  Score moyen: 0.004278 (+/- 0.002716)\n",
      "\n",
      "Combinaison 114/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003585\n",
      "  Fold 2/5... RMSE = 0.009724\n",
      "  Fold 3/5... RMSE = 0.003274\n",
      "  Fold 4/5... RMSE = 0.002964\n",
      "  Fold 5/5... RMSE = 0.002306\n",
      "  Score moyen: 0.004371 (+/- 0.002710)\n",
      "\n",
      "Combinaison 115/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003762\n",
      "  Fold 2/5... RMSE = 0.009826\n",
      "  Fold 3/5... RMSE = 0.002828\n",
      "  Fold 4/5... RMSE = 0.002593\n",
      "  Fold 5/5... RMSE = 0.002155\n",
      "  Score moyen: 0.004233 (+/- 0.002846)\n",
      "\n",
      "Combinaison 116/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003676\n",
      "  Fold 2/5... RMSE = 0.009751\n",
      "  Fold 3/5... RMSE = 0.002862\n",
      "  Fold 4/5... RMSE = 0.002604\n",
      "  Fold 5/5... RMSE = 0.002073\n",
      "  Score moyen: 0.004193 (+/- 0.002827)\n",
      "\n",
      "Combinaison 117/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003706\n",
      "  Fold 2/5... RMSE = 0.009708\n",
      "  Fold 3/5... RMSE = 0.002826\n",
      "  Fold 4/5... RMSE = 0.002720\n",
      "  Fold 5/5... RMSE = 0.002062\n",
      "  Score moyen: 0.004204 (+/- 0.002801)\n",
      "\n",
      "Combinaison 118/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003618\n",
      "  Fold 2/5... RMSE = 0.009687\n",
      "  Fold 3/5... RMSE = 0.002970\n",
      "  Fold 4/5... RMSE = 0.002753\n",
      "  Fold 5/5... RMSE = 0.002075\n",
      "  Score moyen: 0.004221 (+/- 0.002777)\n",
      "\n",
      "Combinaison 119/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003663\n",
      "  Fold 2/5... RMSE = 0.009598\n",
      "  Fold 3/5... RMSE = 0.003042\n",
      "  Fold 4/5... RMSE = 0.002861\n",
      "  Fold 5/5... RMSE = 0.002139\n",
      "  Score moyen: 0.004261 (+/- 0.002712)\n",
      "\n",
      "Combinaison 120/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003574\n",
      "  Fold 2/5... RMSE = 0.009704\n",
      "  Fold 3/5... RMSE = 0.003236\n",
      "  Fold 4/5... RMSE = 0.003105\n",
      "  Fold 5/5... RMSE = 0.002227\n",
      "  Score moyen: 0.004369 (+/- 0.002704)\n",
      "\n",
      "Combinaison 121/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003727\n",
      "  Fold 2/5... RMSE = 0.009790\n",
      "  Fold 3/5... RMSE = 0.002720\n",
      "  Fold 4/5... RMSE = 0.002518\n",
      "  Fold 5/5... RMSE = 0.002141\n",
      "  Score moyen: 0.004179 (+/- 0.002854)\n",
      "\n",
      "Combinaison 122/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003643\n",
      "  Fold 2/5... RMSE = 0.009741\n",
      "  Fold 3/5... RMSE = 0.002768\n",
      "  Fold 4/5... RMSE = 0.002605\n",
      "  Fold 5/5... RMSE = 0.002082\n",
      "  Score moyen: 0.004168 (+/- 0.002831)\n",
      "\n",
      "Combinaison 123/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003661\n",
      "  Fold 2/5... RMSE = 0.009660\n",
      "  Fold 3/5... RMSE = 0.002803\n",
      "  Fold 4/5... RMSE = 0.002673\n",
      "  Fold 5/5... RMSE = 0.002079\n",
      "  Score moyen: 0.004175 (+/- 0.002788)\n",
      "\n",
      "Combinaison 124/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003591\n",
      "  Fold 2/5... RMSE = 0.009687\n",
      "  Fold 3/5... RMSE = 0.002840\n",
      "  Fold 4/5... RMSE = 0.002726\n",
      "  Fold 5/5... RMSE = 0.002088\n",
      "  Score moyen: 0.004187 (+/- 0.002792)\n",
      "\n",
      "Combinaison 125/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003620\n",
      "  Fold 2/5... RMSE = 0.009600\n",
      "  Fold 3/5... RMSE = 0.002936\n",
      "  Fold 4/5... RMSE = 0.002849\n",
      "  Fold 5/5... RMSE = 0.002147\n",
      "  Score moyen: 0.004231 (+/- 0.002725)\n",
      "\n",
      "Combinaison 126/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003544\n",
      "  Fold 2/5... RMSE = 0.009720\n",
      "  Fold 3/5... RMSE = 0.003069\n",
      "  Fold 4/5... RMSE = 0.002896\n",
      "  Fold 5/5... RMSE = 0.002295\n",
      "  Score moyen: 0.004305 (+/- 0.002737)\n",
      "\n",
      "Combinaison 127/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003528\n",
      "  Fold 2/5... RMSE = 0.010065\n",
      "  Fold 3/5... RMSE = 0.002738\n",
      "  Fold 4/5... RMSE = 0.002501\n",
      "  Fold 5/5... RMSE = 0.002235\n",
      "  Score moyen: 0.004213 (+/- 0.002958)\n",
      "\n",
      "Combinaison 128/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003488\n",
      "  Fold 2/5... RMSE = 0.010095\n",
      "  Fold 3/5... RMSE = 0.002850\n",
      "  Fold 4/5... RMSE = 0.002500\n",
      "  Fold 5/5... RMSE = 0.002171\n",
      "  Score moyen: 0.004221 (+/- 0.002969)\n",
      "\n",
      "Combinaison 129/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003498\n",
      "  Fold 2/5... RMSE = 0.010111\n",
      "  Fold 3/5... RMSE = 0.002750\n",
      "  Fold 4/5... RMSE = 0.002522\n",
      "  Fold 5/5... RMSE = 0.002191\n",
      "  Score moyen: 0.004214 (+/- 0.002980)\n",
      "\n",
      "Combinaison 130/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003475\n",
      "  Fold 2/5... RMSE = 0.010190\n",
      "  Fold 3/5... RMSE = 0.003093\n",
      "  Fold 4/5... RMSE = 0.002647\n",
      "  Fold 5/5... RMSE = 0.002196\n",
      "  Score moyen: 0.004320 (+/- 0.002966)\n",
      "\n",
      "Combinaison 131/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003487\n",
      "  Fold 2/5... RMSE = 0.010265\n",
      "  Fold 3/5... RMSE = 0.003062\n",
      "  Fold 4/5... RMSE = 0.002653\n",
      "  Fold 5/5... RMSE = 0.002273\n",
      "  Score moyen: 0.004348 (+/- 0.002986)\n",
      "\n",
      "Combinaison 132/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003474\n",
      "  Fold 2/5... RMSE = 0.010395\n",
      "  Fold 3/5... RMSE = 0.003358\n",
      "  Fold 4/5... RMSE = 0.002885\n",
      "  Fold 5/5... RMSE = 0.002347\n",
      "  Score moyen: 0.004492 (+/- 0.002978)\n",
      "\n",
      "Combinaison 133/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003517\n",
      "  Fold 2/5... RMSE = 0.010070\n",
      "  Fold 3/5... RMSE = 0.002715\n",
      "  Fold 4/5... RMSE = 0.002514\n",
      "  Fold 5/5... RMSE = 0.002213\n",
      "  Score moyen: 0.004206 (+/- 0.002964)\n",
      "\n",
      "Combinaison 134/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003478\n",
      "  Fold 2/5... RMSE = 0.010086\n",
      "  Fold 3/5... RMSE = 0.002813\n",
      "  Fold 4/5... RMSE = 0.002459\n",
      "  Fold 5/5... RMSE = 0.002192\n",
      "  Score moyen: 0.004206 (+/- 0.002972)\n",
      "\n",
      "Combinaison 135/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003486\n",
      "  Fold 2/5... RMSE = 0.010131\n",
      "  Fold 3/5... RMSE = 0.002770\n",
      "  Fold 4/5... RMSE = 0.002620\n",
      "  Fold 5/5... RMSE = 0.002195\n",
      "  Score moyen: 0.004240 (+/- 0.002975)\n",
      "\n",
      "Combinaison 136/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003468\n",
      "  Fold 2/5... RMSE = 0.010176\n",
      "  Fold 3/5... RMSE = 0.003094\n",
      "  Fold 4/5... RMSE = 0.002671\n",
      "  Fold 5/5... RMSE = 0.002243\n",
      "  Score moyen: 0.004330 (+/- 0.002951)\n",
      "\n",
      "Combinaison 137/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003473\n",
      "  Fold 2/5... RMSE = 0.010242\n",
      "  Fold 3/5... RMSE = 0.003079\n",
      "  Fold 4/5... RMSE = 0.002664\n",
      "  Fold 5/5... RMSE = 0.002268\n",
      "  Score moyen: 0.004345 (+/- 0.002976)\n",
      "\n",
      "Combinaison 138/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003472\n",
      "  Fold 2/5... RMSE = 0.010364\n",
      "  Fold 3/5... RMSE = 0.003516\n",
      "  Fold 4/5... RMSE = 0.002925\n",
      "  Fold 5/5... RMSE = 0.002331\n",
      "  Score moyen: 0.004522 (+/- 0.002953)\n",
      "\n",
      "Combinaison 139/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003492\n",
      "  Fold 2/5... RMSE = 0.010015\n",
      "  Fold 3/5... RMSE = 0.002640\n",
      "  Fold 4/5... RMSE = 0.002508\n",
      "  Fold 5/5... RMSE = 0.002241\n",
      "  Score moyen: 0.004179 (+/- 0.002948)\n",
      "\n",
      "Combinaison 140/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003468\n",
      "  Fold 2/5... RMSE = 0.010067\n",
      "  Fold 3/5... RMSE = 0.002751\n",
      "  Fold 4/5... RMSE = 0.002461\n",
      "  Fold 5/5... RMSE = 0.002244\n",
      "  Score moyen: 0.004198 (+/- 0.002963)\n",
      "\n",
      "Combinaison 141/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003471\n",
      "  Fold 2/5... RMSE = 0.010120\n",
      "  Fold 3/5... RMSE = 0.002838\n",
      "  Fold 4/5... RMSE = 0.002569\n",
      "  Fold 5/5... RMSE = 0.002211\n",
      "  Score moyen: 0.004242 (+/- 0.002968)\n",
      "\n",
      "Combinaison 142/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003461\n",
      "  Fold 2/5... RMSE = 0.010205\n",
      "  Fold 3/5... RMSE = 0.003058\n",
      "  Fold 4/5... RMSE = 0.002661\n",
      "  Fold 5/5... RMSE = 0.002263\n",
      "  Score moyen: 0.004330 (+/- 0.002965)\n",
      "\n",
      "Combinaison 143/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003462\n",
      "  Fold 2/5... RMSE = 0.010206\n",
      "  Fold 3/5... RMSE = 0.003108\n",
      "  Fold 4/5... RMSE = 0.002658\n",
      "  Fold 5/5... RMSE = 0.002336\n",
      "  Score moyen: 0.004354 (+/- 0.002951)\n",
      "\n",
      "Combinaison 144/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 0.8, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003470\n",
      "  Fold 2/5... RMSE = 0.010280\n",
      "  Fold 3/5... RMSE = 0.003587\n",
      "  Fold 4/5... RMSE = 0.002828\n",
      "  Fold 5/5... RMSE = 0.002430\n",
      "  Score moyen: 0.004519 (+/- 0.002911)\n",
      "\n",
      "Combinaison 145/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003449\n",
      "  Fold 2/5... RMSE = 0.010193\n",
      "  Fold 3/5... RMSE = 0.002704\n",
      "  Fold 4/5... RMSE = 0.002527\n",
      "  Fold 5/5... RMSE = 0.002234\n",
      "  Score moyen: 0.004222 (+/- 0.003013)\n",
      "\n",
      "Combinaison 146/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003441\n",
      "  Fold 2/5... RMSE = 0.010287\n",
      "  Fold 3/5... RMSE = 0.002943\n",
      "  Fold 4/5... RMSE = 0.002471\n",
      "  Fold 5/5... RMSE = 0.002237\n",
      "  Score moyen: 0.004276 (+/- 0.003034)\n",
      "\n",
      "Combinaison 147/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003440\n",
      "  Fold 2/5... RMSE = 0.010258\n",
      "  Fold 3/5... RMSE = 0.002940\n",
      "  Fold 4/5... RMSE = 0.002563\n",
      "  Fold 5/5... RMSE = 0.002253\n",
      "  Score moyen: 0.004291 (+/- 0.003010)\n",
      "\n",
      "Combinaison 148/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003443\n",
      "  Fold 2/5... RMSE = 0.010304\n",
      "  Fold 3/5... RMSE = 0.003266\n",
      "  Fold 4/5... RMSE = 0.002564\n",
      "  Fold 5/5... RMSE = 0.002236\n",
      "  Score moyen: 0.004363 (+/- 0.003004)\n",
      "\n",
      "Combinaison 149/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003444\n",
      "  Fold 2/5... RMSE = 0.010317\n",
      "  Fold 3/5... RMSE = 0.003354\n",
      "  Fold 4/5... RMSE = 0.002567\n",
      "  Fold 5/5... RMSE = 0.002227\n",
      "  Score moyen: 0.004382 (+/- 0.003004)\n",
      "\n",
      "Combinaison 150/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003443\n",
      "  Fold 2/5... RMSE = 0.010395\n",
      "  Fold 3/5... RMSE = 0.003515\n",
      "  Fold 4/5... RMSE = 0.002774\n",
      "  Fold 5/5... RMSE = 0.002306\n",
      "  Score moyen: 0.004487 (+/- 0.002988)\n",
      "\n",
      "Combinaison 151/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003451\n",
      "  Fold 2/5... RMSE = 0.010224\n",
      "  Fold 3/5... RMSE = 0.002713\n",
      "  Fold 4/5... RMSE = 0.002625\n",
      "  Fold 5/5... RMSE = 0.002228\n",
      "  Score moyen: 0.004248 (+/- 0.003014)\n",
      "\n",
      "Combinaison 152/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003443\n",
      "  Fold 2/5... RMSE = 0.010258\n",
      "  Fold 3/5... RMSE = 0.002964\n",
      "  Fold 4/5... RMSE = 0.002582\n",
      "  Fold 5/5... RMSE = 0.002251\n",
      "  Score moyen: 0.004300 (+/- 0.003006)\n",
      "\n",
      "Combinaison 153/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003444\n",
      "  Fold 2/5... RMSE = 0.010233\n",
      "  Fold 3/5... RMSE = 0.002941\n",
      "  Fold 4/5... RMSE = 0.002580\n",
      "  Fold 5/5... RMSE = 0.002274\n",
      "  Score moyen: 0.004294 (+/- 0.002995)\n",
      "\n",
      "Combinaison 154/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003447\n",
      "  Fold 2/5... RMSE = 0.010243\n",
      "  Fold 3/5... RMSE = 0.003199\n",
      "  Fold 4/5... RMSE = 0.002577\n",
      "  Fold 5/5... RMSE = 0.002222\n",
      "  Score moyen: 0.004338 (+/- 0.002985)\n",
      "\n",
      "Combinaison 155/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003446\n",
      "  Fold 2/5... RMSE = 0.010242\n",
      "  Fold 3/5... RMSE = 0.003233\n",
      "  Fold 4/5... RMSE = 0.002626\n",
      "  Fold 5/5... RMSE = 0.002256\n",
      "  Score moyen: 0.004361 (+/- 0.002971)\n",
      "\n",
      "Combinaison 156/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003446\n",
      "  Fold 2/5... RMSE = 0.010324\n",
      "  Fold 3/5... RMSE = 0.003416\n",
      "  Fold 4/5... RMSE = 0.002859\n",
      "  Fold 5/5... RMSE = 0.002275\n",
      "  Score moyen: 0.004464 (+/- 0.002961)\n",
      "\n",
      "Combinaison 157/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003450\n",
      "  Fold 2/5... RMSE = 0.010175\n",
      "  Fold 3/5... RMSE = 0.002675\n",
      "  Fold 4/5... RMSE = 0.002688\n",
      "  Fold 5/5... RMSE = 0.002290\n",
      "  Score moyen: 0.004256 (+/- 0.002984)\n",
      "\n",
      "Combinaison 158/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003444\n",
      "  Fold 2/5... RMSE = 0.010207\n",
      "  Fold 3/5... RMSE = 0.002941\n",
      "  Fold 4/5... RMSE = 0.002690\n",
      "  Fold 5/5... RMSE = 0.002282\n",
      "  Score moyen: 0.004313 (+/- 0.002971)\n",
      "\n",
      "Combinaison 159/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003444\n",
      "  Fold 2/5... RMSE = 0.010202\n",
      "  Fold 3/5... RMSE = 0.002949\n",
      "  Fold 4/5... RMSE = 0.002684\n",
      "  Fold 5/5... RMSE = 0.002269\n",
      "  Score moyen: 0.004310 (+/- 0.002971)\n",
      "\n",
      "Combinaison 160/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003446\n",
      "  Fold 2/5... RMSE = 0.010198\n",
      "  Fold 3/5... RMSE = 0.003203\n",
      "  Fold 4/5... RMSE = 0.002628\n",
      "  Fold 5/5... RMSE = 0.002260\n",
      "  Score moyen: 0.004347 (+/- 0.002955)\n",
      "\n",
      "Combinaison 161/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003443\n",
      "  Fold 2/5... RMSE = 0.010198\n",
      "  Fold 3/5... RMSE = 0.003219\n",
      "  Fold 4/5... RMSE = 0.002643\n",
      "  Fold 5/5... RMSE = 0.002303\n",
      "  Score moyen: 0.004361 (+/- 0.002946)\n",
      "\n",
      "Combinaison 162/864: {'max_depth': 2, 'min_child_weight': 20, 'subsample': 1, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003443\n",
      "  Fold 2/5... RMSE = 0.010256\n",
      "  Fold 3/5... RMSE = 0.003535\n",
      "  Fold 4/5... RMSE = 0.002903\n",
      "  Fold 5/5... RMSE = 0.002364\n",
      "  Score moyen: 0.004500 (+/- 0.002908)\n",
      "\n",
      "Combinaison 163/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003843\n",
      "  Fold 2/5... RMSE = 0.010395\n",
      "  Fold 3/5... RMSE = 0.003031\n",
      "  Fold 4/5... RMSE = 0.002761\n",
      "  Fold 5/5... RMSE = 0.002495\n",
      "  Score moyen: 0.004505 (+/- 0.002980)\n",
      "\n",
      "Combinaison 164/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003838\n",
      "  Fold 2/5... RMSE = 0.010321\n",
      "  Fold 3/5... RMSE = 0.003051\n",
      "  Fold 4/5... RMSE = 0.002810\n",
      "  Fold 5/5... RMSE = 0.002432\n",
      "  Score moyen: 0.004490 (+/- 0.002951)\n",
      "\n",
      "Combinaison 165/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003842\n",
      "  Fold 2/5... RMSE = 0.010351\n",
      "  Fold 3/5... RMSE = 0.003076\n",
      "  Fold 4/5... RMSE = 0.002822\n",
      "  Fold 5/5... RMSE = 0.002493\n",
      "  Score moyen: 0.004517 (+/- 0.002951)\n",
      "\n",
      "Combinaison 166/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003837\n",
      "  Fold 2/5... RMSE = 0.010242\n",
      "  Fold 3/5... RMSE = 0.003177\n",
      "  Fold 4/5... RMSE = 0.002936\n",
      "  Fold 5/5... RMSE = 0.002506\n",
      "  Score moyen: 0.004540 (+/- 0.002883)\n",
      "\n",
      "Combinaison 167/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003841\n",
      "  Fold 2/5... RMSE = 0.010289\n",
      "  Fold 3/5... RMSE = 0.003197\n",
      "  Fold 4/5... RMSE = 0.002825\n",
      "  Fold 5/5... RMSE = 0.002439\n",
      "  Score moyen: 0.004518 (+/- 0.002922)\n",
      "\n",
      "Combinaison 168/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003838\n",
      "  Fold 2/5... RMSE = 0.010124\n",
      "  Fold 3/5... RMSE = 0.003348\n",
      "  Fold 4/5... RMSE = 0.003038\n",
      "  Fold 5/5... RMSE = 0.002561\n",
      "  Score moyen: 0.004582 (+/- 0.002802)\n",
      "\n",
      "Combinaison 169/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003843\n",
      "  Fold 2/5... RMSE = 0.010389\n",
      "  Fold 3/5... RMSE = 0.002987\n",
      "  Fold 4/5... RMSE = 0.002758\n",
      "  Fold 5/5... RMSE = 0.002476\n",
      "  Score moyen: 0.004491 (+/- 0.002984)\n",
      "\n",
      "Combinaison 170/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003838\n",
      "  Fold 2/5... RMSE = 0.010313\n",
      "  Fold 3/5... RMSE = 0.003019\n",
      "  Fold 4/5... RMSE = 0.002819\n",
      "  Fold 5/5... RMSE = 0.002464\n",
      "  Score moyen: 0.004490 (+/- 0.002946)\n",
      "\n",
      "Combinaison 171/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003842\n",
      "  Fold 2/5... RMSE = 0.010340\n",
      "  Fold 3/5... RMSE = 0.003047\n",
      "  Fold 4/5... RMSE = 0.002810\n",
      "  Fold 5/5... RMSE = 0.002469\n",
      "  Score moyen: 0.004502 (+/- 0.002954)\n",
      "\n",
      "Combinaison 172/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003837\n",
      "  Fold 2/5... RMSE = 0.010224\n",
      "  Fold 3/5... RMSE = 0.003147\n",
      "  Fold 4/5... RMSE = 0.002899\n",
      "  Fold 5/5... RMSE = 0.002525\n",
      "  Score moyen: 0.004526 (+/- 0.002881)\n",
      "\n",
      "Combinaison 173/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003841\n",
      "  Fold 2/5... RMSE = 0.010274\n",
      "  Fold 3/5... RMSE = 0.003132\n",
      "  Fold 4/5... RMSE = 0.002797\n",
      "  Fold 5/5... RMSE = 0.002541\n",
      "  Score moyen: 0.004517 (+/- 0.002911)\n",
      "\n",
      "Combinaison 174/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003838\n",
      "  Fold 2/5... RMSE = 0.010117\n",
      "  Fold 3/5... RMSE = 0.003279\n",
      "  Fold 4/5... RMSE = 0.002930\n",
      "  Fold 5/5... RMSE = 0.002642\n",
      "  Score moyen: 0.004561 (+/- 0.002806)\n",
      "\n",
      "Combinaison 175/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003843\n",
      "  Fold 2/5... RMSE = 0.010374\n",
      "  Fold 3/5... RMSE = 0.002942\n",
      "  Fold 4/5... RMSE = 0.002758\n",
      "  Fold 5/5... RMSE = 0.002453\n",
      "  Score moyen: 0.004474 (+/- 0.002986)\n",
      "\n",
      "Combinaison 176/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003838\n",
      "  Fold 2/5... RMSE = 0.010288\n",
      "  Fold 3/5... RMSE = 0.002971\n",
      "  Fold 4/5... RMSE = 0.002811\n",
      "  Fold 5/5... RMSE = 0.002472\n",
      "  Score moyen: 0.004476 (+/- 0.002941)\n",
      "\n",
      "Combinaison 177/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003842\n",
      "  Fold 2/5... RMSE = 0.010321\n",
      "  Fold 3/5... RMSE = 0.003014\n",
      "  Fold 4/5... RMSE = 0.002827\n",
      "  Fold 5/5... RMSE = 0.002471\n",
      "  Score moyen: 0.004495 (+/- 0.002947)\n",
      "\n",
      "Combinaison 178/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.04, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003837\n",
      "  Fold 2/5... RMSE = 0.010201\n",
      "  Fold 3/5... RMSE = 0.003062\n",
      "  Fold 4/5... RMSE = 0.002913\n",
      "  Fold 5/5... RMSE = 0.002529\n",
      "  Score moyen: 0.004508 (+/- 0.002878)\n",
      "\n",
      "Combinaison 179/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003841\n",
      "  Fold 2/5... RMSE = 0.010237\n",
      "  Fold 3/5... RMSE = 0.003166\n",
      "  Fold 4/5... RMSE = 0.002920\n",
      "  Fold 5/5... RMSE = 0.002477\n",
      "  Score moyen: 0.004528 (+/- 0.002888)\n",
      "\n",
      "Combinaison 180/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.6, 'colsample_bytree': 1, 'learning_rate': 0.08, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003838\n",
      "  Fold 2/5... RMSE = 0.010102\n",
      "  Fold 3/5... RMSE = 0.003240\n",
      "  Fold 4/5... RMSE = 0.003027\n",
      "  Fold 5/5... RMSE = 0.002567\n",
      "  Score moyen: 0.004555 (+/- 0.002804)\n",
      "\n",
      "Combinaison 181/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 300}\n",
      "  Fold 1/5... RMSE = 0.003832\n",
      "  Fold 2/5... RMSE = 0.009928\n",
      "  Fold 3/5... RMSE = 0.002926\n",
      "  Fold 4/5... RMSE = 0.002736\n",
      "  Fold 5/5... RMSE = 0.002331\n",
      "  Score moyen: 0.004351 (+/- 0.002832)\n",
      "\n",
      "Combinaison 182/864: {'max_depth': 2, 'min_child_weight': 30, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.02, 'n_estimators': 600}\n",
      "  Fold 1/5... RMSE = 0.003829\n",
      "  Fold 2/5... RMSE = 0.009812\n",
      "  Fold 3/5... RMSE = 0.002898\n",
      "  Fold 4/5... RMSE = 0.002850\n",
      "  Fold 5/5... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[174]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDÉMARRAGE DE LA VALIDATION CROISÉE AVEC RÉ-ENTRAÎNEMENT DYNAMIQUE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m results, best_params_dynamic, best_score_dynamic = \u001b[43mdynamic_cv_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxgb_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtscv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_grid\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRÉSULTATS FINAUX\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[174]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mdynamic_cv_score\u001b[39m\u001b[34m(model, X, y, cv_splits, param_grid)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Entraîner le modèle avec les paramètres actuels\u001b[39;00m\n\u001b[32m     54\u001b[39m model_dynamic = XGBRegressor(\n\u001b[32m     55\u001b[39m     **params,\n\u001b[32m     56\u001b[39m     objective=\u001b[33m\"\u001b[39m\u001b[33mreg:squarederror\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     60\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[43mmodel_dynamic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_extended\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_extended\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Prédire le point suivant\u001b[39;00m\n\u001b[32m     65\u001b[39m y_pred = model_dynamic.predict(X_val_fold.iloc[[i]])[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\Projet_Data_Science\\Mesure-et-gestion-du-risque-des-portefeuilles-OPCVM-l-aide-de-la-Data-Science\\venv_gestion_risque\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\Projet_Data_Science\\Mesure-et-gestion-du-risque-des-portefeuilles-OPCVM-l-aide-de-la-Data-Science\\venv_gestion_risque\\Lib\\site-packages\\xgboost\\sklearn.py:1368\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1366\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\Projet_Data_Science\\Mesure-et-gestion-du-risque-des-portefeuilles-OPCVM-l-aide-de-la-Data-Science\\venv_gestion_risque\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\Projet_Data_Science\\Mesure-et-gestion-du-risque-des-portefeuilles-OPCVM-l-aide-de-la-Data-Science\\venv_gestion_risque\\Lib\\site-packages\\xgboost\\training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\Projet_Data_Science\\Mesure-et-gestion-du-risque-des-portefeuilles-OPCVM-l-aide-de-la-Data-Science\\venv_gestion_risque\\Lib\\site-packages\\xgboost\\core.py:2434\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2430\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2434\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2437\u001b[39m     )\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2439\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Configuration de la validation croisée\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Fonction personnalisée pour le forecast dynamique avec ré-entraînement\n",
    "def dynamic_cv_score(model, X, y, cv_splits, param_grid):\n",
    "    \"\"\"\n",
    "    Effectue une validation croisée avec ré-entraînement dynamique\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Tester chaque combinaison de paramètres\n",
    "    from itertools import product\n",
    "    \n",
    "    # Générer toutes les combinaisons de paramètres\n",
    "    keys = param_grid.keys()\n",
    "    values = param_grid.values()\n",
    "    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    \n",
    "    print(f\"Test de {len(param_combinations)} combinaisons de paramètres...\")\n",
    "    print(f\"Avec {cv_splits.n_splits} folds de validation croisée\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    for param_idx, params in enumerate(param_combinations):\n",
    "        print(f\"\\nCombinaison {param_idx + 1}/{len(param_combinations)}: {params}\")\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        # Pour chaque fold de la validation croisée\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(cv_splits.split(X)):\n",
    "            print(f\"  Fold {fold_idx + 1}/{cv_splits.n_splits}...\", end=\" \")\n",
    "            \n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            X_val_fold = X.iloc[val_idx]\n",
    "            y_val_fold = y.iloc[val_idx]\n",
    "            \n",
    "            # Forecast dynamique avec ré-entraînement sur ce fold\n",
    "            predictions = []\n",
    "            actuals = []\n",
    "            \n",
    "            for i in range(len(X_val_fold)):\n",
    "                # Créer l'ensemble d'entraînement étendu\n",
    "                if i > 0:\n",
    "                    X_train_extended = pd.concat([X_train_fold, X_val_fold.iloc[:i]])\n",
    "                    y_train_extended = pd.concat([y_train_fold, y_val_fold.iloc[:i]])\n",
    "                else:\n",
    "                    X_train_extended = X_train_fold\n",
    "                    y_train_extended = y_train_fold\n",
    "                \n",
    "                # Entraîner le modèle avec les paramètres actuels\n",
    "                model_dynamic = XGBRegressor(\n",
    "                    **params,\n",
    "                    objective=\"reg:squarederror\",\n",
    "                    eval_metric=\"rmse\",\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                \n",
    "                model_dynamic.fit(X_train_extended, y_train_extended, verbose=0)\n",
    "                \n",
    "                # Prédire le point suivant\n",
    "                y_pred = model_dynamic.predict(X_val_fold.iloc[[i]])[0]\n",
    "                predictions.append(y_pred)\n",
    "                actuals.append(y_val_fold.iloc[i])\n",
    "            \n",
    "            # Calculer le RMSE pour ce fold\n",
    "            fold_rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "            fold_scores.append(fold_rmse)\n",
    "            print(f\"RMSE = {fold_rmse:.6f}\")\n",
    "        \n",
    "        # Calculer le score moyen sur tous les folds\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        \n",
    "        print(f\"  Score moyen: {mean_score:.6f} (+/- {std_score:.6f})\")\n",
    "        \n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'mean_score': mean_score,\n",
    "            'std_score': std_score,\n",
    "            'fold_scores': fold_scores\n",
    "        })\n",
    "        \n",
    "        # Mettre à jour les meilleurs paramètres\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = params\n",
    "            print(f\"  *** Nouveau meilleur score ! ***\")\n",
    "    \n",
    "    return results, best_params, best_score\n",
    "\n",
    "\n",
    "# Exécuter la validation croisée dynamique\n",
    "print(\"DÉMARRAGE DE LA VALIDATION CROISÉE AVEC RÉ-ENTRAÎNEMENT DYNAMIQUE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results, best_params_dynamic, best_score_dynamic = dynamic_cv_score(\n",
    "    model=xgb_base,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    cv_splits=tscv,\n",
    "    param_grid=param_grid\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RÉSULTATS FINAUX\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Meilleurs paramètres: {best_params_dynamic}\")\n",
    "print(f\"Meilleur score RMSE: {best_score_dynamic:.6f}\")\n",
    "\n",
    "# Créer un DataFrame avec tous les résultats pour analyse\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        **r['params'],\n",
    "        'mean_rmse': r['mean_score'],\n",
    "        'std_rmse': r['std_score']\n",
    "    }\n",
    "    for r in results\n",
    "])\n",
    "\n",
    "results_df = results_df.sort_values('mean_rmse')\n",
    "print(\"\\nTop 5 des meilleures combinaisons:\")\n",
    "print(results_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle final avec les meilleurs paramètres\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENTRAÎNEMENT DU MODÈLE FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "xgb_final = XGBRegressor(\n",
    "    **best_params_dynamic,\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_final.fit(X_train, y_train, verbose=50)\n",
    "\n",
    "# Évaluation sur le test set (statique)\n",
    "y_pred = xgb_final.predict(X_test)\n",
    "rmse_static = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae_static = mean_absolute_error(y_test, y_pred)\n",
    "r2_static = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nPERFORMANCE SUR TEST SET (STATIQUE):\")\n",
    "print(f\"RMSE : {rmse_static:.6f}\")\n",
    "print(f\"MAE  : {mae_static:.6f}\")\n",
    "print(f\"R²   : {r2_static:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gestion_risque",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
